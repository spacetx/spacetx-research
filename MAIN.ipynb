{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI DAPI VAE in PYRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "#! conda update -y pytorch torchvision -c pytorch\n",
    "#! pip install pyro-ppl --upgrade\n",
    "# pip install --upgrade Pillow\n",
    "#!pip install seaborn\n",
    "#!pip install leidenalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_version() --->  3.7.7\n",
      "torch.__version__ -->  1.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically\n",
    "\n",
    "# Check versions\n",
    "from platform import python_version\n",
    "print(\"python_version() ---> \",python_version())\n",
    "print(\"torch.__version__ --> \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML, Image\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from MODULES.utilities import *\n",
    "from MODULES.vae_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We expect to find the file \"parameters.json\" in the execution directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wdl.alias': '',\n",
       " 'wdl.memo': 'merfish data',\n",
       " 'wdl.file_train': 'gs://ld-data-bucket/Allen_smFISH/preprocessed_smFISH_stitched_OLEH.tif',\n",
       " 'wdl.file_test': 'gs://ld-results-bucket/ckpt/dummy_1.pkl',\n",
       " 'wdl.file_ckpt': 'gs://ld-results-bucket/ckpt/dummy_2.pkl',\n",
       " 'wdl.bucket_output': 'gs://ld-results-bucket',\n",
       " 'wdl.dir_output': 'merfish_aug_5_v1',\n",
       " 'wdl.notebook_name': 'MAIN.ipynb',\n",
       " 'wdl.git_repo': 'https://github.com/spacetx/spacetx-research.git',\n",
       " 'wdl.commit_or_branch': 'master',\n",
       " 'simulation': {'__comment': 'there are 3 types of runs: scratch, resume, pretrained',\n",
       "  'type': 'scratch',\n",
       "  'MAX_EPOCHS': 5000,\n",
       "  'TEST_FREQUENCY': 100,\n",
       "  'CHECKPOINT_FREQUENCY': 100,\n",
       "  'batch_size': 128},\n",
       " 'architecture': {'__comment': 'architecture parameters, level_zwhere_output is between 0 and n_max_pool included',\n",
       "  'dim_zinstance': 20,\n",
       "  'dim_zwhere': 4,\n",
       "  'dim_logit': 1,\n",
       "  'cropped_size': 28,\n",
       "  'n_max_pool': 4,\n",
       "  'level_zwhere_and_logit_output': 2,\n",
       "  'level_background_output': 4,\n",
       "  'n_ch_output_features': 32,\n",
       "  'n_ch_after_first_two_conv': 32},\n",
       " 'input_image': {'__comment': 'parameters describing the input images',\n",
       "  'n_objects_max': 25,\n",
       "  'size_object_min': 5,\n",
       "  'size_object_max': 20,\n",
       "  'length_scale_GP': 8.0,\n",
       "  'size_raw_image': 80,\n",
       "  'ch_in': 1,\n",
       "  'bg_is_zero': True,\n",
       "  'background_resolution_before_upsampling': [2, 2]},\n",
       " 'nms': {'__comment': 'parameters for the non-max-suppression',\n",
       "  'overlap_threshold': 0.3},\n",
       " 'GECO_loss': {'__comment': 'if active=false use ELBO, else use GECO with Log-Likelihood threshold = n_pixels * n_channel * threshold',\n",
       "  'is_active': True,\n",
       "  'factor_balance_range': [0.1, 0.8, 0.9],\n",
       "  'factor_sparsity_range': [-1, 1.0, 100],\n",
       "  'target_fg_fraction': [0.05, 0.2],\n",
       "  'target_mse': [0.75, 1.0],\n",
       "  'bg_std': 0.05,\n",
       "  'fg_std': 0.05},\n",
       " 'optimizer': {'__comment': 'which optimizer to use',\n",
       "  'type': 'adam',\n",
       "  'base_lr': 0.001,\n",
       "  'betas': [0.9, 0.999],\n",
       "  'base_lr_geco': 0.001,\n",
       "  'betas_geco': [0.9, 0.999],\n",
       "  'weight_decay': 0.0,\n",
       "  'eps': 1e-08,\n",
       "  'scheduler_is_active': True,\n",
       "  'scheduler_type': 'step_LR',\n",
       "  'scheduler_step_size': 500,\n",
       "  'scheduler_gamma': 0.75},\n",
       " 'shortcut_prob_corr_factor': {'__comment': 'parameters for the shortcut for porb_corr_factor',\n",
       "  'values': [0.5, 0.0],\n",
       "  'times': [200, 500]},\n",
       " 'soft_constraint': {'__comment': 'all the parameters about the soft constraints',\n",
       "  'overlap': {'__comment': 'cost which discourages masks from overlapping',\n",
       "   'strength': 0.01,\n",
       "   'exponent': 1},\n",
       "  'mask_volume_absolute': {'__comment': 'cost which discourage masks which are too large or too small',\n",
       "   'lower_bound_value': 40,\n",
       "   'lower_bound_width': 5,\n",
       "   'lower_bound_strength': 0,\n",
       "   'lower_bound_exponent': 2,\n",
       "   'upper_bound_value': 300,\n",
       "   'upper_bound_width': 5,\n",
       "   'upper_bound_strength': 0,\n",
       "   'upper_bound_exponent': 2}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = load_json_as_dict(\"parameters_MERFISH.json\")\n",
    "#params = load_json_as_dict(\"parameters_VISIUM.json\")\n",
    "#params = load_json_as_dict(\"parameters.json\")\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_smFISH_stitched_OLEH.tif\n",
      "dummy_1.pkl\n",
      "NEW_ARCHIVE/merfish_aug_5_v1\n",
      "NEW_ARCHIVE/merfish_aug_5_v1/parameters.json\n",
      "dummy_2.pkl\n"
     ]
    }
   ],
   "source": [
    "# CROMWELL will localize: \n",
    "# gs://ld-data-bucket/data/fashionmnist_train.pkl -> execution_dir/ld-data-bucket/data/fashionmnist_train.pkl\n",
    "# Therefore I just need to remove  \"gs://\"\n",
    "# Note that every path is relative to the execution_dir\n",
    "\n",
    "train_file = os.path.basename(params[\"wdl.file_train\"])\n",
    "test_file = os.path.basename(params[\"wdl.file_test\"])\n",
    "ckpt_file = os.path.basename(params[\"wdl.file_ckpt\"])\n",
    "dir_output = params[\"wdl.dir_output\"]\n",
    "\n",
    "dir_output = os.path.join(\"NEW_ARCHIVE\", dir_output)\n",
    "\n",
    "# create output directionry if it does nto exists\n",
    "try:\n",
    "    os.mkdir(dir_output)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Save input_json_file to output dir\n",
    "json_param_file = os.path.join(dir_output, \"parameters.json\")\n",
    "save_dict_as_json(params,json_param_file)\n",
    "\n",
    "# checks\n",
    "assert os.path.isfile(train_file)\n",
    "assert os.path.isfile(test_file)\n",
    "assert os.path.isfile(ckpt_file)\n",
    "    \n",
    "print(train_file)\n",
    "print(test_file)\n",
    "print(dir_output)\n",
    "print(json_param_file)\n",
    "print(ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"get the data\")\n",
    "#train_file=\"multi_disk_train_shading_bg_v3.pkl\"\n",
    "#test_file=\"multi_disk_test_shading_bg_v3.pkl\"\n",
    "#multi_mnist_test_no_bg.pkl\n",
    "\n",
    "#train_file=\"multi_mnist_train_simple_v3.pkl\"\n",
    "#test_file=\"multi_mnist_test_simple_v3.pkl\"\n",
    "\n",
    "##train_file=\"multi_disk_train_shading_bg.pkl\"\n",
    "##test_file=\"multi_disk_test_shading_bg.pkl\"\n",
    "\n",
    "#x_train, y_train = load_obj(train_file)\n",
    "#train_loader = LoaderInMemory(x=x_train, \n",
    "#                              y=y_train, \n",
    "#                              pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "#                              batch_size=params[\"simulation\"][\"batch_size\"],  \n",
    "#                              shuffle=True)\n",
    "#                               \n",
    "#x_test, y_test = load_obj(train_file)\n",
    "#test_loader = LoaderInMemory(x=x_test, \n",
    "#                             y=y_test, \n",
    "#                             pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "#                             batch_size=params[\"simulation\"][\"batch_size\"],  \n",
    "#                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIELDS -> ('img', 'roi_mask', 'bbox_original', 'bbox_crop')\n",
      "DEBUG -> torch.Size([1, 1, 2688, 2482]) torch.float32 tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from MODULES.namedtuple import PreProcess, ImageBbox\n",
    "preprocessed = torch.load(train_file)\n",
    "print(\"FIELDS ->\", preprocessed._fields)\n",
    "\n",
    "my_min = torch.min(preprocessed.img)\n",
    "my_max = torch.max(preprocessed.img)\n",
    "my_shape = preprocessed.img.shape\n",
    "my_dtype = preprocessed.img.dtype\n",
    "                   \n",
    "print(\"DEBUG ->\",my_shape, my_dtype, my_min, my_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed images and convert to float torch in (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = preprocessed.img.float()\n",
    "roi_mask_torch = preprocessed.roi_mask.bool()\n",
    "assert len(img_torch.shape) == len(roi_mask_torch.shape) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 #params[\"simulation\"][\"batch_size\"]\n",
    "testdata_size = 128\n",
    "traindata_size = 1280\n",
    "\n",
    "random_crop = RandomCrop(desired_w=80, desired_h=80, min_roi_fraction=0.8)\n",
    "#testdata = random_crop(img_torch.expand(testdata_size,-1,-1,-1), roi_mask_torch.expand(testdata_size,-1,-1,-1))\n",
    "#\n",
    "#test_loader = LoaderInMemory(img=testdata, \n",
    "#                             roi_mask=None, \n",
    "#                             labels=None,\n",
    "#                             expand_batch_size=None,\n",
    "#                             data_augmentation=None, \n",
    "#                             pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "#                             batch_size=BATCH_SIZE, \n",
    "#                             drop_last=False, \n",
    "#                             shuffle=False)\n",
    "\n",
    "train_loader = LoaderInMemory(img=img_torch, \n",
    "                              roi_mask=roi_mask_torch, \n",
    "                              labels=None,\n",
    "                              expand_batch_size_factor=traindata_size,\n",
    "                              data_augmentation=random_crop, \n",
    "                              pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              drop_last=False, \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.check_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader.check_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_json_as_dict(json_param_file)\n",
    "\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = CompositionalVae(params)\n",
    "optimizer = instantiate_optimizer(model=vae, dict_params_optimizer=params[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the UNET resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in, labels, index = test_loader.load(batch_size=4)\n",
    "imgs_out = vae.inference_and_generator.unet.show_grid(imgs_in)\n",
    "\n",
    "print(\"imgs_in.shape, imgs_out.shape\", imgs_in.shape, imgs_out.shape)\n",
    "\n",
    "show_batch(imgs_out[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the vae architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the untrained generator match the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "generated_data = vae.generate(imgs_in=imgs_in, draw_boxes=True)\n",
    "tmp = torch.cat((imgs_in.expand(-1,3,-1,-1),generated_data.imgs[:4].expand(-1,3,-1,-1)), dim=0)\n",
    "print(tmp.shape)\n",
    "show_batch(tmp, title=\"data AND generated imgs\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(generated_data.inference.p_map, n_padding=2, title=\"generated probability\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.dict_soft_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=torch.linspace(0,1,100)\n",
    "y1=sample_from_constraints_dict(dict_soft_constraints=vae.dict_soft_constraints,\n",
    "                                var_name=\"overlap\", \n",
    "                                var_value=x1, \n",
    "                                verbose=False)\n",
    "plt.plot(x1,y1, label=\"overlap\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=torch.linspace(0,400,100)\n",
    "y1=sample_from_constraints_dict(dict_soft_constraints=vae.dict_soft_constraints,\n",
    "                                var_name=\"mask_volume_absolute\", \n",
    "                                var_value=x1, \n",
    "                                verbose=False)\n",
    "plt.plot(x1,y1, label=\"mask_volume_absolute\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are 3 possible simulation types: scratch, resumed, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"simulation type = \"+str(params[\"simulation\"][\"type\"]))\n",
    "\n",
    "    \n",
    "if (params[\"simulation\"][\"type\"] == \"scratch\"):\n",
    "    \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"resume\"):\n",
    "    \n",
    "    \n",
    "    #resumed = file2resumed(path=ckpt_file, device=None)\n",
    "    resumed = file2resumed(path=ckpt_file, device='cpu')\n",
    "        \n",
    "    load_model_optimizer(resumed=resumed,  \n",
    "                         model=vae,\n",
    "                         optimizer=optimizer,\n",
    "                         overwrite_member_var=True)\n",
    "    \n",
    "    ckp = load_info(resumed=resumed, \n",
    "                    load_epoch=True, \n",
    "                    load_history=True)\n",
    "    \n",
    "    epoch_restart = ckp.epoch\n",
    "    history_dict = ckp.history_dict\n",
    "    min_test_loss = min(history_dict[\"test_loss\"])\n",
    "    \n",
    "    \n",
    "elif (params[\"simulation\"][\"type\"] == \"pretrained\"):\n",
    "    \n",
    "    resumed = file2resumed(path=ckpt_file, device=None)\n",
    "    # resumed = file2resumed(path=ckpt_file, device='cpu')\n",
    "        \n",
    "    load_model_optimizer(resumed=resumed,  \n",
    "                         model=vae,\n",
    "                         optimizer=None,\n",
    "                         overwrite_member_var=False)\n",
    "       \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"simulation type is NOT recognized\")\n",
    "    \n",
    "# instantiate the scheduler if necessary    \n",
    "if params[\"optimizer\"][\"scheduler_is_active\"]:\n",
    "    scheduler = instantiate_scheduler(optimizer=optimizer, dict_params_scheduler=params[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.geco_dict = params[\"GECO_loss\"]\n",
    "print(vae.geco_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = params[\"simulation\"][\"TEST_FREQUENCY\"]\n",
    "CHECKPOINT_FREQUENCY = params[\"simulation\"][\"CHECKPOINT_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"simulation\"][\"MAX_EPOCHS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart    \n",
    "    \n",
    "    vae.prob_corr_factor=linear_interpolation(epoch, \n",
    "                                              values=params[\"shortcut_prob_corr_factor\"][\"values\"],\n",
    "                                              times=params[\"shortcut_prob_corr_factor\"][\"times\"])\n",
    "        \n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "    #with torch.autograd.set_detect_anomaly(False):\n",
    "        with torch.enable_grad():\n",
    "            vae.train()\n",
    "            train_metrics = process_one_epoch(model=vae, \n",
    "                                              dataloader=train_loader, \n",
    "                                              optimizer=optimizer, \n",
    "                                              verbose=(epoch==0), \n",
    "                                              weight_clipper=None)\n",
    "        with torch.no_grad():        \n",
    "            s = pretty_print_metrics(epoch, train_metrics, is_train=True)\n",
    "            print(s,\"prob_factor=%.4f\" %(vae.prob_corr_factor))\n",
    "            \n",
    "            history_dict = append_dict_to_dict(source=train_metrics, \n",
    "                                               target=history_dict,\n",
    "                                               prefix_exclude=\"wrong_examples\",\n",
    "                                               prefix_to_add=\"train_\")\n",
    "        \n",
    "    if params[\"optimizer\"][\"scheduler_is_active\"]:\n",
    "        scheduler.step()\n",
    "    \n",
    "    if(epoch % TEST_FREQUENCY == 0):\n",
    "        with torch.no_grad():\n",
    "            vae.eval()\n",
    "            test_metrics = process_one_epoch(model=vae, \n",
    "                                             dataloader=test_loader, \n",
    "                                             optimizer=optimizer, \n",
    "                                             verbose=(epoch==0), \n",
    "                                             weight_clipper=None)\n",
    "        \n",
    "            s = pretty_print_metrics(epoch, test_metrics, is_train=False)\n",
    "            print(s,\"prob_factor %.4f\" %(vae.prob_corr_factor))\n",
    "        \n",
    "            history_dict = append_dict_to_dict(source=train_metrics, \n",
    "                                               target=history_dict,\n",
    "                                               prefix_exclude=\"wrong_examples\",\n",
    "                                               prefix_to_add=\"test_\")\n",
    "        \n",
    "            test_loss = test_metrics[\"loss\"]\n",
    "            min_test_loss = min(min_test_loss, test_loss)\n",
    "            \n",
    "            if((test_loss == min_test_loss) or ((epoch % CHECKPOINT_FREQUENCY) == 0)): \n",
    "                checkpoint_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "                history_file = os.path.join(dir_output, \"history_\"+str(epoch)+\".pkl\")\n",
    "            \n",
    "                save_everything(model=vae, \n",
    "                                optimizer=optimizer, \n",
    "                                history_dict=history_dict, \n",
    "                                epoch=epoch, \n",
    "                                hyperparams_dict=params, \n",
    "                                path=checkpoint_file)\n",
    "            \n",
    "                save_dict_as_json(history_dict, path=history_file)\n",
    "                print(\"saved files -> \"+checkpoint_file+\"  \"+history_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_metrics\n",
    "# history_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test generator after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in_tmp, labels, index = train_loader.load(batch_size=3)\n",
    "auch = vae.generate(imgs_in=imgs_in_tmp[:1], draw_boxes=True)\n",
    "\n",
    "pmap_gen = show_batch(auch.inference.p_map[:8], title=\"generated p_map\")\n",
    "imgs_gen = show_batch(auch.imgs[:8], title=\"generated imgs\")\n",
    "display(pmap_gen, imgs_gen)\n",
    "\n",
    "big_mask = auch.inference.big_mask[:,0]\n",
    "big_img = auch.inference.big_img[:,0]\n",
    "tmp = torch.cat((big_mask, big_img),dim=0)\n",
    "show_batch(tmp, n_col=tmp.shape[0]//2, title=\"masks and imgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check segmentation WITHOUT tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in,labels,index = test_loader.load(batch_size=8)\n",
    "segmentation = vae.segment(imgs_in)\n",
    "print(segmentation.integer_mask.shape, segmentation.similarity.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(segmentation.raw_image[:,0].cpu(), figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(segmentation.integer_mask[:,0].cpu(), figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(segmentation.fg_prob[:,0].cpu(), figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check segmentation WITH tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.eval()\n",
    "# img_to_segment = train_loader.img[0,:,800:1100,800:1100]\n",
    "img_to_segment = train_loader.img[0] \n",
    "#img_to_segment = train_loader.img[0,:,1000:1100,1000:1100]\n",
    "#img_to_segment = img_to_segment[:,60:,:40]\n",
    "tiling = vae.segment_with_tiling(single_img=img_to_segment,\n",
    "                                 crop_size=(80,80),\n",
    "                                 stride=(10,10),\n",
    "                                 n_objects_max_per_patch=None,\n",
    "                                 prob_corr_factor=None,\n",
    "                                 overlap_threshold=None,\n",
    "                                 radius_nn=5,\n",
    "                                 batch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tiling._fields)\n",
    "for fld in tiling._fields:\n",
    "    if isinstance(getattr(tiling, fld),torch.Tensor):\n",
    "        print(fld, getattr(tiling, fld).shape)\n",
    "    else:\n",
    "        print(fld,type(getattr(tiling, fld)))\n",
    "        \n",
    "print(tiling.similarity._fields)\n",
    "print(tiling.similarity.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_file = os.path.join(dir_output, \"NEW_tiling_aug5_radius5.pt\")\n",
    "#mask_file = \"/Users/ldalessi/DAPI_unsupervised/spacetx-research/TILING_AUG/NEW_tiling_Aug5_radius5.pt\" \n",
    "\n",
    "torch.save(tiling, mask_file)\n",
    "print(mask_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(ncols=4, figsize=(24,24))\n",
    "axes[0].imshow(tiling.raw_image[0,0].cpu())\n",
    "axes[1].imshow(tiling.integer_mask[0,0].cpu())\n",
    "axes[2].imshow(tiling.fg_prob[0,0].cpu())\n",
    "axes[3].imshow(tiling.similarity.data[0,0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(ncols=2, nrows=2, figsize=(12,12))\n",
    "axes[0,0].imshow(skimage.color.label2rgb(tiling.integer_mask[0,0].cpu().numpy(),\n",
    "                                         numpy.zeros_like(tiling.integer_mask[0,0].cpu().numpy()),\n",
    "                                         alpha=1.0,\n",
    "                                         bg_label=0))\n",
    "axes[0,1].imshow(skimage.color.label2rgb(tiling.integer_mask[0,0].cpu().numpy(),\n",
    "                                         tiling.raw_image[0,0].cpu().numpy(),\n",
    "                                         alpha=0.25,\n",
    "                                         bg_label=0))\n",
    "axes[1,0].imshow(tiling.raw_image[0,0].cpu().numpy(), cmap='gray')\n",
    "axes[1,1].imshow(tiling.similarity.data[0,0].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_mask = vae.segment_with_tiling(train_loader.x[...,2000:2400,2000:2400], \n",
    "#                                   crop_w=80, crop_h=80, \n",
    "#                                   stride_w=60, stride_h=60, n_objects_max_per_patch=10)\n",
    "\n",
    "img_in,labels,index = test_loader.load(batch_size=8)\n",
    "segmentation = vae.segment(img_in)\n",
    "print(segmentation._fields)\n",
    "\n",
    "vae.eval()\n",
    "output_test = vae.forward(img_in,\n",
    "                          draw_image=True,\n",
    "                          draw_boxes=True,\n",
    "                          verbose=False)\n",
    "\n",
    "print(img_in.shape, segmentation.integer_mask.shape, output_test.imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test.inference.prob[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(output_test.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=1\n",
    "figure, axes = plt.subplots(ncols=3, figsize=(24, 24))\n",
    "axes[0].imshow(img_in[chosen,0].cpu(), cmap='gray')\n",
    "axes[1].imshow(skimage.color.label2rgb(skimage.img_as_ubyte(segmentation.integer_mask[chosen,0].cpu()), img_in[chosen,0].cpu(), alpha=0.25, bg_label=0))\n",
    "axes[2].imshow(output_test.imgs[chosen,0].cpu(), cmap='hot')\n",
    "axes[0].set_title(\"input image\")\n",
    "axes[1].set_title(\"segmentation mask\")\n",
    "axes[2].set_title(\"reconstructed image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    if k.startswith(\"train\"):\n",
    "        print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), \n",
    "         sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), \n",
    "         sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('LOSS = - ELBO')\n",
    "plt.title('Training procedure')\n",
    "#plt.ylim(ymax=4, ymin=0)\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test'])\n",
    "#plt.show()\n",
    "\n",
    "fig_file = os.path.join(dir_output, \"train.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(history_dict[\"train_length_GP\"])), history_dict[\"train_length_GP\"], '-', label=\"train\")\n",
    "plt.plot(np.arange(0,len(history_dict[\"test_length_GP\"])*TEST_FREQUENCY,TEST_FREQUENCY), history_dict[\"test_length_GP\"], 'x', label=\"test\")\n",
    "plt.title('LENGTH GP')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('lenght_GP')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "fig_file = os.path.join(dir_output, \"lenght_GP.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('fg fraction av', color=color)\n",
    "ax1.plot(np.arange(0, len(history_dict[\"train_fg_fraction\"])),\n",
    "         history_dict[\"train_fg_fraction\"], 'o', color=color, label=\"train\")\n",
    "ax1.plot(np.arange(0, len(history_dict[\"test_fg_fraction\"])*TEST_FREQUENCY, TEST_FREQUENCY),\n",
    "         history_dict[\"test_fg_fraction\"], 'x-', color=color, label=\"test\")\n",
    "\n",
    "ymin=min(params[\"GECO_loss\"][\"target_fg_fraction\"])\n",
    "ymax=max(params[\"GECO_loss\"][\"target_fg_fraction\"])\n",
    "ax1.plot(ymin*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_min\")\n",
    "ax1.plot(ymax*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_max\")\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid()\n",
    "#ax1.set_ylim([1000,1870])\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(np.arange(0, len(history_dict[\"train_accuracy\"])),\n",
    "         history_dict[\"train_accuracy\"],'x', color=color)\n",
    "ax2.plot(np.arange(0, len(history_dict[\"test_accuracy\"])*TEST_FREQUENCY, TEST_FREQUENCY),\n",
    "         history_dict[\"test_accuracy\"],'-', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid()\n",
    "#ax2.set_ylim([0.97,1.0])\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"accuracy.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20,20))\n",
    "ax = f.add_subplot(321)\n",
    "ax2 = f.add_subplot(322)\n",
    "ax3 = f.add_subplot(323)\n",
    "ax4 = f.add_subplot(324)\n",
    "ax5 = f.add_subplot(325)\n",
    "ax6 = f.add_subplot(326)\n",
    "epoch_min, epoch_max = 200, None\n",
    "\n",
    "\n",
    "loss = np.array(history_dict[\"train_loss\"])\n",
    "kl_instance = np.array(history_dict[\"train_kl_instance\"])\n",
    "kl_where = np.array(history_dict[\"train_kl_where\"])\n",
    "kl_logit = np.array(history_dict[\"train_kl_logit\"])\n",
    "kl_raw = np.array(history_dict[\"train_kl_tot\"])\n",
    "mse_raw = np.array(history_dict[\"train_mse\"])\n",
    "reg_raw = np.array(history_dict[\"train_reg\"])\n",
    "sparsity_raw = np.array(history_dict[\"train_sparsity\"])\n",
    "overlap_raw = np.array(history_dict[\"train_cost_overlap\"])\n",
    "f_geco_sparsity = np.array(history_dict[\"train_geco_sparsity\"])\n",
    "f_geco_balance = np.array(history_dict[\"train_geco_balance\"])\n",
    "\n",
    "\n",
    "ax.plot(sparsity_raw,'-',label='sparsity_raw')\n",
    "ax.plot(overlap_raw,'-',label='cost overlap raw')\n",
    "ax.set_xlim([epoch_min, epoch_max])\n",
    "ax.set_ylim([None, 1.01*max(max(sparsity_raw[epoch_min:epoch_max]), max(overlap_raw[epoch_min:epoch_max]))])\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "ax2.plot(kl_instance,'-',label='kl instance raw')\n",
    "ax2.plot(kl_where,'-',label='kl zwhere raw')\n",
    "ax2.set_xlim([epoch_min, epoch_max])\n",
    "ax2.set_ylim([0, 1.01*max(max(kl_instance[epoch_min:epoch_max]),max(kl_where[epoch_min:epoch_max]))])\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(kl_logit,'-',label='kl logit raw')\n",
    "#ax3.set_ylim([0,1.1])\n",
    "ax3.set_xlim([epoch_min, epoch_max])\n",
    "ax3.set_ylim([None, 1.01*max(kl_logit[epoch_min:epoch_max])])\n",
    "ax3.grid()\n",
    "ax3.legend()\n",
    "\n",
    "\n",
    "ax4.plot(f_geco_sparsity ,'x-',label='geco_sparsity')\n",
    "#ax4.set_ylim([0,100])\n",
    "ax4.set_xlim([epoch_min, epoch_max])\n",
    "ax4.set_ylim([None, 1.01*max(f_geco_sparsity[epoch_min:epoch_max])])\n",
    "ax4.grid()\n",
    "ax4.legend()\n",
    "\n",
    "ax5.plot(f_geco_balance ,'x-',label='geco_balance')\n",
    "ax5.set_xlim([epoch_min, epoch_max])\n",
    "ax5.set_ylim([None, 1.01*max(f_geco_balance[epoch_min:epoch_max])])\n",
    "ax5.grid()\n",
    "ax5.legend()\n",
    "\n",
    "ax6.plot(loss,'-',label='loss')\n",
    "ax6.plot(f_geco_sparsity * sparsity_raw,'x-',label='scaled_sparsity')\n",
    "ax6.plot(f_geco_balance * reg_raw,'x-',label='scaled_reg')\n",
    "ax6.plot(f_geco_balance * mse_raw,'x-',label='scaled_mse')\n",
    "ax6.plot((1-f_geco_balance) * kl_raw,'x-',label='scaled_kl')\n",
    "ax6.set_ylim([0, 1.01*max(loss[epoch_min:epoch_max])])\n",
    "ax6.set_xlim([epoch_min, epoch_max])\n",
    "ax6.grid()\n",
    "ax6.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"metrics.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"GECO_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=20\n",
    "labelsize=20\n",
    "f = plt.figure(figsize=(20,20))\n",
    "ax1 = f.add_subplot(311)\n",
    "ax2 = f.add_subplot(312)\n",
    "ax3 = f.add_subplot(313)\n",
    "epoch_min, epoch_max = 0, None\n",
    "\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax1.set_ylabel('fg_fraction', fontsize=fontsize, color=color)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax1.plot(history_dict[\"train_fg_fraction\"], '.--', color=color, label=\"n_object\")\n",
    "ax1.set_xlim([epoch_min, epoch_max])\n",
    "ymin=min(params[\"GECO_loss\"]['target_fg_fraction'])\n",
    "ymax=max(params[\"GECO_loss\"]['target_fg_fraction'])\n",
    "ax1.plot(ymin*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_min\")\n",
    "ax1.plot(ymax*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_max\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid()\n",
    "\n",
    "ax1b = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax1b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax1b.set_ylabel('geco_sparsity', color=color, fontsize=fontsize)\n",
    "ax1b.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "plt.plot(history_dict[\"train_geco_sparsity\"],'-',label=\"geco_sparsity\",color=color)\n",
    "ax1b.tick_params(axis='y', labelcolor=color)\n",
    "ax1b.grid()\n",
    "\n",
    "##------------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax2.set_ylabel('mse av', fontsize=fontsize, color=color)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2.plot(history_dict[\"train_mse\"], '.--', color=color, label=\"mse av\")\n",
    "ax2.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "ymin=min(params[\"GECO_loss\"][\"target_mse\"])\n",
    "ymax=max(params[\"GECO_loss\"][\"target_mse\"])\n",
    "ax2.plot(ymin*np.ones(len(history_dict[\"train_mse\"])), '-', color='black', label=\"y_min\")\n",
    "ax2.plot(ymax*np.ones(len(history_dict[\"train_mse\"])), '-', color='black', label=\"y_max\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2.grid()\n",
    "\n",
    "ax2b = ax2.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax2b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax2b.set_ylabel('geco_balance', fontsize=fontsize, color=color)\n",
    "plt.plot(history_dict[\"train_geco_balance\"],'-',label=\"geco_balance\",color=color)\n",
    "ax2b.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2b.tick_params(axis='y', labelcolor=color)\n",
    "ax2b.grid()\n",
    "\n",
    "##------------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax3.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax3.set_ylabel('delta_1', fontsize=fontsize, color=color)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3.plot(history_dict[\"train_delta_1\"], '.--', color=color, label=\"delta_1\")\n",
    "ax3.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "\n",
    "ax3b = ax3.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax3b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax3b.set_ylabel('delta_2', fontsize=fontsize, color=color)\n",
    "plt.plot(history_dict[\"train_delta_2\"],'-',label=\"delta_2\",color=color)\n",
    "ax3b.tick_params(axis='y', labelcolor=color)\n",
    "ax3b.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3b.grid()\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"geco.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "epoch_min, epoch_max = 200, None\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_mse\"][epoch_min:epoch_max])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "f = plt.figure(figsize=(20,10))\n",
    "ax1 = f.add_subplot(221)\n",
    "ax2 = f.add_subplot(222)\n",
    "ax3 = f.add_subplot(223)\n",
    "ax4 = f.add_subplot(224, projection='3d')\n",
    "\n",
    "ax1.set_xlabel('MSE',fontsize=fontsize)\n",
    "ax1.set_ylabel('KL',fontsize=fontsize)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax1.scatter(history_dict[\"train_mse\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max],c=colors)\n",
    "ax1.plot(history_dict[\"train_mse\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], '--')\n",
    "ax1.grid()\n",
    "#ax1.set_xlim(xmax=2.5)\n",
    "\n",
    "ax2.set_xlabel('SPARSITY',fontsize=fontsize)\n",
    "ax2.set_ylabel('MSE',fontsize=fontsize)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2.scatter(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_mse\"][epoch_min:epoch_max], c=colors)\n",
    "ax2.plot(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_mse\"][epoch_min:epoch_max], '--')\n",
    "ax2.grid()\n",
    "#ax2.set_xlim(xmax=2.5)\n",
    "\n",
    "ax3.set_xlabel('SPARSITY',fontsize=fontsize)\n",
    "ax3.set_ylabel('KL',fontsize=fontsize)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3.scatter(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], c=colors)\n",
    "ax3.plot(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], '--')\n",
    "ax3.grid()\n",
    "#ax3.set_xlim(xmax=2.5)\n",
    "\n",
    "\n",
    "ax4.scatter(history_dict[\"train_kl_tot\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_sparsity\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_mse\"][epoch_min:epoch_max], c=colors )\n",
    "\n",
    "ax4.plot(history_dict[\"train_kl_tot\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_sparsity\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_mse\"][epoch_min:epoch_max], '--', label='training')\n",
    "ax4.set_xlabel('kl_tot', fontsize=fontsize)\n",
    "ax4.set_ylabel('sparsity', fontsize=fontsize)\n",
    "ax4.set_zlabel('mse', fontsize=fontsize)\n",
    "ax4.legend(prop={'size':fontsize})\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"nll_vs_kll_vs_sparsity.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run one epoch in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch=100\n",
    "#load_model_optimizer(path=os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\"), model=vae)\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    test_metrics = process_one_epoch(model=vae, \n",
    "                                     dataloader=test_loader)\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_pkl = os.path.join(dir_output, \"reference.pkl\")\n",
    "tmp_list = [0, 1, 2,3,4,5,6,7,8,9]\n",
    "#tmp_list = [255, 148, 291, 310, 2,3,4,5,6,7,8,9,10]\n",
    "#tmp_list = [425, 411, 61, 194, 91, 384, 339, 54, 336]\n",
    "\n",
    "reference_imgs, labels, index =test_loader.load(index=torch.tensor(tmp_list[:9]))\n",
    "save_obj(reference_imgs, ref_img_pkl)\n",
    "\n",
    "reference_imgs = load_obj(ref_img_pkl)\n",
    "b = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "\n",
    "ref_img_png = os.path.join(dir_output, \"reference.png\")\n",
    "b.savefig(ref_img_png)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.geco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=0\n",
    "with torch.no_grad():\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"--- eval mode ---\")\n",
    "    vae.eval()\n",
    "    output_test = vae.forward(reference_imgs[:],\n",
    "                              draw_image=True,\n",
    "                              draw_boxes=True,\n",
    "                              verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"--- train mode ---\")\n",
    "    vae.train()\n",
    "    output_train = vae.forward(reference_imgs[:],\n",
    "                               draw_image=True,\n",
    "                               draw_boxes=True,\n",
    "                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap_train = show_batch(output_train.inference.p_map, n_col=3,n_padding=4,title=\"Train Prob MAP\")\n",
    "pmap_test = show_batch(output_test.inference.p_map, n_col=3,n_padding=4,title=\"Test Prob MAP\")\n",
    "\n",
    "counts_train = torch.sum(output_train.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "rec_train = show_batch(output_train.imgs[:],n_col=3,n_padding=4,title=\"# rec train \"+str(counts_train))\n",
    "\n",
    "counts_test = torch.sum(output_test.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "rec_test = show_batch(output_test.imgs[:],n_col=3,n_padding=4,title=\"# rec test \"+str(counts_test))\n",
    "\n",
    "background = show_batch(output_train.inference.big_bg,n_col=3,n_padding=4,title=\"BACKGROUND\")\n",
    "reference = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "\n",
    "background.savefig(os.path.join(dir_output, \"background.png\"))\n",
    "reference.savefig(os.path.join(dir_output, \"reference.png\"))\n",
    "rec_test.savefig(os.path.join(dir_output, \"rec_test.png\"))\n",
    "rec_train.savefig(os.path.join(dir_output, \"rec_train.png\"))\n",
    "pmap_test.savefig(os.path.join(dir_output, \"pmap_test.png\"))\n",
    "pmap_train.savefig(os.path.join(dir_output, \"pmap_train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(background, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_train.inference.p_map.sum(dim=(-1,-2,-3)).cpu())\n",
    "print(output_test.inference.p_map.sum(dim=(-1,-2,-3)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec_train,reference)\n",
    "display(rec_test,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pmap_train,reference)\n",
    "display(pmap_test,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_train.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "print(torch.topk(output_train.inference.p_map[chosen,0].view(-1), k=10, largest=True, sorted=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_test.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "print(torch.topk(output_test.inference.p_map[chosen,0].view(-1), k=10, largest=True, sorted=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(output_train.inference.p_map[0,0].view(-1).cpu().numpy(), density=True, bins=50, label=\"pmap_train\")\n",
    "_ = plt.hist(output_test.inference.p_map[0,0].view(-1).cpu().numpy(), density=True, bins=50, label=\"pmap_test\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(dir_output, \"hist_pmap.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize one chosen image in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_train\n",
    "how_many_to_show=20\n",
    "counts = torch.sum(output.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "prob_tmp = np.round(output.inference.prob[:how_many_to_show,chosen].view(-1).cpu().numpy(),decimals=4)*10000\n",
    "prob_title = (prob_tmp.astype(int)/10000).tolist()\n",
    "print(\"counts ->\",counts[chosen],\" prob ->\",prob_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = reference_imgs[chosen]\n",
    "tmp2 = torch.sum(output.inference.big_img[:how_many_to_show,chosen],dim=0)\n",
    "tmp3 = torch.sum(output.inference.big_mask[:how_many_to_show,chosen],dim=0)\n",
    "mask_times_imgs = output.inference.big_mask * output.inference.big_img\n",
    "tmp4 = torch.sum(mask_times_imgs[:how_many_to_show,chosen],dim=0)\n",
    "print(\"sum big_masks\", torch.max(tmp3))\n",
    "print(\"sum big_masks * big_imgs\", torch.max(tmp4))\n",
    "combined = torch.stack((tmp1,tmp2,tmp3,tmp4),dim=0)\n",
    "print(combined.shape)\n",
    "b = show_batch(combined, n_col=2, title=\"# ref, IMGS, MASKS, IMGS*MASKS\", figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"ref_img_mask.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(output.inference.big_mask[:how_many_to_show,chosen]), torch.max(output.inference.big_mask[:how_many_to_show,chosen]))\n",
    "show_batch(output.inference.big_mask[:how_many_to_show,chosen], n_col=4, title=\"# MASKS\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = show_batch(reference_imgs[chosen]+output.inference.big_mask[:how_many_to_show,chosen], \n",
    "               n_col=3, n_padding=4,title=\"# MASKS over REF, p=\"+str(prob_title), figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"mask_over_ref.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = show_batch(reference_imgs[chosen]+10*output.inference.big_img[:how_many_to_show,chosen], \n",
    "               n_col=4, n_padding=4,title=\"# IMGS over REF, p=\"+str(prob_title), figsize=(24,24), normalize_range=(0,1))\n",
    "b.savefig(os.path.join(dir_output, \"imgs_over_ref.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.inference.prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob =  output.inference.prob[:,chosen, None, None, None]\n",
    "b_mask = output.inference.big_mask[:,chosen]\n",
    "b_img = output.inference.big_img[:,chosen]\n",
    "b_combined = b_img * b_mask * prob\n",
    "tmp = torch.cat((b_mask, b_img, b_combined), dim=0)\n",
    "b = show_batch(tmp, n_col=tmp.shape[0]//3, n_padding=4, title=\"# mask, imgs, product. p=\"+str(prob_title), figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"mask_imgs_product.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(output.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "plt.savefig(os.path.join(dir_output, \"pmap_chosen.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "a = show_batch(reference_imgs[:9],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "b = show_batch(output.inference.p_map[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "c = show_batch(output.inference.big_bg[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "d = show_batch(output.imgs[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "\n",
    "display(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_output = '/home/jupyter/REPOS/spacetx-research/NEW_ARCHIVE/merfish_aug_5_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,5000,5):\n",
    "    if(epoch<10):\n",
    "        label =\"0000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"000\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"00\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = \"0\"+str(epoch)\n",
    "    elif(epoch<100000):\n",
    "        label = str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        ckpt_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "        resumed = file2resumed(path=ckpt_file, device=None)\n",
    "        load_model_optimizer(resumed=resumed, \n",
    "                             model=vae,\n",
    "                             optimizer=None,\n",
    "                             overwrite_member_var=True)\n",
    "        \n",
    "        print(\"epoch, label, prob_cor_factor ->\",epoch,label,vae.prob_corr_factor)\n",
    "        vae.train()\n",
    "        with torch.no_grad():\n",
    "            output = vae.forward(reference_imgs,\n",
    "                                 draw_image=True,\n",
    "                                 draw_boxes=True,\n",
    "                                 verbose=False)\n",
    "        \n",
    "        b=show_batch(output.imgs[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        b.savefig(os.path.join(dir_output, 'movie_rec_'+label+'.png'), bbox_inches='tight')\n",
    "        \n",
    "        b=show_batch(output.inference.p_map[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch), normalize_range=None)\n",
    "        b.savefig(os.path.join(dir_output, 'movie_map_'+label+'.png'), bbox_inches='tight') \n",
    "        \n",
    "        b=show_batch(output.inference.big_bg[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        b.savefig(os.path.join(dir_output, 'movie_bg_'+label+'.png'), bbox_inches='tight') \n",
    "        \n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sorted list of image files so that I can create the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filenames = glob.glob(dir_output+\"/movie_rec*.png\")\n",
    "map_filenames = glob.glob(dir_output+\"/movie_map*.png\")\n",
    "bg_filenames = glob.glob(dir_output+\"/movie_bg*.png\")\n",
    "\n",
    "rec_filenames.sort()\n",
    "map_filenames.sort()\n",
    "bg_filenames.sort()\n",
    "print(rec_filenames)\n",
    "print(map_filenames)\n",
    "print(bg_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    return Image(filename=rec_filenames[n])\n",
    "\n",
    "def show_frame_map(n):\n",
    "    return Image(filename=map_filenames[n])\n",
    "\n",
    "def show_frame_bg(n):\n",
    "    return display.Image(filename=bg_filenames[n])\n",
    "\n",
    "def show_frame_all(n):\n",
    "    try:\n",
    "        a = Image(filename=bg_filenames[n])\n",
    "        b = Image(filename=map_filenames[n])\n",
    "        c = Image(filename=rec_filenames[n])\n",
    "        return display(a,b,c)\n",
    "    except IndexError:\n",
    "        print(\"list index out of range\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gif file\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "movie_rec = os.path.join(dir_output, \"movie_rec.gif\")\n",
    "movie_map = os.path.join(dir_output, \"movie_map.gif\")\n",
    "movie_bg = os.path.join(dir_output, \"movie_bg.gif\")\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec, fps=frame_per_second)\n",
    "\n",
    "im = mpy.ImageSequenceClip(map_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_map, fps=frame_per_second)\n",
    "\n",
    "im = mpy.ImageSequenceClip(bg_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_bg, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_map+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_bg+\"></img>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at few frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CHECK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in_tmp, labels, index = train_loader.load(batch_size=8)\n",
    "auch = vae.generate(imgs_in=imgs_in_tmp[:1], draw_boxes=False)\n",
    "\n",
    "pmap_gen = show_batch(auch.inference.p_map[:8], title=\"generated p_map\")\n",
    "imgs_gen = show_batch(auch.imgs[:8], title=\"generated imgs\")\n",
    "display(pmap_gen, imgs_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_mask = auch.inference.big_mask[:,0]\n",
    "big_img = auch.inference.big_img[:,0]\n",
    "tmp = torch.cat((big_mask, big_img),dim=0)\n",
    "print(auch.inference.prob)\n",
    "show_batch(tmp, n_col=tmp.shape[0]//2, title=\"masks and imgs\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auch.inference.big_mask.shape)\n",
    "fg_mask = torch.sum(auch.inference.big_mask, dim=0)\n",
    "img = torch.sum(auch.inference.big_img, dim=0)\n",
    "print(fg_mask.shape)\n",
    "\n",
    "figure, axes = plt.subplots(ncols=3, figsize=(24, 24))\n",
    "axes[0].imshow(fg_mask[0,0].cpu(), cmap='gray')\n",
    "axes[1].imshow(img[0,0].cpu(), cmap='gray')\n",
    "axes[2].imshow((fg_mask[0,0]*img[0,0]).cpu(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
