{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI DAPI VAE in PYRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as mp\n",
    "\n",
    "from LOW_LEVEL_UTILITIES.utilities import show_batch, save_obj, load_obj, dataset_in_memory, check_datasets\n",
    "from LOW_LEVEL_UTILITIES.utilities import train_one_epoch, evaluate_one_epoch, test_model, linear_decay_p_factor\n",
    "from simulation_dictionary import SimulationDictionary \n",
    "from VAE.vae_model import Compositional_VAE\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, TraceGraph_ELBO, config_enumerate, JitTraceEnum_ELBO \n",
    "from pyro.optim import Adam, Adamax, SGD, RMSprop\n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disk_data_dir = \"/home/ldalessi/DATA/MULTI_DISK/\"\n",
    "#real_data_dir = \"/home/ldalessi/DATA/DAPI_ONLY_v3/\"\n",
    "#real_data_dir = \"/Users/ldalessi/DAPI_unsupervised/DATA/DAPI_ONLY_v3/\"\n",
    "#mMNIST_data_dir = \"/Users/ldalessi/DAPI_unsupervised/DATA/MULTI_MNIST/\"   \n",
    "real_data_dir = \"/home/jupyter/REPOS/spacetx-research/DATA/REAL_DAPI_V4/\"\n",
    "#mMNIST_data_dir = \"/home/ldalessi/DATA/MULTI_MNIST/\"\n",
    "#mMNIST_data_dir = \"/home/jupyter/REPOS/spacetx-research/DATA/MULTI_MNIST/\"\n",
    "#fashion_data_dir = \"/home/jupyter/REPOS/spacetx-research/DATA/MULTI_FashionMNIST/\"\n",
    "#real_data_dir = \"/home/ldalessi/DATA/DAPI_ONLY_v4/\"\n",
    "#real_data_dir = \"/home/jupyter/REPOS/spacetx-research/DATA/REAL_DAPI_V4/\"\n",
    "\n",
    "train_dataset = dataset_in_memory(real_data_dir,\"DAPI_dataset_train\",use_cuda=torch.cuda.is_available())\n",
    "test_dataset  = dataset_in_memory(real_data_dir,\"DAPI_dataset_test\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(fashion_data_dir,\"multi_Fashionmnist_train_large_hard\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(fashion_data_dir,\"multi_Fashionmnist_test_large_hard\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_train_large\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_test_large\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(disk_data_dir,\"multi_disk_train_v1\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(disk_data_dir,\"multi_disk_test_v1\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(disk_data_dir,\"multi_disk_train_no_bg\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(disk_data_dir,\"multi_disk_test_no_bg\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(real_data_dir,\"DAPI_dataset_train\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(real_data_dir,\"DAPI_dataset_test\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_train_large\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_test_large\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_train_with_bg\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_test_with_bg\",use_cuda=torch.cuda.is_available())\n",
    "\n",
    "#train_dataset = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_train_no_bg\",use_cuda=torch.cuda.is_available())\n",
    "#test_dataset  = dataset_in_memory(mMNIST_data_dir,\"multi_mnist_test_no_bg\",use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_datasets(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_datasets(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in, labels = train_dataset.load(8)\n",
    "print(labels[0])\n",
    "show_batch(imgs_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(imgs_in[2:-1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(imgs_in[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(imgs_in[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = plt.hist(imgs_in.view(-1).cpu().numpy(), bins=50, range=(0,1),density=True)\n",
    "plt.title(\"Empirical PDF\")\n",
    "plt.xlabel(\"pixel intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=15\n",
    "r = test_dataset.analyze_brightness_distribution(size=size,stride=3)\n",
    "a = plt.hist(r.view(-1), bins=100, range=(0,1),density=True)\n",
    "plt.title(\"Empirical PDF\")\n",
    "plt.xlabel(\"Average intensity in box of size \"+str(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=35\n",
    "r = test_dataset.analyze_brightness_distribution(size=size,stride=3)\n",
    "a = plt.hist(r.view(-1), bins=100, range=(0,1),density=True)\n",
    "plt.title(\"Empirical PDF\")\n",
    "plt.xlabel(\"Average intensity in box of size \"+str(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir  = '/home/jupyter/REPOS/spacetx-research/ARCHIVE/'\n",
    "#write_dir  = '/home/ldalessi/REPOS/spacetx-research/ARCHIVE/'\n",
    "#write_dir  = '/home/ldalessi/buckets/VAE-ARCHIVE/'\n",
    "#write_dir  = '/Users/ldalessi/DAPI_unsupervised/ARCHIVE/'\n",
    "\n",
    "\n",
    "descriptor        = \"DAPI_branch11_v03\"\n",
    "#descriptor        = \"MNIST_v001\"\n",
    "#descriptor        = \"FASHION_unit_cauchy_t4_v3\"\n",
    "#descriptor        = \"MNIST_unit_cauchy_t4_v4\"\n",
    "#descriptor        = \"DISK_v4\"\n",
    "#descriptor        = \"DISK_speed\"\n",
    "name_vae          = descriptor+\"_vae\"\n",
    "name_history      = descriptor+\"_hystory\"\n",
    "name_hyper_params = descriptor+\"_hyper_params\"\n",
    "epoch_restart     = 0\n",
    "is_restart = False\n",
    "is_pretrained = False\n",
    "\n",
    "if(is_restart):\n",
    "\n",
    "    hyper_params = load_obj(write_dir,name_hyper_params+\"_\"+str(epoch_restart))\n",
    "    hyper_params.check_consistency()\n",
    "    print(hyper_params)\n",
    "    history_dict = load_obj(write_dir,name_history+\"_\"+str(epoch_restart))\n",
    "    min_loss = min(history_dict[\"test_loss\"])\n",
    "    vae = Compositional_VAE.load(hyper_params,write_dir,name_vae+\"_\"+str(epoch_restart))\n",
    "\n",
    "else:    \n",
    "    \n",
    "    epoch_restart     = -1\n",
    "    hyper_params=SimulationDictionary()\n",
    "    hyper_params.check_consistency()\n",
    "    print(hyper_params)\n",
    "    \n",
    "    min_loss = 99999999\n",
    "    history_dict = {\n",
    "        \"train_loss\" : [],\n",
    "        \"test_loss\" : [],\n",
    "        \n",
    "        \"fg_mu\" : [],\n",
    "        \"bg_mu\" : [],\n",
    "        \"fg_sigma\" : [],\n",
    "        \"bg_sigma\" : [],\n",
    "        }\n",
    "    \n",
    "    vae = Compositional_VAE(hyper_params)\n",
    "    vae.reset()\n",
    "    if(is_pretrained):\n",
    "        vae.load_everything(\"/home/jupyter/REPOS/spacetx-research/ARCHIVE/GREAT_RESULT/\",\"DAPI\")\n",
    "    \n",
    "save_obj(hyper_params,write_dir,name_hyper_params+\"_write_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(imgs_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.inference.unet.describe_receptive_field(imgs_in)\n",
    "img_with_grid = vae.inference.unet.show_grid(imgs_in)\n",
    "print(img_with_grid.shape)\n",
    "show_batch(img_with_grid[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putative_imgs,putative_masks,background,c = vae.model()\n",
    "#print(\"putative_imgs.shape\",putative_imgs.shape)\n",
    "#print(\"putative_masks.shape\",putative_masks.shape)\n",
    "#print(\"background.shape\",background.shape)\n",
    "#print(\"c.shape\",c.shape)\n",
    "#print(\"max(putative_imgs)\",torch.max(putative_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(putative_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(putative_masks[0])\n",
    "#print(torch.min(putative_masks),torch.max(putative_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_prior = vae.generate_synthetic_data(N=2)\n",
    "#show_batch(imgs_prior[:8,:1,:,:])\n",
    "#print(\"imgs_prior.shape\",imgs_prior.shape)\n",
    "#print(\"type(imgs_prior)\",type(imgs_prior))\n",
    "#print(\"imgs_prior.device\",imgs_prior.device)\n",
    "#print(\"torch.max(imgs_prior)\",torch.max(imgs_prior))\n",
    "#print(\"torch.min(imgs_prior)\",torch.min(imgs_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putative_imgs,putative_masks,background,c = vae.model(imgs_prior.cuda())\n",
    "##putative_imgs,pixel_weights,background,c = vae.model(imgs_prior)\n",
    "#\n",
    "#print(\"putative_imgs.shape\",putative_imgs.shape)\n",
    "#print(\"putative_masks.shape\",putative_masks.shape)\n",
    "#print(\"background.shape\",background.shape)\n",
    "#print(\"c.shape\",c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rec_img,z_where,putative_imgs,putative_masks,logp,reg = vae.reconstruct_img(imgs_prior,True)\n",
    "#\n",
    "#print(\"rec_img.shape\",rec_img.shape)\n",
    "#print(\"min, max of rec_img)\",torch.min(rec_img),torch.max(rec_img))\n",
    "#print(\"putative_imgs.shape\",putative_imgs.shape)\n",
    "#print(\"putative_masks.shape\",putative_masks.shape)\n",
    "#print(\"logp.logp_off.shape\",logp.logp_off.shape)\n",
    "#print(\"logp.logp_on_cauchy.shape\",logp.logp_on_cauchy.shape)\n",
    "#print(\"logp.logp_on_normal.shape\",logp.logp_on_normal.shape)\n",
    "#print(\"reg.small_box_size.shape\",reg.small_box_size.shape)\n",
    "#print(\"reg.big_mask_volume.shape\",reg.big_mask_volume.shape)\n",
    "#print(\"reg.tot_var_mask.shape\",reg.tot_var_mask.shape)\n",
    "#print(\"reg.overlap_mask.shape\",reg.overlap_mask.shape)\n",
    "#show_batch(rec_img[:8,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug model and guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"TEST SAMPLE\")\n",
    "#test_model(vae.model, \n",
    "#           vae.guide, TraceGraph_ELBO())\n",
    "#\n",
    "#print(\"TEST PARALLEL ENUM\")\n",
    "#test_model(vae.model, \n",
    "#           config_enumerate(vae.guide, \"parallel\"), \n",
    "#           TraceEnum_ELBO(max_plate_nesting=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = 5\n",
    "WRITE_FREQUENCY = 5\n",
    "smoke_test= False\n",
    "if(smoke_test):\n",
    "    pyro.enable_validation(False)\n",
    "    pyro.distributions.enable_validation(True)\n",
    "    NUM_EPOCHS = 6 \n",
    "else:\n",
    "    pyro.enable_validation(False)\n",
    "    pyro.distributions.enable_validation(False)\n",
    "    NUM_EPOCHS = 101\n",
    "    \n",
    "# batch size\n",
    "batch_size = 50\n",
    "time_scale_decay_prob = 40\n",
    "\n",
    "# setup the optimizer\n",
    "optimizer = Adam({\"lr\": 1.0e-3, \"betas\":(0.9, 0.999)})\n",
    "#optimizer = RMSprop({\"lr\": 1.0e-4})\n",
    "\n",
    "svi = SVI(vae.model, config_enumerate(vae.guide, \"parallel\"), optimizer, loss=TraceEnum_ELBO(max_plate_nesting=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "#epoch_restart = 45\n",
    "#for delta_epoch in range(1,-1):\n",
    "\n",
    "for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart\n",
    "   \n",
    "    \n",
    "    vae.inference.nms.overlap_threshold=0.2\n",
    "    vae.p_corr_factor = linear_decay_p_factor(epoch,time_scale_decay_prob)\n",
    "    vae.randomize_nms_factor = 0.1\n",
    "    vae.n_objects_max=30\n",
    "    vae.train()   \n",
    "    \n",
    "    \n",
    "    print(\"epoch,vae.p_corr_factor,vae.randomize_nms_factor\",epoch,vae.p_corr_factor,vae.randomize_nms_factor)\n",
    "    loss = train_one_epoch(svi, train_dataset, epoch, batch_size, verbose=(delta_epoch==1))\n",
    "    print(\"[epoch %03d] train loss: %.4f\" % (epoch, loss))\n",
    "                \n",
    "    history_dict[\"train_loss\"].append(loss)\n",
    "    try:\n",
    "        history_dict[\"fg_mu\"].append(pyro.param(\"fg_mu\").item())\n",
    "        history_dict[\"bg_mu\"].append(pyro.param(\"bg_mu\").item())\n",
    "        history_dict[\"fg_sigma\"].append(pyro.param(\"fg_sigma\").item())\n",
    "        history_dict[\"bg_sigma\"].append(pyro.param(\"bg_sigma\").item())\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    if(epoch % TEST_FREQUENCY == 0):      \n",
    "        vae.inference.nms.overlap_threshold=0.2\n",
    "        vae.randomize_nms_factor = 0.0\n",
    "        vae.p_corr_factor = 0.0\n",
    "        vae.n_objects_max=30\n",
    "        vae.eval()\n",
    "            \n",
    "        loss = evaluate_one_epoch(svi, test_dataset, epoch, batch_size, verbose=(delta_epoch==1))        \n",
    "        history_dict[\"test_loss\"].append(loss)\n",
    "            \n",
    "        if(loss < min_loss):\n",
    "            min_loss = loss\n",
    "            print(\"[epoch %03d] test  loss: %.4f --New Record--\" % (epoch, loss)) \n",
    "        else:\n",
    "            print(\"[epoch %03d] test  loss: %.4f \" % (epoch, loss))\n",
    "                \n",
    "        if((loss == min_loss) or ((epoch % WRITE_FREQUENCY) == 0)):   \n",
    "            # Save on disk\n",
    "            vae.save_everything(write_dir,name_vae+\"_\"+str(epoch))\n",
    "            save_obj(history_dict,write_dir,name_history+\"_\"+str(epoch))\n",
    "            save_obj(hyper_params,write_dir,name_hyper_params+\"_\"+str(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_dict[\"train_loss\"][-5:])\n",
    "print(history_dict[\"test_loss\"][-5:])\n",
    "\n",
    "print(history_dict[\"fg_mu\"][-5:])\n",
    "print(history_dict[\"bg_mu\"][-5:])\n",
    "\n",
    "print(history_dict[\"fg_sigma\"][-5:])\n",
    "print(history_dict[\"bg_sigma\"][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign =1.0\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), sign*np.array(history_dict[\"train_loss\"])+y_shift)\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"]), TEST_FREQUENCY), sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('LOSS = - ELBO')\n",
    "plt.title('Training procedure')\n",
    "#plt.ylim(ymin = -10000, ymax=-4000)\n",
    "#plt.ylim(bottom=-250000, top=200000)\n",
    "#plt.ylim(bottom=-250000, top=0)\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test'])\n",
    "#plt.show()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.savefig(write_dir+name_vae+'_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot with learned parameters\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "plt.xlabel('epoch',fontsize=fontsize)\n",
    "plt.ylabel('parameters bg fg',fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "\n",
    "plt.plot(history_dict[\"fg_mu\"],'.')\n",
    "plt.plot(history_dict[\"bg_mu\"],'.')\n",
    "\n",
    "plt.plot(history_dict[\"fg_sigma\"],'-')\n",
    "plt.plot(history_dict[\"bg_sigma\"],'-')\n",
    "\n",
    "plt.legend(['fg_mu','bg_mu',\n",
    "            'fg_sigma','bg_sigma'])\n",
    "plt.grid(True)\n",
    "              \n",
    "mp.savefig(write_dir+name_vae+'_hystory.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as mp\n",
    "\n",
    "#reference_dir = '/Users/ldalessi/DAPI_unsupervised/REFERENCES/'\n",
    "#reference_dir = '/home/ldalessi/DATA/REFERENCE/'\n",
    "reference_dir = '/home/jupyter/REPOS/spacetx-research/DATA/REFERENCES/'\n",
    "#name='reference_mMNIST_v2'\n",
    "#name='reference_disks_v3'\n",
    "name='reference_dapi'\n",
    "#name='reference_fashion'\n",
    "\n",
    "# create image if necessary\n",
    "#reference_imgs, labels=test_dataset.load(8)\n",
    "#save_obj(reference_imgs ,reference_dir,name)\n",
    "\n",
    "reference_imgs = load_obj(reference_dir,name)\n",
    "show_batch(reference_imgs[:8],nrow=4,npadding=4,title=\"REFERENCE\")\n",
    "mp.savefig(write_dir+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.p_corr_factor = 0.0\n",
    "vae.randomize_nms_factor = 0.0\n",
    "vae.inference.nms.overlap_threshold=0.4\n",
    "vae.n_objects_max=30\n",
    "\n",
    "rec_img,z_where,putative_imgs,putative_masks,logp,reg = vae.reconstruct_img(reference_imgs,True)\n",
    "counts = torch.sum(z_where.prob>0.5,dim=1).view(-1).cpu().numpy().tolist(),\n",
    "b=show_batch(rec_img[:8],nrow=4,npadding=4,title=\"# COUNTS= \"+str(counts))\n",
    "mp.savefig(write_dir+name_vae+'_rec_both.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=7\n",
    "print(z_where.prob[chosen].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tmp = np.round(z_where.prob[chosen].view(-1).cpu().numpy(),decimals=4)*10000\n",
    "prob_title = (prob_tmp.astype(int)/10000).tolist()\n",
    "prob_title = 0\n",
    "b=show_batch(putative_imgs[chosen],nrow=4,npadding=4,title=\"# IMGS, p=\"+str(prob_title))\n",
    "mp.savefig(write_dir+name_vae+'_rec_imgs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(putative_masks[0,0,0].cpu())\n",
    "print(putative_masks[0,0,0,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=show_batch(putative_masks[chosen],nrow=4,npadding=4,title=\"# MASKS, p=\"+str(prob_title))\n",
    "print(name_vae)\n",
    "mp.savefig(write_dir+name_vae+'_rec_masks.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = (z_where.prob[chosen] > 0.5)[...,None,None].float()\n",
    "show_batch(torch.sum(active*putative_masks[chosen],dim=0,keepdim=True)+2*reference_imgs[chosen])\n",
    "mp.savefig(write_dir+name_vae+'_debug0_imgs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[chosen:chosen+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(putative_masks[chosen]+reference_imgs[chosen,0])\n",
    "mp.savefig(write_dir+name_vae+'_debug1_imgs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = rec_img[chosen].unsqueeze(0)\n",
    "tmp2 = reference_imgs[chosen].unsqueeze(0).expand(-1,3,-1,-1)\n",
    "tmp = torch.cat((tmp1,tmp2),dim=0)\n",
    "show_batch(tmp)\n",
    "mp.savefig(write_dir+name_vae+'_debug2_imgs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"reg_small_box ----->\",vae.lambda_small_box_size*reg.small_box_size[chosen,:16].detach().cpu())\n",
    "print(\"reg_mask_fraction ->\",vae.lambda_mask_volume_fraction*reg.mask_volume_fraction[chosen,:16].detach().cpu())\n",
    "print(\"reg_mask_absolute ->\",vae.lambda_mask_volume_absolute*reg.mask_volume_absolute[chosen,:16].detach().cpu())\n",
    "print(\"reg_tot_var ------->\",vae.lambda_tot_var_mask*reg.tot_var_mask[chosen,:16].detach().cpu())\n",
    "print(\"reg_mask_overlap -->\",vae.lambda_overlap*reg.overlap_mask[chosen,:16].detach().cpu())\n",
    "print(\"mask_volumes ------>\",torch.sum(putative_masks[chosen,:16],dim=(-2,-1)).view(-1))\n",
    "print(\"probability object >\",z_where.prob[chosen,:16].detach().cpu().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"logp_off -------->\",logp.logp_off[chosen,:16].detach().cpu())\n",
    "print(\"logp_on_cauchy -->\",logp.logp_on_cauchy[chosen,:16].detach().cpu())\n",
    "print(\"logp_on_normal -->\",logp.logp_on_normal[chosen,:16].detach().cpu())\n",
    "print(\"probability object\",z_where.prob[chosen,:16].detach().cpu().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off=logp.logp_off.view(-1).detach().cpu().numpy()\n",
    "on_c=logp.logp_on_cauchy.view(-1).detach().cpu().numpy()\n",
    "on_n=logp.logp_on_normal.view(-1).detach().cpu().numpy()\n",
    "a1 = plt.hist([off,on_c,on_n],bins=20,histtype=\"bar\",stacked=True)\n",
    "plt.legend([\"logp_off\",\"logp_on_cauchy\",\"logp_on_normal\"], loc='upper right')\n",
    "plt.title(\"Distribution of the three log_probs\")\n",
    "plt.xlabel(\"Log prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_movie_files = []\n",
    "for epoch in range(0,125,5):\n",
    "    if(epoch<10):\n",
    "        label =\"_000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"_00\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"_0\"+str(epoch)\n",
    "    else:\n",
    "        label = str(epoch)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        vae.load_everything(write_dir,name_vae+\"_\"+str(epoch))\n",
    "        vae.p_corr_factor = linear_decay_p_factor(epoch,time_scale_decay_prob)\n",
    "        print(label,vae.p_corr_factor)\n",
    "        rec_img,z_where,putative_imgs,putative_masks,logp,reg = vae.reconstruct_img(reference_imgs,True)\n",
    "        counts = torch.sum(z_where.prob>0.5,dim=1).view(-1).cpu().numpy().tolist()\n",
    "        b=show_batch(rec_img[:8],nrow=4,npadding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        name_output = name_vae+label+'.png'\n",
    "        list_of_movie_files.append(name_output)\n",
    "        mp.savefig(write_dir+name_output) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(list_of_movie_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_img,z_where,putative_imgs,putative_masks,logp,reg = vae.reconstruct_img(reference_imgs,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipywidgets import interactive, IntSlider\n",
    "#from PIL import Image\n",
    "from IPython.display import Image\n",
    "\n",
    "def show_frame(n):\n",
    "    return Image(filename=write_dir+list_of_movie_files[n])  \n",
    "    #image = Image.open(write_dir+list_of_movie_files[n], mode='r')\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()    \n",
    "\n",
    "# Widget does not work\n",
    "#interactive_plot = interactive(show_frame,n=IntSlider(min=0, max=N_frames-1, step=1))\n",
    "#output = interactive_plot.children[-1]\n",
    "#interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_dir  = '/home/jupyter/REPOS/spacetx-research/ARCHIVE/'\n",
    "#name_vae = \"MNIST_unit_cauchy_t4_v2_vae_0\"\n",
    "#list_of_movie_files = []\n",
    "#for file in os.listdir(write_dir):\n",
    "#    if file.startswith(name_vae) and file.endswith(\".png\"):\n",
    "#        list_of_movie_files.append(file)\n",
    "N_frames = len(list_of_movie_files)\n",
    "print(list_of_movie_files)\n",
    "print(N_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],nrow=4,npadding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
