{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI DAPI VAE in PYRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "#! conda update -y pytorch torchvision -c pytorch\n",
    "#! pip install pyro-ppl --upgrade\n",
    "# pip install --upgrade Pillow\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML, Image\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (utilities.py, line 367)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-8293161a1a9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from MODULES.utilities import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/jupyter/REPOS/spacetx-research/MODULES/utilities.py\"\u001b[0;36m, line \u001b[0;32m367\u001b[0m\n\u001b[0;31m    if self.fg_mask is None or\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from MODULES.utilities import *\n",
    "from MODULES.vae_model import *\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "#from pyro.infer import SVI, Trace_ELBO #,TraceEnum_ELBO, TraceGraph_ELBO, config_enumerate, JitTraceEnum_ELBO \n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "# Check versions\n",
    "print(\"pyro.__version__  --> \",pyro.__version__)\n",
    "print(\"torch.__version__ --> \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(pyro.__version__.startswith('1.3'))\n",
    "#assert(torch.__version__.startswith('1.4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We expect to find the file \"parameters.json\" in the execution directoryÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = load_json_as_dict(\"parameters.json\")\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROMWELL will localize: \n",
    "# gs://ld-data-bucket/data/fashionmnist_train.pkl -> execution_dir/ld-data-bucket/data/fashionmnist_train.pkl\n",
    "# Therefore I just need to remove  \"gs://\"\n",
    "# Note that every path is relative to the execution_dir\n",
    "\n",
    "train_file = os.path.basename(params[\"wdl.file_train\"])\n",
    "test_file = os.path.basename(params[\"wdl.file_test\"])\n",
    "ckpt_file = os.path.basename(params[\"wdl.file_ckpt\"])\n",
    "dir_output = params[\"wdl.dir_output\"]\n",
    "\n",
    "# create output directionry if it does nto exists\n",
    "try:\n",
    "    os.mkdir(dir_output)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Save input_json_file to output dir\n",
    "json_param_file = os.path.join(dir_output, \"parameters.json\")\n",
    "save_dict_as_json(params,json_param_file)\n",
    "\n",
    "# checks\n",
    "assert os.path.isfile(train_file)\n",
    "assert os.path.isfile(test_file)\n",
    "assert os.path.isfile(ckpt_file)\n",
    "    \n",
    "print(train_file)\n",
    "print(test_file)\n",
    "print(dir_output)\n",
    "print(json_param_file)\n",
    "print(ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"get the data\")\n",
    "#train_file=\"multi_disk_train_shading_bg_v3.pkl\"\n",
    "#test_file=\"multi_disk_test_shading_bg_v3.pkl\"\n",
    "#multi_mnist_test_no_bg.pkl\n",
    "\n",
    "#train_file=\"multi_mnist_train_simple_v3.pkl\"\n",
    "#test_file=\"multi_mnist_test_simple_v3.pkl\"\n",
    "\n",
    "##train_file=\"multi_disk_train_shading_bg.pkl\"\n",
    "##test_file=\"multi_disk_test_shading_bg.pkl\"\n",
    "\n",
    "#x_train, y_train = load_obj(train_file)\n",
    "#train_loader = LoaderInMemory(x=x_train, \n",
    "#                              y=y_train, \n",
    "#                              pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "#                              batch_size=params[\"simulation\"][\"batch_size\"],  \n",
    "#                              shuffle=True)\n",
    "#                               \n",
    "#x_test, y_test = load_obj(train_file)\n",
    "#test_loader = LoaderInMemory(x=x_test, \n",
    "#                             y=y_test, \n",
    "#                             pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "#                             batch_size=params[\"simulation\"][\"batch_size\"],  \n",
    "#                             shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL DATASETS: Import image and preproces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "from MODULES.preprocessing import img_pre_processing, sum_in_windows\n",
    "\n",
    "pilfile = PIL.Image.open(train_file)\n",
    "img_preprocessed = img_pre_processing(pilfile, reduction_factor=8, remove_background=True)\n",
    "fg_mask = img_preprocessed>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive = skimage.exposure.equalize_adapthist(img_preprocessed, kernel_size=80, clip_limit=0.03)\n",
    "gamma = skimage.exposure.adjust_gamma(img_preprocessed, gamma=0.5, gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 80\n",
    "while 1>0:\n",
    "    iw = torch.randint(low=0, high=img_preprocessed.shape[-2]-delta, size=[1])\n",
    "    ih = torch.randint(low=0, high=img_preprocessed.shape[-1]-delta, size=[1])\n",
    "    if(np.sum(fg_mask[iw:iw+delta,ih:ih+delta])>0):\n",
    "        break\n",
    "print(iw,ih)\n",
    "\n",
    "figure, axes = plt.subplots(ncols=4, nrows=4, figsize=(24, 24))\n",
    "axes[0,0].imshow(img_preprocessed, cmap='gray')\n",
    "axes[0,1].imshow(adaptive, cmap='gray')\n",
    "axes[0,2].imshow(gamma, cmap='gray')\n",
    "axes[0,3].imshow(fg_mask, cmap='gray')\n",
    "\n",
    "axes[1,0].hist(img_preprocessed.flatten(), bins=50, density=True)\n",
    "axes[1,1].hist(adaptive.flatten(), bins=50, density=True)\n",
    "axes[1,2].hist(gamma.flatten(), bins=50, density=True)\n",
    "\n",
    "axes[2,0].hist(img_preprocessed[fg_mask].flatten(), bins=50, density=True)\n",
    "axes[2,1].hist(adaptive[fg_mask].flatten(), bins=50, density=True)\n",
    "axes[2,2].hist(gamma[fg_mask].flatten(), bins=50, density=True)\n",
    "\n",
    "axes[3,0].imshow(img_preprocessed[iw:iw+delta, ih:ih+delta], cmap='gray')\n",
    "axes[3,1].imshow(adaptive[iw:iw+delta, ih:ih+delta], cmap='gray')\n",
    "axes[3,2].imshow(gamma[iw:iw+delta, ih:ih+delta], cmap='gray')\n",
    "axes[3,3].imshow(fg_mask[iw:iw+delta, ih:ih+delta], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = torch.from_numpy(adaptive).float()[None,None]\n",
    "fg_mask_torch = torch.from_numpy(fg_mask)[None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = params[\"simulation\"][\"batch_size\"]\n",
    "random_crops_test = ManyRandomCropsTensor(desired_w=80, desired_h=80, n_crops=2000, \n",
    "                                          fg_mask=fg_mask_torch, fg_fraction_threshold=0.1)\n",
    "random_crops_train = ManyRandomCropsTensor(desired_w=80, desired_h=80, n_crops=BATCH_SIZE, \n",
    "                                           fg_mask=fg_mask_torch, fg_fraction_threshold=0.1)\n",
    "\n",
    "train_loader = LoaderInMemory(x=img_torch, \n",
    "                              y=None, \n",
    "                              data_augmentation=random_crops_train, \n",
    "                              transform_y=False, \n",
    "                              pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "                              batch_size=1, \n",
    "                              drop_last=False, \n",
    "                              shuffle=True)\n",
    "\n",
    "test_loader = LoaderInMemory(x=random_crops_test(img_torch), \n",
    "                              y=None, \n",
    "                              data_augmentation=None, \n",
    "                              transform_y=False, \n",
    "                              pin_in_cuda_memory=torch.cuda.is_available(),\n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              drop_last=False, \n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader.check_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.check_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate the regularizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the value for fg_fraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_test_dataset = (test_loader.x > 0.1).float()\n",
    "show_batch(binarized_test_dataset[:8], figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_pixel_fraction = binarized_test_dataset.mean(dim=(-1,-2,-3))\n",
    "print(torch.min(fg_pixel_fraction))\n",
    "\n",
    "figure, axes = plt.subplots(figsize=(24, 6))\n",
    "axes.hist(fg_pixel_fraction.cpu(), bins=50)\n",
    "axes.set_xlabel(\"fg_pixel_fraction\")\n",
    "axes.set_ylabel(\"PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_loader.x\n",
    "print(\"img.shape ->\",img.shape)\n",
    "avg = torch.mean(img, dim=(-1,-2,-3), keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=0.02\n",
    "MSE_avg = torch.mean(((img-avg)/sigma).pow(2), dim=(-1,-2,-3))\n",
    "print(torch.min(MSE_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize=(24, 6))\n",
    "axes.hist(MSE_avg.cpu(), bins=50)\n",
    "axes.set_xlabel(\"MSE_avg\")\n",
    "axes.set_ylabel(\"PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = CompositionalVae(params)\n",
    "optimizer = instantiate_optimizer(model=vae, dict_params_optimizer=params[\"optimizer\"])\n",
    "#vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the untrained generator match the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,index = train_loader.load(batch_size=1)\n",
    "print(x.shape, y.shape, index.shape)\n",
    "show_batch(x[:8], n_col=4, n_padding=4, pad_value=1, title=\"sample of training data\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auch = vae.generate(imgs_in=x, draw_bounding_box=True)\n",
    "show_batch(auch.imgs[:8]+x[:8], title=\"generated imgs and data\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_mask = auch.inference.big_mask[:,0]\n",
    "big_img = auch.inference.big_img[:,0]\n",
    "tmp = torch.cat((big_mask, big_img),dim=0)\n",
    "show_batch(tmp, n_col=tmp.shape[0]//2, title=\"masks and imgs\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the segmentation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,index = test_loader.load(batch_size=8)\n",
    "seg_mask = vae.segment(x, draw_bounding_box=True)\n",
    "\n",
    "print(x.shape,seg_mask.shape)\n",
    "plt.imshow(seg_mask[0,0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_loader.x.shape)\n",
    "#seg_mask = vae.segment_with_tiling(train_loader.x, crop_w=80, crop_h=80, stride_w=60, stride_h=60, n_objects_max_per_patch=None, draw_bounding_box=True)\n",
    "\n",
    "#print(seg_mask.shape)\n",
    "#plt.imshow(seg_mask[0,0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.dict_soft_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=torch.linspace(0,1,100)\n",
    "y1=sample_from_constraints_dict(dict_soft_constraints=vae.dict_soft_constraints,\n",
    "                                var_name=\"overlap\", \n",
    "                                var_value=x1, \n",
    "                                verbose=False)\n",
    "plt.plot(x1,y1, label=\"overlap\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.linspace(0,0.75,100)\n",
    "y=sample_from_constraints_dict(dict_soft_constraints=vae.dict_soft_constraints,\n",
    "                               var_name=\"fg_pixel_fraction\", \n",
    "                               var_value=x, \n",
    "                               verbose=False)\n",
    "plt.plot(x, y, label=\"fg_pixel_fraction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are 3 possible simulation types: scratch, resumed, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"simulation type = \"+str(params[\"simulation\"][\"type\"]))\n",
    "\n",
    "if (params[\"simulation\"][\"type\"] == \"scratch\"):\n",
    "    \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"resumed\"):\n",
    "        \n",
    "    resumed = load_info(path=ckpt_file, \n",
    "                        load_epoch=True, \n",
    "                        load_history=True)\n",
    "    epoch_restart = resumed.epoch\n",
    "    history_dict = resumed.history_dict\n",
    "    min_test_loss = min(history_dict[\"test_loss\"])\n",
    "    \n",
    "    load_model_optimizer(path=ckpt_file, \n",
    "                         model=vae,\n",
    "                         optimizer=optimizer)\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"pretrained\"):\n",
    "       \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "    \n",
    "    load_model_optimizer(path=ckpt_file, \n",
    "                         model=vae,\n",
    "                         optimizer=None)\n",
    "    \n",
    "# instantiate the scheduler if necessary    \n",
    "if params[\"optimizer\"][\"scheduler_is_active\"]:\n",
    "    scheduler = instantiate_scheduler(optimizer=optimizer, dict_params_scheduler=params[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = params[\"simulation\"][\"TEST_FREQUENCY\"]\n",
    "CHECKPOINT_FREQUENCY = params[\"simulation\"][\"CHECKPOINT_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"simulation\"][\"MAX_EPOCHS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart    \n",
    "    \n",
    "    ## vae.is_geco_selftuning = False\n",
    "    ## vae.geco_mu_detached = linear_interpolation(epoch, \n",
    "    ##                                             values=[0.95,0.5],\n",
    "    ##                                             times=[100,500])\n",
    "    \n",
    "    vae.prob_corr_factor=linear_interpolation(epoch, \n",
    "                                              values=params[\"shortcut_prob_corr_factor\"][\"values\"],\n",
    "                                              times=params[\"shortcut_prob_corr_factor\"][\"times\"])\n",
    "        \n",
    "    #with torch.autograd.set_detect_anomaly(True):\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        vae.train()\n",
    "        with torch.enable_grad():\n",
    "            train_metrics = process_one_epoch(model=vae, \n",
    "                                              dataloader=train_loader, \n",
    "                                              optimizer=optimizer, \n",
    "                                              verbose=(epoch==0), \n",
    "                                              weight_clipper=None)\n",
    "        with torch.no_grad():        \n",
    "            s = pretty_print_metrics(epoch, train_metrics, is_train=True)\n",
    "            print(s,\"prob_factor=%.4f\" %(vae.prob_corr_factor))\n",
    "            \n",
    "            history_dict = append_dict_to_dict(source=train_metrics, \n",
    "                                               target=history_dict,\n",
    "                                               prefix_exclude=\"wrong_examples\",\n",
    "                                               prefix_to_add=\"train_\")\n",
    "        \n",
    "    if params[\"optimizer\"][\"scheduler_is_active\"]:\n",
    "        scheduler.step(epoch=epoch)\n",
    "    \n",
    "    if(epoch % TEST_FREQUENCY == 0):\n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            test_metrics = process_one_epoch(model=vae, \n",
    "                                             dataloader=test_loader, \n",
    "                                             optimizer=optimizer, \n",
    "                                             verbose=(epoch==0), \n",
    "                                             weight_clipper=None)\n",
    "        \n",
    "            s = pretty_print_metrics(epoch, test_metrics, is_train=False)\n",
    "            print(s,\"prob_factor %.4f\" %(vae.prob_corr_factor))\n",
    "        \n",
    "            history_dict = append_dict_to_dict(source=train_metrics, \n",
    "                                               target=history_dict,\n",
    "                                               prefix_exclude=\"wrong_examples\",\n",
    "                                               prefix_to_add=\"test_\")\n",
    "        \n",
    "            test_loss = test_metrics[\"loss\"]\n",
    "            min_test_loss = min(min_test_loss, test_loss)\n",
    "            \n",
    "            if((test_loss == min_test_loss) or ((epoch % CHECKPOINT_FREQUENCY) == 0)): \n",
    "                checkpoint_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "                history_file = os.path.join(dir_output, \"history_\"+str(epoch)+\".pkl\")\n",
    "            \n",
    "                save_everything(model=vae, \n",
    "                                optimizer=optimizer, \n",
    "                                history_dict=history_dict, \n",
    "                                epoch=epoch, \n",
    "                                hyperparams_dict=params, \n",
    "                                path=checkpoint_file)\n",
    "            \n",
    "                save_dict_as_json(history_dict, path=history_file)\n",
    "                print(\"saved files -> \"+checkpoint_file+\"  \"+history_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test generator after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in_tmp, labels, index = train_loader.load(batch_size=8)\n",
    "auch = vae.generate(imgs_in=imgs_in_tmp[:1], draw_bounding_box=True)\n",
    "\n",
    "pmap_gen = show_batch(auch.inference.p_map[:8], title=\"generated p_map\")\n",
    "imgs_gen = show_batch(auch.imgs[:8], title=\"generated imgs\")\n",
    "display(pmap_gen, imgs_gen)\n",
    "\n",
    "big_mask = auch.inference.big_mask[:,0]\n",
    "big_img = auch.inference.big_img[:,0]\n",
    "tmp = torch.cat((big_mask, big_img),dim=0)\n",
    "show_batch(tmp, n_col=tmp.shape[0]//2, title=\"masks and imgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_mask = vae.segment_with_tiling(train_loader.x[...,2000:2400,2000:2400], \n",
    "#                                   crop_w=80, crop_h=80, \n",
    "#                                   stride_w=60, stride_h=60, n_objects_max_per_patch=10)\n",
    "\n",
    "x,y,index = test_loader.load(batch_size=8)\n",
    "seg_mask = vae.segment(x)\n",
    "print(x.shape, seg_mask.shape)\n",
    "#show_batch(seg_mask)\n",
    "plt.imshow(seg_mask[0,0].cpu())\n",
    "#plt.imshow(x[0,0].cpu())\n",
    "    \n",
    "#figure, axes = plt.subplots(ncols=2, figsize=(24, 24))\n",
    "#axes[1].imshow(train_loader.x[0,0,2000:2400,2000:2400], cmap='gray')\n",
    "#axes[0].imshow(seg_mask[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    if k.startswith(\"train\"):\n",
    "        print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), \n",
    "         sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), \n",
    "         sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('LOSS = - ELBO')\n",
    "plt.title('Training procedure')\n",
    "#plt.ylim(ymax=2)\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test'])\n",
    "#plt.show()\n",
    "\n",
    "fig_file = os.path.join(dir_output, \"train.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('n obj av', color=color)\n",
    "ax1.plot(np.arange(0, len(history_dict[\"train_n_obj\"])),\n",
    "         history_dict[\"train_n_obj\"], 'o', color=color, label=\"train\")\n",
    "ax1.plot(np.arange(0, len(history_dict[\"test_n_obj\"])*TEST_FREQUENCY, TEST_FREQUENCY),\n",
    "         history_dict[\"test_n_obj\"], 'x-', color=color, label=\"test\")\n",
    "\n",
    "ymin=min(params[\"GECO\"][\"target_n_obj\"])\n",
    "ymax=max(params[\"GECO\"][\"target_n_obj\"])\n",
    "ax1.plot(ymin*np.ones(len(history_dict[\"train_n_obj\"])), '-', color='black', label=\"y_min\")\n",
    "ax1.plot(ymax*np.ones(len(history_dict[\"train_n_obj\"])), '-', color='black', label=\"y_max\")\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid()\n",
    "#ax1.set_ylim([1000,1870])\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(np.arange(0, len(history_dict[\"train_accuracy\"])),\n",
    "         history_dict[\"train_accuracy\"],'x', color=color)\n",
    "ax2.plot(np.arange(0, len(history_dict[\"test_accuracy\"])*TEST_FREQUENCY, TEST_FREQUENCY),\n",
    "         history_dict[\"test_accuracy\"],'-', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid()\n",
    "#ax2.set_ylim([0.97,1.0])\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"accuracy.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20,10))\n",
    "ax = f.add_subplot(221)\n",
    "ax2 = f.add_subplot(222)\n",
    "ax3 = f.add_subplot(223)\n",
    "ax4 = f.add_subplot(224)\n",
    "epoch_min, epoch_max = 0, 2500\n",
    "\n",
    "ax.plot(np.array(history_dict[\"train_sparsity\"]),'-',label='sparsity')\n",
    "#ax.set_ylim([0,10])\n",
    "ax.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "ax2.plot(np.array(history_dict[\"train_kl_what\"]),'-',label='kl zwhat')\n",
    "ax2.plot(np.array(history_dict[\"train_kl_mask\"]),'-',label='kl zmask')\n",
    "ax2.plot(np.array(history_dict[\"train_kl_where\"]),'-',label='kl zwhere')\n",
    "#ax2.plot(np.array(history_dict[\"train_kl_logit\"]),'-',label='kl logit')\n",
    "#ax2.set_ylim([0,1])\n",
    "ax2.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "#ax3.plot(history_dict[\"soft_cost_total_raw\"],'-',label='cost total')\n",
    "ax3.plot(history_dict[\"train_cost_overlap\"],'-',label='cost overlap')\n",
    "ax3.plot(history_dict[\"train_cost_fg_pixel_fraction\"],'-',label='cost fg_pixel_fraction')\n",
    "#ax3.plot(history_dict[\"train_cost_volume_mask_fraction\"],'-',label='cost volume_mask_fraction')\n",
    "#ax3.plot(history_dict[\"train_cost_prob_map_integral\"],'-',label='cost prob_map_integral')\n",
    "#ax3.plot(history_dict[\"train_cost_prob_map_fraction\"],'-',label='cost prob_map_fraction')\n",
    "#ax3.plot(history_dict[\"train_cost_prob_map_TV\"],'-',label='cost prob_map_TV')\n",
    "#ax3.plot(history_dict[\"train_reg\"],'-',label='all_reg')\n",
    "#ax3.set_ylim([0,1.1])\n",
    "ax3.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "ax3.grid()\n",
    "ax3.legend()\n",
    "\n",
    "ax4.plot(history_dict[\"train_loss\"],'-',label='loss')\n",
    "ax4.plot(np.array(history_dict[\"train_geco_sparsity\"])*np.array(history_dict[\"train_sparsity\"]),'x-',label='scaled_sparsity')\n",
    "ax4.plot(np.array(history_dict[\"train_geco_nll\"])*np.array(history_dict[\"train_nll\"]),'o-',label='scaled_nll')\n",
    "ax4.plot(history_dict[\"train_kl_tot\"],'+',label='kl_tot')\n",
    "ax4.plot(history_dict[\"train_reg\"],'.',label='reg')\n",
    "#ax4.set_ylim([0,5])\n",
    "ax4.set_xlim([epoch_min, epoch_max])\n",
    "ax4.grid()\n",
    "ax4.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"metrics.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"GECO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=20\n",
    "labelsize=20\n",
    "f = plt.figure(figsize=(20,20))\n",
    "ax1 = f.add_subplot(311)\n",
    "ax2 = f.add_subplot(312)\n",
    "ax3 = f.add_subplot(313)\n",
    "epoch_min, epoch_max = 0, 2500\n",
    "\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax1.set_ylabel('n obj av', fontsize=fontsize, color=color)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax1.plot(history_dict[\"train_n_obj\"], '.--', color=color, label=\"n_object\")\n",
    "ax1.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "\n",
    "ymin=min(params[\"GECO\"][\"target_n_obj\"])\n",
    "ymax=max(params[\"GECO\"][\"target_n_obj\"])\n",
    "ax1.plot(ymin*np.ones(len(history_dict[\"train_n_obj\"])), '-', color='black', label=\"y_min\")\n",
    "ax1.plot(ymax*np.ones(len(history_dict[\"train_n_obj\"])), '-', color='black', label=\"y_max\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid()\n",
    "\n",
    "ax1b = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax1b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax1b.set_ylabel('geco_sparsity', color=color, fontsize=fontsize)\n",
    "plt.plot(history_dict[\"train_geco_sparsity\"],'-',label=\"geco_sparsity\",color=color)\n",
    "ax1b.tick_params(axis='y', labelcolor=color)\n",
    "ax1b.grid()\n",
    "\n",
    "##------------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax2.set_ylabel('nll av', fontsize=fontsize, color=color)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2.plot(history_dict[\"train_nll\"], '.--', color=color, label=\"nll av\")\n",
    "ax2.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "ymin=min(params[\"GECO\"][\"target_nll\"])\n",
    "ymax=max(params[\"GECO\"][\"target_nll\"])\n",
    "ax2.plot(ymin*np.ones(len(history_dict[\"train_n_obj\"])), '-', color='black', label=\"y_min\")\n",
    "ax2.plot(ymax*np.ones(len(history_dict[\"train_n_obj\"])), '-', color='black', label=\"y_max\")\n",
    "\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid()\n",
    "\n",
    "ax2b = ax2.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax2b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax2b.set_ylabel('geco_nll', fontsize=fontsize, color=color)\n",
    "plt.plot(history_dict[\"train_geco_nll\"],'-',label=\"geco_nll\",color=color)\n",
    "ax2b.tick_params(axis='y', labelcolor=color)\n",
    "ax2b.grid()\n",
    "\n",
    "#---------------------------------------\n",
    "ax3.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax3.set_ylabel('delta1, delta2', fontsize=fontsize)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3.plot(history_dict[\"train_delta_1\"], 'x--', label=\"delta_1\")\n",
    "ax3.plot(history_dict[\"train_delta_2\"], 'o--', label=\"delta_2\")\n",
    "ax3.grid()\n",
    "ax3.legend()\n",
    "ax3.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "\n",
    "##------------------------------------\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"geco.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "epoch_min, epoch_max = 0, 2500\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_nll\"][epoch_min:epoch_max])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "f = plt.figure(figsize=(20,10))\n",
    "ax1 = f.add_subplot(221)\n",
    "ax2 = f.add_subplot(222)\n",
    "ax3 = f.add_subplot(223)\n",
    "ax4 = f.add_subplot(224, projection='3d')\n",
    "\n",
    "ax1.set_xlabel('NLL',fontsize=fontsize)\n",
    "ax1.set_ylabel('KL',fontsize=fontsize)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax1.scatter(history_dict[\"train_nll\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max],c=colors)\n",
    "ax1.plot(history_dict[\"train_nll\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], '--')\n",
    "ax1.grid()\n",
    "#ax1.set_xlim(xmax=2.5)\n",
    "\n",
    "ax2.set_xlabel('SPARSITY',fontsize=fontsize)\n",
    "ax2.set_ylabel('NLL',fontsize=fontsize)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2.scatter(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_nll\"][epoch_min:epoch_max], c=colors)\n",
    "ax2.plot(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_nll\"][epoch_min:epoch_max], '--')\n",
    "ax2.grid()\n",
    "ax2.set_xlim(xmax=2.5)\n",
    "\n",
    "ax3.set_xlabel('SPARSITY',fontsize=fontsize)\n",
    "ax3.set_ylabel('KL',fontsize=fontsize)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3.scatter(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], c=colors)\n",
    "ax3.plot(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], '--')\n",
    "ax3.grid()\n",
    "ax3.set_xlim(xmax=2.5)\n",
    "\n",
    "\n",
    "ax4.scatter(history_dict[\"train_kl_tot\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_sparsity\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_nll\"][epoch_min:epoch_max], c=colors )\n",
    "\n",
    "ax4.plot(history_dict[\"train_kl_tot\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_sparsity\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_nll\"][epoch_min:epoch_max], '--', label='training')\n",
    "ax4.set_xlabel('kl_tot', fontsize=fontsize)\n",
    "ax4.set_ylabel('sparsity', fontsize=fontsize)\n",
    "ax4.set_zlabel('nll', fontsize=fontsize)\n",
    "ax4.legend(prop={'size':fontsize})\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"nll_vs_kll_vs_sparsity.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run one epoch in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch=100\n",
    "#load_model_optimizer(path=os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\"), model=vae)\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    test_metrics = process_one_epoch(model=vae, \n",
    "                                     dataloader=test_loader)\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_pkl = os.path.join(dir_output, \"reference.pkl\")\n",
    "tmp_list = [0, 1, 2,3,4,5,6,7,8,9]\n",
    "#tmp_list = [255, 148, 291, 310, 2,3,4,5,6,7,8,9,10]\n",
    "#tmp_list = [425, 411, 61, 194, 91, 384, 339, 54, 336]\n",
    "\n",
    "reference_imgs, labels, index =test_loader.load(index=torch.tensor(tmp_list[:9]))\n",
    "save_obj(reference_imgs, ref_img_pkl)\n",
    "\n",
    "reference_imgs = load_obj(ref_img_pkl)\n",
    "b = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "\n",
    "ref_img_png = os.path.join(dir_output, \"reference.png\")\n",
    "b.savefig(ref_img_png)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.geco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=0\n",
    "with torch.no_grad():\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"--- eval mode ---\")\n",
    "    vae.eval()\n",
    "    output_test = vae.forward(reference_imgs[:],\n",
    "                              draw_image=True,\n",
    "                              draw_bounding_box=True,\n",
    "                              verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"--- train mode ---\")\n",
    "    vae.train()\n",
    "    output_train = vae.forward(reference_imgs[:],\n",
    "                               draw_image=True,\n",
    "                               draw_bounding_box=True,\n",
    "                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap_train = show_batch(output_train.inference.p_map, n_col=3,n_padding=4,title=\"Train Prob MAP\")\n",
    "pmap_test = show_batch(output_test.inference.p_map, n_col=3,n_padding=4,title=\"Test Prob MAP\")\n",
    "\n",
    "counts_train = torch.sum(output_train.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "rec_train = show_batch(output_train.imgs[:],n_col=3,n_padding=4,title=\"# rec train \"+str(counts_train))\n",
    "\n",
    "counts_test = torch.sum(output_test.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "rec_test = show_batch(output_test.imgs[:],n_col=3,n_padding=4,title=\"# rec test \"+str(counts_test))\n",
    "\n",
    "background = show_batch(output_train.inference.bg_mu,n_col=3,n_padding=4,title=\"BACKGROUND\")\n",
    "reference = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "\n",
    "background.savefig(os.path.join(dir_output, \"background.png\"))\n",
    "reference.savefig(os.path.join(dir_output, \"reference.png\"))\n",
    "rec_test.savefig(os.path.join(dir_output, \"rec_test.png\"))\n",
    "rec_train.savefig(os.path.join(dir_output, \"rec_train.png\"))\n",
    "pmap_test.savefig(os.path.join(dir_output, \"pmap_test.png\"))\n",
    "pmap_train.savefig(os.path.join(dir_output, \"pmap_train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(background, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_train.inference.p_map.sum(dim=(-1,-2,-3)).cpu())\n",
    "print(output_test.inference.p_map.sum(dim=(-1,-2,-3)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec_train,reference)\n",
    "display(rec_test,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pmap_train,reference)\n",
    "display(pmap_test,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_train.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "print(torch.topk(output_train.inference.p_map[chosen,0].view(-1), k=10, largest=True, sorted=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_test.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "print(torch.topk(output_test.inference.p_map[chosen,0].view(-1), k=10, largest=True, sorted=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(output_train.inference.p_map[0,0].view(-1).cpu().numpy(), density=True, bins=50, label=\"pmap_train\")\n",
    "_ = plt.hist(output_test.inference.p_map[0,0].view(-1).cpu().numpy(), density=True, bins=50, label=\"pmap_test\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(dir_output, \"hist_pmap.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize one chosen image in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_train\n",
    "how_many_to_show=20\n",
    "counts = torch.sum(output.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "prob_tmp = np.round(output.inference.prob[:how_many_to_show,chosen].view(-1).cpu().numpy(),decimals=4)*10000\n",
    "prob_title = (prob_tmp.astype(int)/10000).tolist()\n",
    "print(\"counts ->\",counts[chosen],\" prob ->\",prob_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = reference_imgs[chosen]\n",
    "tmp2 = torch.sum(output.inference.big_img[:how_many_to_show,chosen],dim=0)\n",
    "tmp3 = torch.sum(output.inference.big_mask[:how_many_to_show,chosen],dim=0)\n",
    "mask_times_imgs = output.inference.big_mask * output.inference.big_img\n",
    "tmp4 = torch.sum(mask_times_imgs[:how_many_to_show,chosen],dim=0)\n",
    "print(\"sum big_masks\", torch.max(tmp3))\n",
    "print(\"sum big_masks * big_imgs\", torch.max(tmp4))\n",
    "combined = torch.stack((tmp1,tmp2,tmp3,tmp4),dim=0)\n",
    "print(combined.shape)\n",
    "b = show_batch(combined, n_col=2, title=\"# ref, IMGS, MASKS, IMGS*MASKS\", figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"ref_img_mask.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(output.inference.big_mask[:how_many_to_show,chosen]), torch.max(output.inference.big_mask[:how_many_to_show,chosen]))\n",
    "show_batch(output.inference.big_mask[:how_many_to_show,chosen], n_col=4, title=\"# MASKS\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = show_batch(reference_imgs[chosen]+output.inference.big_mask[:how_many_to_show,chosen], \n",
    "               n_col=3, n_padding=4,title=\"# MASKS over REF, p=\"+str(prob_title), figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"mask_over_ref.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = show_batch(reference_imgs[chosen]+10*output.inference.big_img[:how_many_to_show,chosen], \n",
    "               n_col=3, n_padding=4,title=\"# IMGS over REF, p=\"+str(prob_title), figsize=(24,24), normalize_range=(0,1))\n",
    "b.savefig(os.path.join(dir_output, \"imgs_over_ref.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.inference.prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob =  output.inference.prob[:,chosen, None, None, None]\n",
    "b_mask = output.inference.big_mask[:,chosen]\n",
    "b_img = output.inference.big_img[:,chosen]\n",
    "b_combined = b_img * b_mask * prob\n",
    "tmp = torch.cat((b_mask, b_img, b_combined), dim=0)\n",
    "b = show_batch(tmp, n_col=tmp.shape[0]//3, n_padding=4, title=\"# mask, imgs, product. p=\"+str(prob_title), figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"mask_imgs_product.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(output.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "plt.savefig(os.path.join(dir_output, \"pmap_chosen.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "a = show_batch(reference_imgs[:9],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "b = show_batch(output.inference.p_map[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "c = show_batch(output.inference.bg_mu[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "d = show_batch(output.imgs[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "\n",
    "display(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,2000,20):\n",
    "    if(epoch<10):\n",
    "        label =\"000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"00\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"0\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "\n",
    "    try:\n",
    "        load_model_optimizer(path=os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\"), model=vae)\n",
    "        print(\"epoch, label, prob_cor_factor ->\",epoch,label,vae.prob_corr_factor)\n",
    "        vae.train()\n",
    "        with torch.no_grad():\n",
    "            output = vae.forward(reference_imgs,\n",
    "                                 draw_image=True,\n",
    "                                 draw_bounding_box=True,\n",
    "                                 verbose=False)\n",
    "        \n",
    "        b=show_batch(output.imgs[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        b.savefig(os.path.join(dir_output, 'movie_rec_'+label+'.png'), bbox_inches='tight')\n",
    "        \n",
    "        b=show_batch(output.inference.p_map[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch), normalize_range=None)\n",
    "        b.savefig(os.path.join(dir_output, 'movie_map_'+label+'.png'), bbox_inches='tight') \n",
    "        \n",
    "        b=show_batch(output.inference.bg_mu[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        b.savefig(os.path.join(dir_output, 'movie_bg_'+label+'.png'), bbox_inches='tight') \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sorted list of image files so that I can create the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filenames = glob.glob(dir_output+\"/movie_rec*.png\")\n",
    "map_filenames = glob.glob(dir_output+\"/movie_map*.png\")\n",
    "bg_filenames = glob.glob(dir_output+\"/movie_bg*.png\")\n",
    "\n",
    "rec_filenames.sort()\n",
    "map_filenames.sort()\n",
    "bg_filenames.sort()\n",
    "print(rec_filenames)\n",
    "print(map_filenames)\n",
    "print(bg_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    return Image(filename=rec_filenames[n])\n",
    "\n",
    "def show_frame_map(n):\n",
    "    return Image(filename=map_filenames[n])\n",
    "\n",
    "def show_frame_bg(n):\n",
    "    return display.Image(filename=bg_filenames[n])\n",
    "\n",
    "def show_frame_all(n):\n",
    "    try:\n",
    "        a = Image(filename=bg_filenames[n])\n",
    "        b = Image(filename=map_filenames[n])\n",
    "        c = Image(filename=rec_filenames[n])\n",
    "        return display(a,b,c)\n",
    "    except IndexError:\n",
    "        print(\"list index out of range\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gif file\n",
    "movie_rec = os.path.join(dir_output, \"movie_rec.gif\")\n",
    "movie_map = os.path.join(dir_output, \"movie_map.gif\")\n",
    "movie_bg = os.path.join(dir_output, \"movie_bg.gif\")\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec, fps=frame_per_second)\n",
    "\n",
    "im = mpy.ImageSequenceClip(map_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_map, fps=frame_per_second)\n",
    "\n",
    "im = mpy.ImageSequenceClip(bg_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_bg, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_map+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_bg+\"></img>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at few frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
