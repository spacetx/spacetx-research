{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic DAPI stain generator\n",
    "\n",
    "This notebook generates synthetic images of DAPI stains. The images could be used for training a variational auto-encoder (VAE) for testing purposes (e.g. to generate simulated test data of a FOV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default point spread function kernel\n",
    "DEFAULT_PSF_KERNEL = np.asarray(\n",
    "    [[1.0, 0.5, 0.5],\n",
    "     [0.5, 1.0, 0.5],\n",
    "     [0.5, 0.5, 1.0]])\n",
    "\n",
    "DEFAULT_PSF_KERNEL = DEFAULT_PSF_KERNEL / np.sum(DEFAULT_PSF_KERNEL)\n",
    "\n",
    "class NucleusLatentSpace:\n",
    "    \"\"\"A parameter store for synthetic DAPI stains.\n",
    "    \n",
    "    Arguments:\n",
    "        a_arr: 1d ndarray containing cosine coefficients\n",
    "        b_arr: 1d ndarray containing sine coefficients\n",
    "        theta_hnuc_arr: ndarray containing polar angles to place heterochromatin spots\n",
    "        scale_hnuc: size of heterochromatin spots\n",
    "        scale_boundary: size of the nucleus; must be in [0, 1]\n",
    "        rel_radius_hnuc_arr: radial position of heterochromatin spots (relative to the nucleus boundary)\n",
    "            must be in [0, 1]\n",
    "        intensity_bg_min: minimum background intensity\n",
    "        intensity_bg_max: maximum background intensity\n",
    "        intensity_interior_min: minimum nucleus body intensity\n",
    "        intensity_interior_max: maximum nucleus body intensity\n",
    "        intensity_hnuc_min: minimum heterochromatin spot intensity\n",
    "        intensity_hnuc_max: maximum heterochromatin spot intensity\n",
    "        psf_kernel: 2d ndarray of point spread function \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 a_arr,\n",
    "                 b_arr,\n",
    "                 theta_hnuc_arr,\n",
    "                 scale_hnuc,\n",
    "                 scale_boundary,\n",
    "                 rel_radius_hnuc_arr,\n",
    "                 intensity_bg_min = 0.0,\n",
    "                 intensity_bg_max = 0.0,\n",
    "                 intensity_interior_min = 0.1,\n",
    "                 intensity_interior_max = 0.5,\n",
    "                 intensity_hnuc_min = 0.4,\n",
    "                 intensity_hnuc_max = 0.9,\n",
    "                 psf_kernel = DEFAULT_PSF_KERNEL):\n",
    "        assert len(a_arr) == len(b_arr)\n",
    "        assert len(theta_hnuc_arr) == len(rel_radius_hnuc_arr)\n",
    "        \n",
    "        self.a_arr = a_arr\n",
    "        self.b_arr = b_arr\n",
    "        self.theta_hnuc_arr = theta_hnuc_arr\n",
    "        self.scale_hnuc = scale_hnuc\n",
    "        self.scale_boundary = scale_boundary\n",
    "        self.rel_radius_hnuc_arr = rel_radius_hnuc_arr\n",
    "        self.intensity_bg_min = intensity_bg_min\n",
    "        self.intensity_bg_max = intensity_bg_max\n",
    "        self.intensity_interior_min = intensity_interior_min\n",
    "        self.intensity_interior_max = intensity_interior_max\n",
    "        self.intensity_hnuc_min = intensity_hnuc_min\n",
    "        self.intensity_hnuc_max = intensity_hnuc_max\n",
    "        self.psf_kernel = psf_kernel\n",
    "        \n",
    "        # enforce the coefficient of cos(0) is 1.0\n",
    "        self.a_arr[0] = 1.0\n",
    "        \n",
    "\n",
    "def generate_random_nucleus_params() -> NucleusLatentSpace:\n",
    "    \"\"\"Generates sensible random instances of `NucleusLatentSpace`.\"\"\"\n",
    "    scale_boundary = 0.5\n",
    "    num_harmonics = 6\n",
    "    harmonics_attenuation_factor = 0.2 / np.arange(1, num_harmonics + 1)\n",
    "    a_arr = np.random.randn(num_harmonics) * harmonics_attenuation_factor\n",
    "    b_arr = np.random.randn(num_harmonics) * harmonics_attenuation_factor\n",
    "    \n",
    "    scale_hnuc = 0.07\n",
    "    num_hnuc = np.random.poisson(5.)\n",
    "    theta_hnuc_arr = 2 * np.pi * np.random.rand(num_hnuc)\n",
    "    rel_radius_hnuc_arr = np.random.rand(num_hnuc)\n",
    "    \n",
    "    return NucleusLatentSpace(a_arr, b_arr, theta_hnuc_arr, scale_hnuc, scale_boundary, rel_radius_hnuc_arr)\n",
    "\n",
    "\n",
    "def get_boundary_radius(a_arr, b_arr, theta, scale_boundary) -> np.ndarray:\n",
    "    \"\"\"Returns the boundary radius of the nucleus.\n",
    "    \n",
    "    Arguments:\n",
    "        a_arr: 1d ndarray containing cosine coefficients\n",
    "        b_arr: 1d ndarray containing sine coefficients\n",
    "        theta: ndarray containing polar angles for which the radius is to be calculated\n",
    "        scale_boundary: a global scale factor for the boundary curve\n",
    "    \"\"\"\n",
    "    cos_theta = np.zeros(theta.shape + (len(a_arr),))\n",
    "    sin_theta = np.zeros(theta.shape + (len(a_arr),))\n",
    "    for n in range(len(a_arr)):\n",
    "        cos_theta[..., n] = np.cos(n * theta)\n",
    "        sin_theta[..., n] = np.sin(n * theta)\n",
    "    return scale_boundary * np.sum((a_arr * cos_theta + a_arr * sin_theta), axis=-1)\n",
    "\n",
    "\n",
    "def get_uniform_random(min_val: float, max_val: float, shape: Tuple) -> np.ndarray:\n",
    "    \"\"\"Returns uniform random number in a given interval.\"\"\"\n",
    "    return min_val + (max_val - min_val) * np.random.rand(*shape)\n",
    "\n",
    "\n",
    "def generate_dapi_stain(params: NucleusLatentSpace, width=128, height=128) -> np.ndarray:\n",
    "    \"\"\"Generates a synthetic DAPI stain for given parameters.\"\"\"\n",
    "    # generate grid\n",
    "    x_vec = np.linspace(-1.0, 1.0, num=width)\n",
    "    y_vec = np.linspace(-1.0, 1.0, num=height)\n",
    "    x_mat, y_mat = np.meshgrid(x_vec, y_vec)\n",
    "    \n",
    "    # generate polar coordinates\n",
    "    r_mat = np.sqrt(x_mat**2 + y_mat**2)\n",
    "    t_mat = np.arctan2(y_mat, x_mat)\n",
    "    \n",
    "    boundary_radius_mat = get_boundary_radius(params.a_arr, params.b_arr, t_mat, params.scale_boundary)\n",
    "    interior_mask = r_mat < boundary_radius_mat\n",
    "\n",
    "    full_hnuc_mask = np.zeros_like(interior_mask)\n",
    "    num_hnuc = len(params.theta_hnuc_arr)\n",
    "    for n in range(num_hnuc):\n",
    "        radius_boundary = get_boundary_radius(\n",
    "            params.a_arr, params.b_arr, np.asarray([params.theta_hnuc_arr[n]]), params.scale_boundary)\n",
    "        radius_hnuc = params.rel_radius_hnuc_arr[n] * (radius_boundary - params.scale_hnuc)\n",
    "        x_hnuc = radius_hnuc * np.cos(params.theta_hnuc_arr[n])\n",
    "        y_hnuc = radius_hnuc * np.sin(params.theta_hnuc_arr[n])\n",
    "        single_hnuc_mask = np.sqrt((x_mat - x_hnuc)**2 + (y_mat - y_hnuc)**2) < params.scale_hnuc\n",
    "        full_hnuc_mask += single_hnuc_mask\n",
    "\n",
    "    shape = interior_mask.shape\n",
    "\n",
    "    full_image = get_uniform_random(\n",
    "        params.intensity_bg_min, params.intensity_bg_max, shape)\n",
    "    full_image[interior_mask] = get_uniform_random(\n",
    "        params.intensity_interior_min, params.intensity_interior_max, full_image[interior_mask].shape)\n",
    "    full_image[full_hnuc_mask] = get_uniform_random(\n",
    "        params.intensity_hnuc_min, params.intensity_hnuc_max, full_image[full_hnuc_mask].shape)\n",
    "\n",
    "    # apply PSF\n",
    "    final_image = ndi.convolve(full_image, params.psf_kernel)\n",
    "    \n",
    "    return final_image\n",
    "\n",
    "\n",
    "def generate_batch(width, height, num_samples) -> np.ndarray:\n",
    "    \"\"\"Generates a batch of synthetic DAPI stains.\"\"\"\n",
    "    synth_dapi_stain_samples = np.zeros((num_samples, width, height))\n",
    "\n",
    "    for n in range(num_samples):\n",
    "        synth_dapi_stain_samples[n, ...] = generate_dapi_stain(\n",
    "            generate_random_nucleus_params(), width, height)\n",
    "    return synth_dapi_stain_samples\n",
    "\n",
    "\n",
    "def show_images(imgs) -> None:\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(1, len(imgs), i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(generate_batch(64, 64, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./synth_dapi_stains/synth_dapi_stains_train_64_64_10k.npy',\n",
    "        generate_batch(64, 64, 10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./synth_dapi_stains/synth_dapi_stains_test_64_64_1k.npy',\n",
    "        generate_batch(64, 64, 1_000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
