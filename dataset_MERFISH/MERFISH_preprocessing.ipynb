{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS MERFISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy\n",
    "import skimage.filters\n",
    "import skimage.exposure\n",
    "import skimage.transform\n",
    "import skimage.morphology\n",
    "import PIL.Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "from MODULES.namedtuple import ImageBbox, PreProcess\n",
    "from MODULES.utilities import save_obj, load_obj, load_json_as_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_pre_processing(pilfile, reduction_factor=1, remove_background=True):\n",
    "    \"\"\" Resize and rescale intensities in (0,1) \"\"\"\n",
    "    \n",
    "    # Open and resize using bilinear interpolation\n",
    "    w_raw, h_raw = pilfile.size\n",
    "    w_new = int(w_raw/reduction_factor)\n",
    "    h_new = int(h_raw/reduction_factor)\n",
    "    pilresize = pilfile.convert(\"F\").resize((w_new, h_new), resample=PIL.Image.BILINEAR)\n",
    "    img_np = numpy.array(pilresize)\n",
    "    \n",
    "    # Compute NUCLEI and ROI masks\n",
    "    image_thresh = skimage.filters.threshold_otsu(img_np)\n",
    "    NUCLEI_mask = (img_np > image_thresh)\n",
    "    #ROI_mask = skimage.morphology.convex_hull_image(NUCLEI_mask) * (img_np > 1E-5)\n",
    "    ROI_mask = (img_np > 1E-5)\n",
    "        \n",
    "    # Rescale foreground intensity in (0,1)\n",
    "    if remove_background:\n",
    "        ql, qr = numpy.percentile(img_np[img_np > image_thresh].flatten(), q=(0, 100))  # note that the statistics are compute on the foreground only\n",
    "        img_tmp = skimage.exposure.rescale_intensity(img_np, in_range=(ql, qr), out_range=(0.0, 1.0))\n",
    "    else:\n",
    "        img_tmp = skimage.exposure.rescale_intensity(img_np, in_range=\"image\", out_range=(0.0, 1.0))\n",
    "        \n",
    "    return img_tmp, NUCLEI_mask, ROI_mask\n",
    "\n",
    "\n",
    "def find_bbox(mask):\n",
    "    assert len(mask.shape) == 2\n",
    "    row = numpy.sum(mask, axis=-1) > 0\n",
    "    col = numpy.sum(mask, axis=-2) > 0\n",
    "    max_row = max(numpy.arange(row.shape[0]) * row) + 1\n",
    "    min_row = row.shape[0] - max(numpy.arange(start=row.shape[0], stop=0, step=-1) * row)\n",
    "    max_col = max(numpy.arange(col.shape[0]) * col) + 1\n",
    "    min_col = col.shape[0] - max(numpy.arange(start=col.shape[0], stop=0, step=-1) * col)\n",
    "    return ImageBbox(min_row=min_row,\n",
    "                     min_col=min_col,\n",
    "                     max_row=max_row,\n",
    "                     max_col=max_col)\n",
    "\n",
    "\n",
    "def show_random_examples(img: numpy.ndarray,\n",
    "                         nexamples: int = 9, \n",
    "                         ncols: int = 3, \n",
    "                         crop_size: int = 200,\n",
    "                         figsize: tuple = (12,12)):\n",
    "    \n",
    "    nrows=int(numpy.ceil(nexamples/ncols))\n",
    "    iw_array = numpy.random.randint(low=0, high=img.shape[-2]-crop_size, size=nexamples, dtype=int)\n",
    "    ih_array = numpy.random.randint(low=0, high=img.shape[-1]-crop_size, size=nexamples, dtype=int)\n",
    "\n",
    "    if nrows == 1:\n",
    "        figure, axes = plt.subplots(ncols=ncols, figsize=figsize)\n",
    "        for n in range(nexamples):\n",
    "            axes[n].imshow(img[iw_array[n]:iw_array[n]+crop_size,\n",
    "                               ih_array[n]:ih_array[n]+crop_size], cmap='gray')\n",
    "    else:\n",
    "        figure, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)\n",
    "        for n in range(nexamples):\n",
    "            r = int(n / ncols)\n",
    "            c = numpy.mod(n,ncols)\n",
    "            axes[r,c].imshow(img[iw_array[n]:iw_array[n]+crop_size,\n",
    "                                 ih_array[n]:ih_array[n]+crop_size], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The entire preprocessing is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"DAPI_Overview.tif\"\n",
    "reduction_factor=1\n",
    "pilfile = PIL.Image.open(input_file)\n",
    "print(\"size raw image ->\", pilfile.size)\n",
    "\n",
    "img_tmp, NUCLEI_mask, ROI_mask = img_pre_processing(pilfile, reduction_factor=reduction_factor, remove_background=False)\n",
    "img = img_tmp\n",
    "#img = skimage.exposure.equalize_adapthist(img_tmp, kernel_size=160, clip_limit=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, figsize=(24,24))\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(NUCLEI_mask)\n",
    "axs[2].imshow(ROI_mask)\n",
    "axs[0].set_title(\"image\")\n",
    "axs[1].set_title(\"NUCLEI mask\")\n",
    "axs[2].set_title(\"ROI mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(numpy.sum(NUCLEI_mask))/numpy.sum(ROI_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (1000,2100,1300,2400)\n",
    "window = (4*1000,4*2100,4*1300,4*2400)\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(24,24))\n",
    "axs[0].imshow(img[window[0]:window[2],window[1]:window[3]], cmap='gray')\n",
    "axs[1].imshow(NUCLEI_mask[window[0]:window[2],window[1]:window[3]], cmap='gray')\n",
    "axs[2].imshow(ROI_mask[window[0]:window[2],window[1]:window[3]], cmap='gray')\n",
    "axs[0].set_title(\"image\")\n",
    "axs[1].set_title(\"NUCLEI mask\")\n",
    "axs[2].set_title(\"ROI mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the image to the smallest rectangle which fits the ROI_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_original= ImageBbox(min_row=0,\n",
    "                         min_col=0,\n",
    "                         max_row=img.shape[0],\n",
    "                         max_col=img.shape[1])\n",
    "\n",
    "#bbox_crop = find_bbox(ROI_mask)\n",
    "bbox_crop = bbox_original\n",
    "print(bbox_original)\n",
    "print(bbox_crop)\n",
    "\n",
    "crop_img = img[bbox_crop.min_row:bbox_crop.max_row,\n",
    "               bbox_crop.min_col:bbox_crop.max_col]\n",
    "crop_ROI_mask = ROI_mask[bbox_crop.min_row:bbox_crop.max_row,\n",
    "                         bbox_crop.min_col:bbox_crop.max_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=PreProcess(img=transforms.ToTensor()(crop_img)[None],\n",
    "               roi_mask=transforms.ToTensor()(crop_ROI_mask)[None],\n",
    "               bbox_original=bbox_original,\n",
    "               bbox_crop=bbox_crop)\n",
    "print(tmp.img.shape)\n",
    "print(tmp.roi_mask.shape)\n",
    "assert len(tmp.img.shape) == len(tmp.roi_mask.shape) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show random example before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_examples(img=tmp.img[0,0].cpu(),\n",
    "                     nexamples=9, \n",
    "                     ncols=3, \n",
    "                     crop_size=4*80,\n",
    "                     figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.basename(input_file)\n",
    "f = \"streamlined_\"+str(reduction_factor)+\"_\"+base_name\n",
    "\n",
    "save_obj(tmp, f)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESCALE THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2688, 2444])\n",
      "(19558, 21504)\n"
     ]
    }
   ],
   "source": [
    "oleh_mask = PIL.Image.open(\"MERFISH_mask_OLEH.tif\")\n",
    "small = load_obj(\"streamlined_8_DAPI_Overview.tif\")\n",
    "medium = load_obj(\"streamlined_4_DAPI_Overview.tif\")\n",
    "big = load_obj(\"streamlined_2_DAPI_Overview.tif\")\n",
    "huge = load_obj(\"streamlined_1_DAPI_Overview.tif\")\n",
    "print(small.img.shape)\n",
    "print(oleh_mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imsave(\"oleh_merfish_mask_huge.tif\", numpy.array(oleh_mask).astype(numpy.uint16), plugin=None, check_contrast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oleh_mask_resize = oleh_mask.convert(\"F\").resize((small.img.shape[-2],small.img.shape[-1]), resample=PIL.Image.NEAREST)\n",
    "data = numpy.array(oleh_mask_resize).astype(numpy.uint16)\n",
    "skimage.io.imsave(\"oleh_merfish_mask_small.tif\", data, plugin=None, check_contrast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oleh_mask_resize = oleh_mask.convert(\"F\").resize((medium.img.shape[-2],small.img.shape[-1]), resample=PIL.Image.NEAREST)\n",
    "data = numpy.array(oleh_mask_resize).astype(numpy.uint16)\n",
    "skimage.io.imsave(\"oleh_merfish_mask_medium.tif\", data, plugin=None, check_contrast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "oleh_mask_resize = oleh_mask.convert(\"F\").resize((big.img.shape[-2],small.img.shape[-1]), resample=PIL.Image.NEAREST)\n",
    "data = numpy.array(oleh_mask_resize).astype(numpy.uint16)\n",
    "skimage.io.imsave(\"oleh_merfish_mask_big.tif\", data, plugin=None, check_contrast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688, 2444)\n",
      "(5376, 2444)\n",
      "(10752, 2444)\n",
      "(19558, 21504)\n"
     ]
    }
   ],
   "source": [
    "print(PIL.Image.open(\"oleh_merfish_mask_small.tif\").size)\n",
    "print(PIL.Image.open(\"oleh_merfish_mask_medium.tif\").size)\n",
    "print(PIL.Image.open(\"oleh_merfish_mask_big.tif\").size)\n",
    "print(PIL.Image.open(\"oleh_merfish_mask_huge.tif\").size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tmp = \"streamlined_8_DAPI_Overview.tif\"\n",
    "a = load_obj(f_tmp)\n",
    "print(a.img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a.img.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_examples(img=a.img[0,0].cpu(),\n",
    "                     nexamples=9, \n",
    "                     ncols=3, \n",
    "                     crop_size=80,\n",
    "                     figsize=(24,24))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
