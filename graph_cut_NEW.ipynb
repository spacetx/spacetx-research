{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI DAPI VAE in PYRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM CLI: conda install -c nvidia -c rapidsai -c numba -c conda-forge -c defaults numba=0.48.0 cugraph cudatoolkit=10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML, Image\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from MODULES.utilities import *\n",
    "from MODULES.vae_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.2\n",
      "pyro.__version__  -->  1.3.0\n",
      "torch.__version__ -->  1.4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "#from pyro.infer import SVI, Trace_ELBO #,TraceEnum_ELBO, TraceGraph_ELBO, config_enumerate, JitTraceEnum_ELBO \n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "# Check versions\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "print(\"pyro.__version__  --> \",pyro.__version__)\n",
    "print(\"torch.__version__ --> \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0df6953cc3a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmask_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/ldalessi/DAPI_unsupervised/spacetx-research/merfish_june22_v2/BIG_edges_tiling.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0medges_tiling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    117\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "mask_file = \"/Users/ldalessi/DAPI_unsupervised/spacetx-research/merfish_june22_v2/BIG_edges_tiling.pkl\"\n",
    "tmp = torch.load(mask_file, map_location=torch.device('cpu'))\n",
    "edges_tiling, img_to_segment = tmp\n",
    "print(mask_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges_tiling[12].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(edges_tiling.cpu()[:,1000:1300,1000:1300], figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(\"python_version -->\",python_version())\n",
    "print(\"cuda_version -->\")\n",
    "!nvcc --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import leidenalg as la\n",
    "\n",
    "la.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "from typing import NamedTuple\n",
    "\n",
    "def plot_segmentation(mask, raw_img, figsize=None):\n",
    "    figure, axes = plt.subplots(ncols=3, figsize=figsize)\n",
    "    axes[0].imshow(skimage.color.label2rgb(mask, np.zeros_like(mask), alpha=1.0, bg_label=0))\n",
    "    axes[1].imshow(skimage.color.label2rgb(mask, raw_img, alpha=0.25, bg_label=0))\n",
    "    axes[2].imshow(raw_img, cmap='gray')\n",
    "    \n",
    "def plot_resolution(label_list):\n",
    "    N = len(label_list)\n",
    "    MAX_row = N//4\n",
    "    \n",
    "    figure, axes = plt.subplots(ncols=4,nrows=MAX_row, figsize=(30, 30))\n",
    "    for n in range(4*MAX_row):\n",
    "        row = n//4\n",
    "        col = n % 4\n",
    "        axes[row,col].imshow(skimage.color.label2rgb(label_list[n], np.zeros_like(label_list[n]), alpha=1.0, bg_label=0))\n",
    "\n",
    "class adjacency(NamedTuple):\n",
    "    v: list\n",
    "    i: list\n",
    "    j: list\n",
    "        \n",
    "class GraphSegmentation():\n",
    "    \"\"\" Takes many integer segmentation masks and produce a consensus segmentation mask.\n",
    "        It does so by producing a graph in which each node is a foreground pixel and each edge\n",
    "        is the number of times two pixel are segmented in the same object. \n",
    "        \n",
    "        Typical usage:\n",
    "        consensus = ConsensusSegmentation(integer_segmentation_masks)\n",
    "        mask = consensus.mask()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, edges):\n",
    "        super().__init__()\n",
    "        \n",
    "        # size = (2*r+1)*(2*r+1), w, h. Each channel contains the edges between pixel_i and pixel_j\n",
    "        assert len(edges.shape) == 3 \n",
    "        \n",
    "        self.edges = edges\n",
    "        self.device = self.edges.device\n",
    "        N, self.nx, self.ny = self.edges.shape\n",
    "        self.radius_nn = int((np.sqrt(N) -1) // 2)\n",
    "        print(\"radius_nn ->\",self.radius_nn)\n",
    "        \n",
    "        self.ch_edge_ii = (N -1)//2\n",
    "        print(\"ch_e_ii -->\",self.ch_edge_ii)\n",
    "        \n",
    "        self.fg_mask = self.edges[self.ch_edge_ii] > 0.5\n",
    "        \n",
    "        ix_matrix, iy_matrix = torch.meshgrid([torch.arange(self.nx, dtype=int, device=self.device), \n",
    "                                               torch.arange(self.ny, dtype=int, device=self.device)])\n",
    "        self.x_coordinate_fg_pixel = ix_matrix[self.fg_mask]\n",
    "        self.y_coordinate_fg_pixel = iy_matrix[self.fg_mask]\n",
    "        self.n_fg_pixel = self.x_coordinate_fg_pixel.shape[0]\n",
    "        self.index_array = torch.arange(self.n_fg_pixel, dtype=int, device=self.device)\n",
    "        self.index_matrix = -1*torch.ones_like(ix_matrix)\n",
    "        self.index_matrix[self.x_coordinate_fg_pixel, \n",
    "                          self.y_coordinate_fg_pixel] = self.index_array\n",
    "        \n",
    "        print(\"n_fg_pixel -->\",self.n_fg_pixel)\n",
    "        \n",
    "        self.adj = self._build_adjacency()\n",
    "        \n",
    "        self.graph = self._build_graph(self.adj)\n",
    "        \n",
    "        \n",
    "    def _build_adjacency(self):\n",
    "        ch = -1\n",
    "        w_list, i_list, j_list = [],[],[]\n",
    "        for dx in range(-self.radius_nn, self.radius_nn + 1):\n",
    "            index_matrix_tmp = torch.roll(self.index_matrix, dx, dims=-2)\n",
    "            for dy in range(-self.radius_nn, self.radius_nn + 1):\n",
    "                index_matrix_shifted = torch.roll(index_matrix_tmp, dy, dims=-1)\n",
    "                \n",
    "                w = self.edges[ch][self.fg_mask]\n",
    "                i = self.index_matrix[self.fg_mask]\n",
    "                j = index_matrix_shifted[self.fg_mask]\n",
    "                \n",
    "                \n",
    "                w_tmp = w[w>0.01] \n",
    "                i_tmp = i[w>0.01] \n",
    "                j_tmp = j[w>0.01] \n",
    "                \n",
    "                w_list += w_tmp[j_tmp>=0].cpu().numpy().tolist()\n",
    "                i_list += i_tmp[j_tmp>=0].cpu().numpy().tolist()\n",
    "                j_list += j_tmp[j_tmp>=0].cpu().numpy().tolist()\n",
    "                \n",
    "        return adjacency(v=w_list, i=i_list, j=j_list)\n",
    "        \n",
    "    \n",
    "    def _build_graph(self, adj):\n",
    "        \n",
    "        vertex_list = [n for n in range(self.n_fg_pixel)]\n",
    "        edgelist = list(zip(adj.i, adj.j))\n",
    "        \n",
    "        graph = ig.Graph(vertex_attrs={\"label\":vertex_list}, edges=edgelist, directed=False)\n",
    "        graph.es['weight'] = adj.v\n",
    "        return graph\n",
    "    \n",
    "    @functools.lru_cache(maxsize=10)\n",
    "    def find_profile(self, resolution_range=(0.01,0.5)):\n",
    "        optimiser = la.Optimiser()\n",
    "        profile = optimiser.resolution_profile(self.graph, la.CPMVertexPartition,\n",
    "                                               resolution_range=resolution_range,\n",
    "                                               weights=self.graph.es['weight'])\n",
    "        return profile\n",
    "\n",
    "    @functools.lru_cache(maxsize=10)\n",
    "    def find_partition(self, resolution):\n",
    "        partition = la.find_partition(self.graph, la.CPMVertexPartition, \n",
    "                                      resolution_parameter = resolution,\n",
    "                                      weights=self.graph.es['weight'])\n",
    "        return partition\n",
    "\n",
    "    \n",
    "    def profile_to_list_of_masks(self,profile):\n",
    "        mask_list = []\n",
    "        for n,partition in enumerate(profile):\n",
    "            mask = self.partition_to_mask(partition)\n",
    "            mask_list.append(mask)\n",
    "        return mask_list\n",
    "\n",
    "    def partition_to_mask(self, partition, size_threshold=10):\n",
    "        \n",
    "        instace_IDs = torch.tensor(partition.membership, device=self.device) + 1 # +1 b/c label_bg=0, label_fg=1,2,...\n",
    "        \n",
    "        for n,size in enumerate(partition.sizes()):\n",
    "            if size < size_threshold:\n",
    "                tmp = (instace_IDs == n+1)\n",
    "                instace_IDs[tmp] = 0   # small community are set to bg value\n",
    "                \n",
    "        mask = torch.zeros_like(self.index_matrix)\n",
    "        mask[self.x_coordinate_fg_pixel, self.y_coordinate_fg_pixel] = instace_IDs\n",
    "        return mask.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cugraph\n",
    "# import cudf\n",
    "# \n",
    "# #Create dataframe on GPU\n",
    "# df = cudf.DataFrame()\n",
    "# df['v'] = g.adj.v\n",
    "# df['i'] = g.adj.i\n",
    "# df['j'] = g.adj.j\n",
    "# \n",
    "# # Crete graph on GPU\n",
    "# G = cugraph.Graph()\n",
    "# G.from_cudf_edgelist(df, source='i', destination='j', edge_attr='v')\n",
    "# \n",
    "# # Run Louvain on the graph\n",
    "# df_partition, mod = cugraph.louvain(G)\n",
    "# print('Modularity was {}'.format(mod))\n",
    "# df_partition.head()\n",
    "# \n",
    "# # TAkes the partition\n",
    "# ainstance_IDs = np.array(df_partition[\"partition\"]) # use torch.tensor so that things stay on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_to_segment[0,1000:1250,2200:2450].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_small = GraphSegmentation(edges_tiling[:,1000:1250,2200:2450])\n",
    "g_large = GraphSegmentation(edges_tiling)\n",
    "plt.imshow(img_to_segment[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_015 = g_small.find_partition(resolution=0.015)\n",
    "partition_02 = g_small.find_partition(resolution=0.02)\n",
    "partition_01 = g_small.find_partition(resolution=0.01)\n",
    "#print(partition)\n",
    "mask_015 = g_small.partition_to_mask(partition_03, size_threshold=10)\n",
    "mask_02 = g_small.partition_to_mask(partition_02, size_threshold=10)\n",
    "mask_01 = g_small.partition_to_mask(partition_01, size_threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation(mask_01, img_to_segment[0, 1000:1250,2200:2450].cpu(), figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation(mask_02, img_to_segment[0, 1000:1250,2200:2450].cpu(), figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation(mask_015, img_to_segment[0, 1000:1250,2200:2450].cpu(), figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resolution(labels_list[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_mask = vae.segment_with_tiling(train_loader.x[...,2000:2400,2000:2400], \n",
    "#                                   crop_w=80, crop_h=80, \n",
    "#                                   stride_w=60, stride_h=60, n_objects_max_per_patch=10)\n",
    "\n",
    "x,y,index = test_loader.load(batch_size=8)\n",
    "seg_mask = vae.segment(x)\n",
    "\n",
    "vae.eval()\n",
    "output_test = vae.forward(x,\n",
    "                          draw_image=True,\n",
    "                          draw_boxes=True,\n",
    "                          verbose=False)\n",
    "\n",
    "print(x.shape, seg_mask.shape, output_test.imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test.inference.prob[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(output_test.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=6\n",
    "figure, axes = plt.subplots(ncols=3, figsize=(24, 24))\n",
    "axes[0].imshow(x[chosen,0].cpu(), cmap='gray')\n",
    "axes[1].imshow(skimage.color.label2rgb(skimage.img_as_ubyte(seg_mask[chosen,0].cpu()), x[chosen,0].cpu(), alpha=0.25, bg_label=0))\n",
    "axes[2].imshow(output_test.imgs[chosen,0].cpu(), cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    if k.startswith(\"train\"):\n",
    "        print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), \n",
    "         sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), \n",
    "         sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('LOSS = - ELBO')\n",
    "plt.title('Training procedure')\n",
    "#plt.ylim(ymax=4, ymin=0)\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test'])\n",
    "#plt.show()\n",
    "\n",
    "fig_file = os.path.join(dir_output, \"train.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(history_dict[\"train_length_GP\"])), history_dict[\"train_length_GP\"], '-', label=\"train\")\n",
    "plt.plot(np.arange(0,len(history_dict[\"test_length_GP\"])*TEST_FREQUENCY,TEST_FREQUENCY), history_dict[\"test_length_GP\"], 'x', label=\"test\")\n",
    "plt.title('LENGTH GP')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('lenght_GP')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "fig_file = os.path.join(dir_output, \"lenght_GP.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('fg fraction av', color=color)\n",
    "ax1.plot(np.arange(0, len(history_dict[\"train_fg_fraction\"])),\n",
    "         history_dict[\"train_fg_fraction\"], 'o', color=color, label=\"train\")\n",
    "ax1.plot(np.arange(0, len(history_dict[\"test_fg_fraction\"])*TEST_FREQUENCY, TEST_FREQUENCY),\n",
    "         history_dict[\"test_fg_fraction\"], 'x-', color=color, label=\"test\")\n",
    "\n",
    "ymin=min(params[\"GECO\"][\"target_fg_fraction\"])\n",
    "ymax=max(params[\"GECO\"][\"target_fg_fraction\"])\n",
    "ax1.plot(ymin*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_min\")\n",
    "ax1.plot(ymax*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_max\")\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid()\n",
    "#ax1.set_ylim([1000,1870])\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(np.arange(0, len(history_dict[\"train_accuracy\"])),\n",
    "         history_dict[\"train_accuracy\"],'x', color=color)\n",
    "ax2.plot(np.arange(0, len(history_dict[\"test_accuracy\"])*TEST_FREQUENCY, TEST_FREQUENCY),\n",
    "         history_dict[\"test_accuracy\"],'-', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid()\n",
    "#ax2.set_ylim([0.97,1.0])\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"accuracy.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20,20))\n",
    "ax = f.add_subplot(321)\n",
    "ax2 = f.add_subplot(322)\n",
    "ax3 = f.add_subplot(323)\n",
    "ax4 = f.add_subplot(324)\n",
    "ax5 = f.add_subplot(325)\n",
    "ax6 = f.add_subplot(326)\n",
    "epoch_min, epoch_max = 200, None\n",
    "\n",
    "\n",
    "loss = np.array(history_dict[\"train_loss\"])\n",
    "kl_instance = np.array(history_dict[\"train_kl_instance\"])\n",
    "kl_where = np.array(history_dict[\"train_kl_where\"])\n",
    "kl_logit = np.array(history_dict[\"train_kl_logit\"])\n",
    "kl_raw = np.array(history_dict[\"train_kl_tot\"])\n",
    "nll_raw = np.array(history_dict[\"train_nll\"])\n",
    "reg_raw = np.array(history_dict[\"train_reg\"])\n",
    "sparsity_raw = np.array(history_dict[\"train_sparsity\"])\n",
    "overlap_raw = np.array(history_dict[\"train_cost_overlap\"])\n",
    "f_geco_sparsity = np.array(history_dict[\"train_geco_sparsity\"])\n",
    "f_geco_balance = np.array(history_dict[\"train_geco_balance\"])\n",
    "\n",
    "\n",
    "ax.plot(sparsity_raw,'-',label='sparsity_raw')\n",
    "ax.plot(overlap_raw,'-',label='cost overlap raw')\n",
    "ax.set_xlim([epoch_min, epoch_max])\n",
    "ax.set_ylim([None, 1.01*max(max(sparsity_raw[epoch_min:epoch_max]), max(overlap_raw[epoch_min:epoch_max]))])\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "ax2.plot(kl_instance,'-',label='kl instance raw')\n",
    "ax2.plot(kl_where,'-',label='kl zwhere raw')\n",
    "ax2.set_xlim([epoch_min, epoch_max])\n",
    "ax2.set_ylim([0, 1.01*max(max(kl_instance[epoch_min:epoch_max]),max(kl_where[epoch_min:epoch_max]))])\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(kl_logit,'-',label='kl logit raw')\n",
    "#ax3.set_ylim([0,1.1])\n",
    "ax3.set_xlim([epoch_min, epoch_max])\n",
    "ax3.set_ylim([None, 1.01*max(kl_logit[epoch_min:epoch_max])])\n",
    "ax3.grid()\n",
    "ax3.legend()\n",
    "\n",
    "\n",
    "ax4.plot(f_geco_sparsity ,'x-',label='geco_sparsity')\n",
    "#ax4.set_ylim([0,100])\n",
    "ax4.set_xlim([epoch_min, epoch_max])\n",
    "ax4.set_ylim([None, 1.01*max(f_geco_sparsity[epoch_min:epoch_max])])\n",
    "ax4.grid()\n",
    "ax4.legend()\n",
    "\n",
    "ax5.plot(f_geco_balance ,'x-',label='geco_balance')\n",
    "ax5.set_xlim([epoch_min, epoch_max])\n",
    "ax5.set_ylim([None, 1.01*max(f_geco_balance[epoch_min:epoch_max])])\n",
    "ax5.grid()\n",
    "ax5.legend()\n",
    "\n",
    "ax6.plot(loss,'-',label='loss')\n",
    "ax6.plot(f_geco_sparsity * sparsity_raw,'x-',label='scaled_sparsity')\n",
    "ax6.plot(f_geco_balance * reg_raw,'x-',label='scaled_reg')\n",
    "ax6.plot(f_geco_balance * nll_raw,'x-',label='scaled_nll')\n",
    "ax6.plot((1-f_geco_balance) * kl_raw,'x-',label='scaled_kl')\n",
    "ax6.set_ylim([0, 1.01*max(loss[epoch_min:epoch_max])])\n",
    "ax6.set_xlim([epoch_min, epoch_max])\n",
    "ax6.grid()\n",
    "ax6.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"metrics.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"GECO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=20\n",
    "labelsize=20\n",
    "f = plt.figure(figsize=(20,20))\n",
    "ax1 = f.add_subplot(311)\n",
    "ax2 = f.add_subplot(312)\n",
    "ax3 = f.add_subplot(313)\n",
    "epoch_min, epoch_max = 0, None\n",
    "\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax1.set_ylabel('fg_fraction', fontsize=fontsize, color=color)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax1.plot(history_dict[\"train_fg_fraction\"], '.--', color=color, label=\"n_object\")\n",
    "ax1.set_xlim([epoch_min, epoch_max])\n",
    "ymin=min(params[\"GECO\"]['target_fg_fraction'])\n",
    "ymax=max(params[\"GECO\"]['target_fg_fraction'])\n",
    "ax1.plot(ymin*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_min\")\n",
    "ax1.plot(ymax*np.ones(len(history_dict[\"train_fg_fraction\"])), '-', color='black', label=\"y_max\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid()\n",
    "\n",
    "ax1b = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax1b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax1b.set_ylabel('geco_sparsity', color=color, fontsize=fontsize)\n",
    "ax1b.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "plt.plot(history_dict[\"train_geco_sparsity\"],'-',label=\"geco_sparsity\",color=color)\n",
    "ax1b.tick_params(axis='y', labelcolor=color)\n",
    "ax1b.grid()\n",
    "\n",
    "##------------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax2.set_ylabel('nll av', fontsize=fontsize, color=color)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2.plot(history_dict[\"train_nll\"], '.--', color=color, label=\"nll av\")\n",
    "ax2.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "ymin=min(params[\"GECO\"][\"target_nll\"])\n",
    "ymax=max(params[\"GECO\"][\"target_nll\"])\n",
    "ax2.plot(ymin*np.ones(len(history_dict[\"train_nll\"])), '-', color='black', label=\"y_min\")\n",
    "ax2.plot(ymax*np.ones(len(history_dict[\"train_nll\"])), '-', color='black', label=\"y_max\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2.grid()\n",
    "\n",
    "ax2b = ax2.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax2b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax2b.set_ylabel('geco_balance', fontsize=fontsize, color=color)\n",
    "plt.plot(history_dict[\"train_geco_balance\"],'-',label=\"geco_balance\",color=color)\n",
    "ax2b.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2b.tick_params(axis='y', labelcolor=color)\n",
    "ax2b.grid()\n",
    "\n",
    "##------------------------------------\n",
    "\n",
    "color = 'tab:red'\n",
    "ax3.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax3.set_ylabel('delta_1', fontsize=fontsize, color=color)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3.plot(history_dict[\"train_delta_1\"], '.--', color=color, label=\"delta_1\")\n",
    "ax3.set_xlim([epoch_min, epoch_max])\n",
    "\n",
    "\n",
    "ax3b = ax3.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax3b.set_xlabel('epochs', fontsize=fontsize)\n",
    "ax3b.set_ylabel('delta_2', fontsize=fontsize, color=color)\n",
    "plt.plot(history_dict[\"train_delta_2\"],'-',label=\"delta_2\",color=color)\n",
    "ax3b.tick_params(axis='y', labelcolor=color)\n",
    "ax3b.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3b.grid()\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"geco.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "epoch_min, epoch_max = 0, 2500\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_nll\"][epoch_min:epoch_max])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "f = plt.figure(figsize=(20,10))\n",
    "ax1 = f.add_subplot(221)\n",
    "ax2 = f.add_subplot(222)\n",
    "ax3 = f.add_subplot(223)\n",
    "ax4 = f.add_subplot(224, projection='3d')\n",
    "\n",
    "ax1.set_xlabel('NLL',fontsize=fontsize)\n",
    "ax1.set_ylabel('KL',fontsize=fontsize)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax1.scatter(history_dict[\"train_nll\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max],c=colors)\n",
    "ax1.plot(history_dict[\"train_nll\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], '--')\n",
    "ax1.grid()\n",
    "#ax1.set_xlim(xmax=2.5)\n",
    "\n",
    "ax2.set_xlabel('SPARSITY',fontsize=fontsize)\n",
    "ax2.set_ylabel('NLL',fontsize=fontsize)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax2.scatter(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_nll\"][epoch_min:epoch_max], c=colors)\n",
    "ax2.plot(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_nll\"][epoch_min:epoch_max], '--')\n",
    "ax2.grid()\n",
    "#ax2.set_xlim(xmax=2.5)\n",
    "\n",
    "ax3.set_xlabel('SPARSITY',fontsize=fontsize)\n",
    "ax3.set_ylabel('KL',fontsize=fontsize)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax3.scatter(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], c=colors)\n",
    "ax3.plot(history_dict[\"train_sparsity\"][epoch_min:epoch_max], history_dict[\"train_kl_tot\"][epoch_min:epoch_max], '--')\n",
    "ax3.grid()\n",
    "#ax3.set_xlim(xmax=2.5)\n",
    "\n",
    "\n",
    "ax4.scatter(history_dict[\"train_kl_tot\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_sparsity\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_nll\"][epoch_min:epoch_max], c=colors )\n",
    "\n",
    "ax4.plot(history_dict[\"train_kl_tot\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_sparsity\"][epoch_min:epoch_max],\n",
    "         history_dict[\"train_nll\"][epoch_min:epoch_max], '--', label='training')\n",
    "ax4.set_xlabel('kl_tot', fontsize=fontsize)\n",
    "ax4.set_ylabel('sparsity', fontsize=fontsize)\n",
    "ax4.set_zlabel('nll', fontsize=fontsize)\n",
    "ax4.legend(prop={'size':fontsize})\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig_file = os.path.join(dir_output, \"nll_vs_kll_vs_sparsity.png\")\n",
    "plt.savefig(fig_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run one epoch in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch=100\n",
    "#load_model_optimizer(path=os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\"), model=vae)\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    test_metrics = process_one_epoch(model=vae, \n",
    "                                     dataloader=test_loader)\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_pkl = os.path.join(dir_output, \"reference.pkl\")\n",
    "tmp_list = [0, 1, 2,3,4,5,6,7,8,9]\n",
    "#tmp_list = [255, 148, 291, 310, 2,3,4,5,6,7,8,9,10]\n",
    "#tmp_list = [425, 411, 61, 194, 91, 384, 339, 54, 336]\n",
    "\n",
    "reference_imgs, labels, index =test_loader.load(index=torch.tensor(tmp_list[:9]))\n",
    "save_obj(reference_imgs, ref_img_pkl)\n",
    "\n",
    "reference_imgs = load_obj(ref_img_pkl)\n",
    "b = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "\n",
    "ref_img_png = os.path.join(dir_output, \"reference.png\")\n",
    "b.savefig(ref_img_png)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.geco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen=0\n",
    "with torch.no_grad():\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"--- eval mode ---\")\n",
    "    vae.eval()\n",
    "    output_test = vae.forward(reference_imgs[:],\n",
    "                              draw_image=True,\n",
    "                              draw_boxes=True,\n",
    "                              verbose=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"--- train mode ---\")\n",
    "    vae.train()\n",
    "    output_train = vae.forward(reference_imgs[:],\n",
    "                               draw_image=True,\n",
    "                               draw_boxes=True,\n",
    "                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap_train = show_batch(output_train.inference.p_map, n_col=3,n_padding=4,title=\"Train Prob MAP\")\n",
    "pmap_test = show_batch(output_test.inference.p_map, n_col=3,n_padding=4,title=\"Test Prob MAP\")\n",
    "\n",
    "counts_train = torch.sum(output_train.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "rec_train = show_batch(output_train.imgs[:],n_col=3,n_padding=4,title=\"# rec train \"+str(counts_train))\n",
    "\n",
    "counts_test = torch.sum(output_test.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "rec_test = show_batch(output_test.imgs[:],n_col=3,n_padding=4,title=\"# rec test \"+str(counts_test))\n",
    "\n",
    "background = show_batch(output_train.inference.big_bg,n_col=3,n_padding=4,title=\"BACKGROUND\")\n",
    "reference = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "\n",
    "background.savefig(os.path.join(dir_output, \"background.png\"))\n",
    "reference.savefig(os.path.join(dir_output, \"reference.png\"))\n",
    "rec_test.savefig(os.path.join(dir_output, \"rec_test.png\"))\n",
    "rec_train.savefig(os.path.join(dir_output, \"rec_train.png\"))\n",
    "pmap_test.savefig(os.path.join(dir_output, \"pmap_test.png\"))\n",
    "pmap_train.savefig(os.path.join(dir_output, \"pmap_train.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(background, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_train.inference.p_map.sum(dim=(-1,-2,-3)).cpu())\n",
    "print(output_test.inference.p_map.sum(dim=(-1,-2,-3)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec_train,reference)\n",
    "display(rec_test,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pmap_train,reference)\n",
    "display(pmap_test,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_train.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "print(torch.topk(output_train.inference.p_map[chosen,0].view(-1), k=10, largest=True, sorted=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_test.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "print(torch.topk(output_test.inference.p_map[chosen,0].view(-1), k=10, largest=True, sorted=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(output_train.inference.p_map[0,0].view(-1).cpu().numpy(), density=True, bins=50, label=\"pmap_train\")\n",
    "_ = plt.hist(output_test.inference.p_map[0,0].view(-1).cpu().numpy(), density=True, bins=50, label=\"pmap_test\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(dir_output, \"hist_pmap.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize one chosen image in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_train\n",
    "how_many_to_show=20\n",
    "counts = torch.sum(output.inference.prob>0.5,dim=0).view(-1).cpu().numpy().tolist()\n",
    "prob_tmp = np.round(output.inference.prob[:how_many_to_show,chosen].view(-1).cpu().numpy(),decimals=4)*10000\n",
    "prob_title = (prob_tmp.astype(int)/10000).tolist()\n",
    "print(\"counts ->\",counts[chosen],\" prob ->\",prob_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = reference_imgs[chosen]\n",
    "tmp2 = torch.sum(output.inference.big_img[:how_many_to_show,chosen],dim=0)\n",
    "tmp3 = torch.sum(output.inference.big_mask[:how_many_to_show,chosen],dim=0)\n",
    "mask_times_imgs = output.inference.big_mask * output.inference.big_img\n",
    "tmp4 = torch.sum(mask_times_imgs[:how_many_to_show,chosen],dim=0)\n",
    "print(\"sum big_masks\", torch.max(tmp3))\n",
    "print(\"sum big_masks * big_imgs\", torch.max(tmp4))\n",
    "combined = torch.stack((tmp1,tmp2,tmp3,tmp4),dim=0)\n",
    "print(combined.shape)\n",
    "b = show_batch(combined, n_col=2, title=\"# ref, IMGS, MASKS, IMGS*MASKS\", figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"ref_img_mask.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(output.inference.big_mask[:how_many_to_show,chosen]), torch.max(output.inference.big_mask[:how_many_to_show,chosen]))\n",
    "show_batch(output.inference.big_mask[:how_many_to_show,chosen], n_col=4, title=\"# MASKS\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = show_batch(reference_imgs[chosen]+output.inference.big_mask[:how_many_to_show,chosen], \n",
    "               n_col=3, n_padding=4,title=\"# MASKS over REF, p=\"+str(prob_title), figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"mask_over_ref.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = show_batch(reference_imgs[chosen]+10*output.inference.big_img[:how_many_to_show,chosen], \n",
    "               n_col=4, n_padding=4,title=\"# IMGS over REF, p=\"+str(prob_title), figsize=(24,24), normalize_range=(0,1))\n",
    "b.savefig(os.path.join(dir_output, \"imgs_over_ref.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.inference.prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob =  output.inference.prob[:,chosen, None, None, None]\n",
    "b_mask = output.inference.big_mask[:,chosen]\n",
    "b_img = output.inference.big_img[:,chosen]\n",
    "b_combined = b_img * b_mask * prob\n",
    "tmp = torch.cat((b_mask, b_img, b_combined), dim=0)\n",
    "b = show_batch(tmp, n_col=tmp.shape[0]//3, n_padding=4, title=\"# mask, imgs, product. p=\"+str(prob_title), figsize=(24,24))\n",
    "b.savefig(os.path.join(dir_output, \"mask_imgs_product.png\"))\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(output.inference.p_map[chosen,0].cpu().numpy())\n",
    "_ = plt.colorbar()\n",
    "plt.savefig(os.path.join(dir_output, \"pmap_chosen.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "a = show_batch(reference_imgs[:9],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "b = show_batch(output.inference.p_map[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "c = show_batch(output.inference.big_bg[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "d = show_batch(output.imgs[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "\n",
    "display(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,50000,5):\n",
    "    if(epoch<10):\n",
    "        label =\"0000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"000\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"00\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = \"0\"+str(epoch)\n",
    "    elif(epoch<100000):\n",
    "        label = str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "\n",
    "    try:\n",
    "        ckpt_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "                     \n",
    "        ckpt = load_ckpt(path=ckpt_file, device=None)\n",
    "                                 \n",
    "        load_model_optimizer(ckpt=ckpt, \n",
    "                             model=vae,\n",
    "                             optimizer=None)\n",
    "        \n",
    "        print(\"epoch, label, prob_cor_factor ->\",epoch,label,vae.prob_corr_factor)\n",
    "        vae.train()\n",
    "        with torch.no_grad():\n",
    "            output = vae.forward(reference_imgs,\n",
    "                                 draw_image=True,\n",
    "                                 draw_boxes=True,\n",
    "                                 verbose=False)\n",
    "        \n",
    "        b=show_batch(output.imgs[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        b.savefig(os.path.join(dir_output, 'movie_rec_'+label+'.png'), bbox_inches='tight')\n",
    "        \n",
    "        b=show_batch(output.inference.p_map[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch), normalize_range=None)\n",
    "        b.savefig(os.path.join(dir_output, 'movie_map_'+label+'.png'), bbox_inches='tight') \n",
    "        \n",
    "        b=show_batch(output.inference.big_bg[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        b.savefig(os.path.join(dir_output, 'movie_bg_'+label+'.png'), bbox_inches='tight') \n",
    "        \n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sorted list of image files so that I can create the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filenames = glob.glob(dir_output+\"/movie_rec*.png\")\n",
    "map_filenames = glob.glob(dir_output+\"/movie_map*.png\")\n",
    "bg_filenames = glob.glob(dir_output+\"/movie_bg*.png\")\n",
    "\n",
    "rec_filenames.sort()\n",
    "map_filenames.sort()\n",
    "bg_filenames.sort()\n",
    "print(rec_filenames)\n",
    "print(map_filenames)\n",
    "print(bg_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    return Image(filename=rec_filenames[n])\n",
    "\n",
    "def show_frame_map(n):\n",
    "    return Image(filename=map_filenames[n])\n",
    "\n",
    "def show_frame_bg(n):\n",
    "    return display.Image(filename=bg_filenames[n])\n",
    "\n",
    "def show_frame_all(n):\n",
    "    try:\n",
    "        a = Image(filename=bg_filenames[n])\n",
    "        b = Image(filename=map_filenames[n])\n",
    "        c = Image(filename=rec_filenames[n])\n",
    "        return display(a,b,c)\n",
    "    except IndexError:\n",
    "        print(\"list index out of range\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gif file\n",
    "movie_rec = os.path.join(dir_output, \"movie_rec.gif\")\n",
    "movie_map = os.path.join(dir_output, \"movie_map.gif\")\n",
    "movie_bg = os.path.join(dir_output, \"movie_bg.gif\")\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec, fps=frame_per_second)\n",
    "\n",
    "im = mpy.ImageSequenceClip(map_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_map, fps=frame_per_second)\n",
    "\n",
    "im = mpy.ImageSequenceClip(bg_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_bg, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_map+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_bg+\"></img>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at few frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_all(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CHECK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in_tmp, labels, index = train_loader.load(batch_size=8)\n",
    "auch = vae.generate(imgs_in=imgs_in_tmp[:1], draw_bounding_box=False)\n",
    "\n",
    "pmap_gen = show_batch(auch.inference.p_map[:8], title=\"generated p_map\")\n",
    "imgs_gen = show_batch(auch.imgs[:8], title=\"generated imgs\")\n",
    "display(pmap_gen, imgs_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_mask = auch.inference.big_mask[:,0]\n",
    "big_img = auch.inference.big_img[:,0]\n",
    "tmp = torch.cat((big_mask, big_img),dim=0)\n",
    "print(auch.inference.prob)\n",
    "show_batch(tmp, n_col=tmp.shape[0]//2, title=\"masks and imgs\", figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auch.inference.big_mask.shape)\n",
    "fg_mask = torch.sum(auch.inference.big_mask, dim=0)\n",
    "img = torch.sum(auch.inference.big_img, dim=0)\n",
    "print(fg_mask.shape)\n",
    "\n",
    "figure, axes = plt.subplots(ncols=3, figsize=(24, 24))\n",
    "axes[0].imshow(fg_mask[0,0].cpu(), cmap='gray')\n",
    "axes[1].imshow(img[0,0].cpu(), cmap='gray')\n",
    "axes[2].imshow((fg_mask[0,0]*img[0,0]).cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_mask = vae.segment_with_tiling(train_loader.x[...,2000:2400,2000:2400], \n",
    "#                                   crop_w=80, crop_h=80, \n",
    "#                                   stride_w=60, stride_h=60, n_objects_max_per_patch=10)\n",
    "\n",
    "x,y,index = test_loader.load(batch_size=8)\n",
    "seg_mask = vae.segment(x)\n",
    "\n",
    "vae.eval()\n",
    "output_test = vae.forward(x,\n",
    "                          draw_image=True,\n",
    "                          draw_bounding_box=True,\n",
    "                          verbose=False)\n",
    "\n",
    "print(x.shape, seg_mask.shape, output_test.imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(x, figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(output_test.imgs, figsize=(24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(ncols=3, figsize=(24, 24))\n",
    "axes[0].imshow(x[0,0].cpu(), cmap='gray')\n",
    "axes[1].imshow(skimage.color.label2rgb(skimage.img_as_ubyte(seg_mask[0,0].cpu()), x[0,0].cpu(), alpha=0.25, bg_label=0))\n",
    "axes[2].imshow(output_test.imgs[0,0].cpu(), cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.segment_with_tile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
