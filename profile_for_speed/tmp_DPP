File: /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py
File duration: 24.9873s (5.25%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         2|  9.29832e-05|  4.64916e-05|  0.00%|import torch
     2|         1|  1.45435e-05|  1.45435e-05|  0.00%|import neptune
     3|         1|   2.5034e-05|   2.5034e-05|  0.00%|import numpy
     4|         1|   2.6226e-05|   2.6226e-05|  0.00%|import torch.nn.functional as F
     5|         1|  6.27041e-05|  6.27041e-05|  0.00%|from torch.distributions.utils import broadcast_all
(call)|         1|   3.6478e-05|   3.6478e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
     6|         1|  6.05583e-05|  6.05583e-05|  0.00%|from typing import Union, Callable, Optional, Tuple
(call)|         1|  2.43187e-05|  2.43187e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
     7|         1|  5.93662e-05|  5.93662e-05|  0.00%|from collections import OrderedDict
(call)|         1|  4.45843e-05|  4.45843e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
     8|         1|  6.86646e-05|  6.86646e-05|  0.00%|from torch.distributions.distribution import Distribution
(call)|         1|  2.28882e-05|  2.28882e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
     9|         1|  5.93662e-05|  5.93662e-05|  0.00%|from torch.distributions import constraints
(call)|         1|  4.31538e-05|  4.31538e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
    10|         0|            0|            0|  0.00%|
    11|         1|  5.88894e-05|  5.88894e-05|  0.00%|from MODULES.utilities import compute_average_in_box, compute_ranking, convert_to_box_list
(call)|         1|  2.28882e-05|  2.28882e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
    12|         1|  5.72205e-05|  5.72205e-05|  0.00%|from MODULES.utilities import pass_bernoulli
(call)|         1|  2.24113e-05|  2.24113e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
    13|         1|  0.000208139|  0.000208139|  0.00%|from MODULES.utilities_visualization import show_batch
(call)|         1|      17.3911|      17.3911|  3.65%|# <frozen importlib._bootstrap>:978 _find_and_load
(call)|         1|   4.8399e-05|   4.8399e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
    14|         1|  8.70228e-05|  8.70228e-05|  0.00%|from MODULES.namedtuple import DIST, MetricMiniBatch, BB
(call)|         1|  2.28882e-05|  2.28882e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
    15|         1|  6.34193e-05|  6.34193e-05|  0.00%|from MODULES.utilities_neptune import log_dict_metrics
(call)|         1|  3.67165e-05|  3.67165e-05|  0.00%|# <frozen importlib._bootstrap>:1009 _handle_fromlist
    16|         0|            0|            0|  0.00%|
    17|        24|  0.000195265|  8.13603e-06|  0.00%|def are_broadcastable(a: torch.Tensor, b: torch.Tensor) -> bool:
    18|         0|            0|            0|  0.00%|    """ Return True if tensor are broadcastable to each other, False otherwise """
    19|       115|   0.00124931|  1.08636e-05|  0.00%|    return all((m == n) or (m == 1) or (n == 1) for m, n in zip(a.shape[::-1], b.shape[::-1]))
(call)|        46|  0.000471592|   1.0252e-05|  0.00%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:19 <genexpr>
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|
    22|        49|  0.000365973|  7.46883e-06|  0.00%|def sample_and_kl_diagonal_normal(posterior_mu: torch.Tensor,
    23|         1|  2.00272e-05|  2.00272e-05|  0.00%|                                  posterior_std: torch.Tensor,
    24|         1|  1.97887e-05|  1.97887e-05|  0.00%|                                  prior_mu: torch.Tensor,
    25|         1|  1.90735e-05|  1.90735e-05|  0.00%|                                  prior_std: torch.Tensor,
    26|         1|  1.97887e-05|  1.97887e-05|  0.00%|                                  noisy_sampling: bool,
    27|         1|   2.6226e-05|   2.6226e-05|  0.00%|                                  sample_from_prior: bool) -> DIST:
    28|         0|            0|            0|  0.00%|
    29|        48|  0.000954628|  1.98881e-05|  0.00%|    post_mu, post_std, pr_mu, pr_std = broadcast_all(posterior_mu, posterior_std, prior_mu, prior_std)
(call)|        48|    0.0172689|  0.000359769|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/distributions/utils.py:7 broadcast_all
    30|        48|  0.000250578|  5.22037e-06|  0.00%|    if sample_from_prior:
    31|         0|            0|            0|  0.00%|        # working with the prior
    32|         2|  0.000176907|  8.84533e-05|  0.00%|        sample = pr_mu + pr_std * torch.randn_like(pr_mu) if noisy_sampling else pr_mu
    33|         2|  0.000109196|  5.45979e-05|  0.00%|        kl = torch.zeros_like(pr_mu)
    34|         0|            0|            0|  0.00%|    else:
    35|         0|            0|            0|  0.00%|        # working with the posterior
    36|        46|   0.00584888|   0.00012715|  0.00%|        sample = post_mu + post_std * torch.randn_like(post_mu) if noisy_sampling else post_mu
    37|        46|    0.0425732|  0.000925505|  0.01%|        tmp = (post_std + pr_std) * (post_std - pr_std) + (post_mu - pr_mu).pow(2)
    38|        46|   0.00875235|  0.000190268|  0.00%|        kl = tmp / (2 * pr_std * pr_std) - post_std.log() + pr_std.log()
    39|         0|            0|            0|  0.00%|
    40|        48|   0.00109744|  2.28633e-05|  0.00%|    return DIST(sample=sample, kl=kl)
(call)|        48|  0.000491142|  1.02321e-05|  0.00%|# <string>_115:1 __new__
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|
    43|        25|  0.000329733|  1.31893e-05|  0.00%|def sample_and_kl_prob(logit_map: torch.Tensor,
    44|         1|  2.19345e-05|  2.19345e-05|  0.00%|                       similarity_kernel: torch.Tensor,
    45|         1|  1.93119e-05|  1.93119e-05|  0.00%|                       images: torch.Tensor,
    46|         1|  2.88486e-05|  2.88486e-05|  0.00%|                       background: torch.Tensor,
    47|         1|  2.36034e-05|  2.36034e-05|  0.00%|                       bounding_box_no_noise: BB,
    48|         1|  2.02656e-05|  2.02656e-05|  0.00%|                       prob_corr_factor: float,
    49|         1|  2.02656e-05|  2.02656e-05|  0.00%|                       noisy_sampling: bool,
    50|         1|  8.41618e-05|  8.41618e-05|  0.00%|                       sample_from_prior: bool) -> Tuple[DIST, torch.Tensor]:
(call)|         1|  0.000606537|  0.000606537|  0.00%|# /opt/anaconda3/lib/python3.7/typing.py:746 __getitem__
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|    # Correction factor
    53|        24|  0.000174522|  7.27177e-06|  0.00%|    if sample_from_prior:
    54|         1|  1.90735e-05|  1.90735e-05|  0.00%|        with torch.no_grad():
(call)|         1|  1.33514e-05|  1.33514e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:65 __enter__
    55|         1|   3.0756e-05|   3.0756e-05|  0.00%|            batch_size = torch.Size([logit_map.shape[0]])
    56|         1|  1.78814e-05|  1.78814e-05|  0.00%|            s = similarity_kernel.requires_grad_(False)
    57|         1|  0.000165224|  0.000165224|  0.00%|            c_all = FiniteDPP(L=s).sample(sample_shape=batch_size).transpose(-1, -2).float()
(call)|         1|     0.114024|     0.114024|  0.02%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:166 __init__
(call)|         1|     0.178251|     0.178251|  0.04%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:211 sample
    58|         1|  6.10352e-05|  6.10352e-05|  0.00%|            kl = torch.zeros(logit_map.shape[0])
    59|         1|  6.50883e-05|  6.50883e-05|  0.00%|            q_all = torch.zeros_like(c_all).float()
(call)|         1|  3.69549e-05|  3.69549e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:69 __exit__
    60|         0|            0|            0|  0.00%|    else:
    61|         0|            0|            0|  0.00%|        # Work with posterior
    62|        23|  0.000431538|  1.87625e-05|  0.00%|        if (prob_corr_factor > 0) and (prob_corr_factor <= 1.0):
    63|        23|  0.000412703|  1.79436e-05|  0.00%|            with torch.no_grad():
(call)|        23|  0.000417948|  1.81716e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:65 __enter__
    64|        23|    0.0241849|   0.00105152|  0.01%|                av_intensity = compute_average_in_box((images - background).abs(), bounding_box_no_noise)
(call)|        23|     0.301733|    0.0131188|  0.06%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities.py:219 compute_average_in_box
    65|        23|  0.000354052|  1.53935e-05|  0.00%|                assert len(av_intensity.shape) == 2
    66|        23|  0.000315905|   1.3735e-05|  0.00%|                n_boxes_all, batch_size = av_intensity.shape
    67|        23|  0.000722408|  3.14091e-05|  0.00%|                ranking = compute_ranking(av_intensity)  # n_boxes_all, batch. It is in [0,n_box_all-1]
(call)|        23|    0.0403819|   0.00175574|  0.01%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities.py:205 compute_ranking
    68|        23|   0.00248885|  0.000108211|  0.00%|                tmp = ((ranking + 1).float() / (n_boxes_all + 1))
    69|        23|    0.0015285|  6.64566e-05|  0.00%|                q_approx = tmp.pow(10)
(call)|        23|  0.000963211|  4.18787e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:69 __exit__
    70|         0|            0|            0|  0.00%|
    71|        23|   0.00186706|  8.11763e-05|  0.00%|            q_uncorrected = torch.sigmoid(convert_to_box_list(logit_map).squeeze(-1))
(call)|        23|   0.00119281|  5.18612e-05|  0.00%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities.py:9 convert_to_box_list
    72|        23|    0.0463724|   0.00201619|  0.01%|            q_all = ((1 - prob_corr_factor) * q_uncorrected + prob_corr_factor * q_approx).clamp(min=1E-4, max=1 - 1E-4)
    73|        23|    0.0309417|   0.00134529|  0.01%|            log_q = torch.log(q_all)
    74|        23|      0.06551|   0.00284826|  0.01%|            log_one_minus_q = torch.log1p(-q_all)
    75|         0|            0|            0|  0.00%|        else:
    76|         0|            0|            0|  0.00%|            logit_reshaped = convert_to_box_list(logit_map).squeeze(-1)
    77|         0|            0|            0|  0.00%|            q_all = torch.sigmoid(logit_reshaped)
    78|         0|            0|            0|  0.00%|            log_q = F.logsigmoid(logit_reshaped)
    79|         0|            0|            0|  0.00%|            log_one_minus_q = F.logsigmoid(-logit_reshaped)
    80|         0|            0|            0|  0.00%|
    81|        23|  0.000726223|  3.15749e-05|  0.00%|        c_all = pass_bernoulli(prob=q_all, noisy_sampling=noisy_sampling)  # float variable which requires grad
(call)|        23|    0.0724237|   0.00314886|  0.02%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities.py:78 pass_bernoulli
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|        # Here the gradients are only through log_q and similarity_kernel not c
    84|        23|   0.00113606|  4.93941e-05|  0.00%|        c_no_grad = c_all.bool().detach()  # bool variable has requires_grad = False
    85|        23|   0.00578499|  0.000251521|  0.00%|        log_prob_posterior = (c_no_grad * log_q + ~c_no_grad * log_one_minus_q).sum(dim=0)
    86|        23|    0.0086472|  0.000375965|  0.00%|        log_prob_prior = FiniteDPP(L=similarity_kernel).log_prob(c_no_grad.transpose(-1, -2))  # shape: batch_shape
(call)|        23|      9.71631|     0.422448|  2.04%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:166 __init__
(call)|        23|      8.49779|     0.369469|  1.79%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:229 log_prob
    87|        23|  0.000333309|  1.44917e-05|  0.00%|        assert log_prob_posterior.shape == log_prob_prior.shape
    88|        23|   0.00108981|  4.73831e-05|  0.00%|        kl = log_prob_posterior - log_prob_prior
    89|         0|            0|            0|  0.00%|
    90|        24|  0.000837088|  3.48787e-05|  0.00%|    return DIST(sample=c_all, kl=kl), q_all
(call)|        24|   0.00039196|  1.63317e-05|  0.00%|# <string>_115:1 __new__
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|
    93|         3|  0.000130892|  4.36306e-05|  0.00%|class SimilarityKernel(torch.nn.Module):
(call)|         1|  8.22544e-05|  8.22544e-05|  0.00%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:93 SimilarityKernel
    94|         1|  5.48363e-06|  5.48363e-06|  0.00%|    """ Similarity based on sum of gaussian kernels of different strength and length_scales """
    95|         0|            0|            0|  0.00%|
    96|         2|  2.00272e-05|  1.00136e-05|  0.00%|    def __init__(self, n_kernels: int = 4, eps: float = 1E-4):
    97|         1|  2.36034e-05|  2.36034e-05|  0.00%|        super().__init__()
(call)|         1|  0.000551224|  0.000551224|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:71 __init__
    98|         0|            0|            0|  0.00%|
    99|         1|  1.97887e-05|  1.97887e-05|  0.00%|        self.n_kernels = n_kernels
(call)|         1|  5.05447e-05|  5.05447e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   100|         1|  1.43051e-05|  1.43051e-05|  0.00%|        self.eps = eps
(call)|         1|  4.52995e-05|  4.52995e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   101|         1|  3.79086e-05|  3.79086e-05|  0.00%|        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
(call)|         1|  3.43323e-05|  3.43323e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:33 is_available
(call)|         1|  5.10216e-05|  5.10216e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   102|         0|            0|            0|  0.00%|
   103|         1|  1.57356e-05|  1.57356e-05|  0.00%|        self.similarity_w = torch.nn.Parameter(data=torch.ones(self.n_kernels,
   104|         1|  5.24521e-06|  5.24521e-06|  0.00%|                                                               device=self.device,
   105|         1|     0.133077|     0.133077|  0.03%|                                                               dtype=torch.float)/self.n_kernels, requires_grad=True)
(call)|         1|  0.000195503|  0.000195503|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/parameter.py:23 __new__
(call)|         1|  0.000319958|  0.000319958|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   106|         1|  1.95503e-05|  1.95503e-05|  0.00%|        self.similarity_s2 = torch.nn.Parameter(data=100*torch.randn(self.n_kernels,
   107|         1|  5.72205e-06|  5.72205e-06|  0.00%|                                                                     device=self.device,
   108|         1|    0.0765655|    0.0765655|  0.02%|                                                                     dtype=torch.float), requires_grad=True)
(call)|         1|  0.000105143|  0.000105143|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/parameter.py:23 __new__
(call)|         1|  0.000231504|  0.000231504|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|        # Initialization
   111|         1|  2.24113e-05|  2.24113e-05|  0.00%|        self.n_width = -1
(call)|         1|  7.08103e-05|  7.08103e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   112|         1|  1.57356e-05|  1.57356e-05|  0.00%|        self.n_height = -1
(call)|         1|   4.3869e-05|   4.3869e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   113|         1|  2.45571e-05|  2.45571e-05|  0.00%|        self.d2 = None
(call)|         1|   4.3869e-05|   4.3869e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   114|         1|  1.52588e-05|  1.52588e-05|  0.00%|        self.diag = None
(call)|         1|  4.41074e-05|  4.41074e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   115|         0|            0|            0|  0.00%|
   116|         2|  1.54972e-05|   7.7486e-06|  0.00%|    def _compute_d2_diag(self, n_width: int, n_height: int):
   117|         1|  1.90735e-05|  1.90735e-05|  0.00%|        with torch.no_grad():
(call)|         1|  1.64509e-05|  1.64509e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:65 __enter__
   118|         1|  5.74589e-05|  5.74589e-05|  0.00%|            ix_array = torch.arange(start=0, end=n_width, dtype=torch.int, device=self.device)
   119|         1|  3.45707e-05|  3.45707e-05|  0.00%|            iy_array = torch.arange(start=0, end=n_height, dtype=torch.int, device=self.device)
   120|         1|  2.47955e-05|  2.47955e-05|  0.00%|            ix_grid, iy_grid = torch.meshgrid([ix_array, iy_array])
(call)|         1|  0.000150442|  0.000150442|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/functional.py:295 meshgrid
   121|         1|    9.799e-05|    9.799e-05|  0.00%|            map_points = torch.stack((ix_grid, iy_grid), dim=-1)  # n_width, n_height, 2
   122|         1|  6.84261e-05|  6.84261e-05|  0.00%|            locations = map_points.flatten(start_dim=0, end_dim=-2)  # (n_width*n_height, 2)
   123|         1|     0.086165|     0.086165|  0.02%|            d2 = (locations.unsqueeze(-2) - locations.unsqueeze(-3)).pow(2).sum(dim=-1).float()
   124|         1|  4.00543e-05|  4.00543e-05|  0.00%|            diag = torch.eye(d2.shape[-2],
   125|         1|  8.58307e-06|  8.58307e-06|  0.00%|                             dtype=torch.float,
   126|         1|  8.10623e-06|  8.10623e-06|  0.00%|                             device=self.device,
   127|         1|    0.0305648|    0.0305648|  0.01%|                             requires_grad=False) * self.eps
   128|         1|  5.03063e-05|  5.03063e-05|  0.00%|            return d2, diag
(call)|         1|  6.55651e-05|  6.55651e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:69 __exit__
   129|         0|            0|            0|  0.00%|
   130|         1|   6.4373e-06|   6.4373e-06|  0.00%|    def sample_2_mask(self, sample):
   131|         0|            0|            0|  0.00%|        independent_dims = list(sample.shape[:-1])
   132|         0|            0|            0|  0.00%|        mask = sample.view(independent_dims + [self.n_width, self.n_height])
   133|         0|            0|            0|  0.00%|        return mask
   134|         0|            0|            0|  0.00%|
   135|        49|  0.000219345|  4.47643e-06|  0.00%|    def get_sigma2_w(self):
   136|        48|   0.00539207|  0.000112335|  0.00%|        return F.softplus(self.similarity_s2), F.softplus(self.similarity_w)
(call)|        96|   0.00219536|  2.28683e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:580 __getattr__
   137|         0|            0|            0|  0.00%|
   138|        25|  0.000156641|  6.26564e-06|  0.00%|    def forward(self, n_width: int, n_height: int):
   139|         0|            0|            0|  0.00%|        """ Implement L = sum_i a_i exp[-b_i d2] """
   140|        24|  0.000508547|  2.11895e-05|  0.00%|        sigma2, w = self.get_sigma2_w()
(call)|        24|   0.00367117|  0.000152965|  0.00%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:135 get_sigma2_w
   141|         0|            0|            0|  0.00%|
   142|        24|  0.000133276|  5.55317e-06|  0.00%|        if (n_width != self.n_width) or (n_height != self.n_height):
   143|         1|  2.09808e-05|  2.09808e-05|  0.00%|            self.n_width = n_width
(call)|         1|  8.60691e-05|  8.60691e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   144|         1|  1.50204e-05|  1.50204e-05|  0.00%|            self.n_height = n_height
(call)|         1|  4.41074e-05|  4.41074e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   145|         1|  5.60284e-05|  5.60284e-05|  0.00%|            self.d2, self.diag = self._compute_d2_diag(n_width=n_width, n_height=n_height)
(call)|         1|     0.117379|     0.117379|  0.02%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:116 _compute_d2_diag
(call)|         2|  0.000101805|  5.09024e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:596 __setattr__
   146|         0|            0|            0|  0.00%|
   147|        24|      0.14221|   0.00592543|  0.03%|        likelihood_kernel = (w[..., None, None] * torch.exp(-0.5*self.d2/sigma2[..., None, None])).sum(dim=-3) + self.diag
   148|        24|   0.00037694|  1.57058e-05|  0.00%|        return likelihood_kernel  # shape (n_width*n_height, n_width*n_height)
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|
   151|         3|  0.000139236|  4.64122e-05|  0.00%|class FiniteDPP(Distribution):
(call)|         1|  0.000142813|  0.000142813|  0.00%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:151 FiniteDPP
   152|         0|            0|            0|  0.00%|    """ Finite DPP distribution defined via:
   153|         0|            0|            0|  0.00%|        1. L = likelihood kernel of shape *,n,n
   154|         0|            0|            0|  0.00%|        2. K = correlation kernel of shape *,n,n
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|        The constraints are:
   157|         0|            0|            0|  0.00%|        K = positive semidefinite, symmetric, eigenvalues in [0,1]
   158|         0|            0|            0|  0.00%|        L = positive semidefinite, symmetric, eigenvalues >= 0
   159|         1|  4.76837e-06|  4.76837e-06|  0.00%|    """
   160|         0|            0|            0|  0.00%|
   161|         1|  7.86781e-06|  7.86781e-06|  0.00%|    arg_constraints = {'K': constraints.positive_definite,
   162|         1|  6.91414e-06|  6.91414e-06|  0.00%|                       'L': constraints.positive_definite}
   163|         1|  2.40803e-05|  2.40803e-05|  0.00%|    support = constraints.boolean
   164|         1|  6.67572e-06|  6.67572e-06|  0.00%|    has_rsample = False
   165|         0|            0|            0|  0.00%|
   166|        25|  0.000192404|  7.69615e-06|  0.00%|    def __init__(self, K=None, L=None, validate_args=None):
   167|         0|            0|            0|  0.00%|
   168|        24|  0.000172615|  7.19229e-06|  0.00%|        if (K is None and L is None) or (K is not None and L is not None):
   169|         0|            0|            0|  0.00%|            raise Exception("only one among K and L need to be defined")
   170|         0|            0|            0|  0.00%|
   171|        24|  0.000133753|  5.57303e-06|  0.00%|        elif K is not None:
   172|         0|            0|            0|  0.00%|            self.K = 0.5 * (K + K.transpose(-1, -2))  # make sure it is symmetrized
   173|         0|            0|            0|  0.00%|            u, s_k, v = torch.svd(self.K)
   174|         0|            0|            0|  0.00%|            s_l = s_k / (1.0 - s_k)
   175|         0|            0|            0|  0.00%|            self.L = torch.matmul(u * s_l.unsqueeze(-2), v.transpose(-1, -2))
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|            tmp = torch.matmul(u * s_k.unsqueeze(-2), v.transpose(-1, -2))
   178|         0|            0|            0|  0.00%|            check = (tmp - self.K).abs().max()
   179|         0|            0|            0|  0.00%|            # print("check ->",check)
   180|         0|            0|            0|  0.00%|            assert check < 1E-4
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|        else:
   183|        24|   0.00236082|  9.83675e-05|  0.00%|            self.L = 0.5 * (L + L.transpose(-1, -2))  # make sure it is symmetrized
   184|        24|      9.69664|     0.404027|  2.04%|            u, s_l, v = torch.svd(self.L)
   185|        24|   0.00671482|  0.000279784|  0.00%|            s_k = s_l / (1.0 + s_l)
   186|        24|    0.0589659|   0.00245691|  0.01%|            self.K = torch.matmul(u * s_k.unsqueeze(-2), v.transpose(-1, -2))
   187|         0|            0|            0|  0.00%|
   188|        24|   0.00288773|  0.000120322|  0.00%|            tmp = torch.matmul(u * s_l.unsqueeze(-2), v.transpose(-1, -2))
   189|        24|    0.0112901|   0.00047042|  0.00%|            check = (tmp - self.L).abs().max()
   190|         0|            0|            0|  0.00%|            # print("check ->",check)
   191|        24|    0.0441904|   0.00184127|  0.01%|            assert check < 1E-4
(call)|        24|    0.0045054|  0.000187725|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py:25 wrapped
   192|         0|            0|            0|  0.00%|
   193|        24|  0.000343323|  1.43051e-05|  0.00%|        self.s_l = s_l
   194|        24|  0.000386477|  1.61032e-05|  0.00%|        batch_shape, event_shape = self.K.shape[:-2], self.K.shape[-1:]
   195|        24|  0.000649929|  2.70804e-05|  0.00%|        super(FiniteDPP, self).__init__(batch_shape, event_shape, validate_args=validate_args)
(call)|        24|  0.000900269|  3.75112e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py:24 __init__
   196|         0|            0|            0|  0.00%|
   197|         1|  7.86781e-06|  7.86781e-06|  0.00%|    def expand(self, batch_shape, _instance=None):
   198|         0|            0|            0|  0.00%|        new = self._get_checked_instance(FiniteDPP, _instance)
   199|         0|            0|            0|  0.00%|        batch_shape = torch.Size(batch_shape)
   200|         0|            0|            0|  0.00%|        kernel_shape = batch_shape + self.event_shape + self.event_shape
   201|         0|            0|            0|  0.00%|        value_shape = batch_shape + self.event_shape
   202|         0|            0|            0|  0.00%|        new.s_l = self.s_l.expand(value_shape)
   203|         0|            0|            0|  0.00%|        new.L = self.L.expand(kernel_shape)
   204|         0|            0|            0|  0.00%|        new.K = self.K.expand(kernel_shape)
   205|         0|            0|            0|  0.00%|        super(FiniteDPP, new).__init__(batch_shape,
   206|         0|            0|            0|  0.00%|                                       self.event_shape,
   207|         0|            0|            0|  0.00%|                                       validate_args=False)
   208|         0|            0|            0|  0.00%|        new._validate_args = self._validate_args
   209|         0|            0|            0|  0.00%|        return new
   210|         0|            0|            0|  0.00%|
   211|         2|  3.95775e-05|  1.97887e-05|  0.00%|    def sample(self, sample_shape=torch.Size()):
   212|         1|  4.60148e-05|  4.60148e-05|  0.00%|        shape_value = self._extended_shape(sample_shape)  # shape = sample_shape + batch_shape + event_shape
(call)|         1|  2.45571e-05|  2.45571e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py:209 _extended_shape
   213|         1|  7.15256e-06|  7.15256e-06|  0.00%|        shape_kernel = shape_value + self._event_shape  # shape = sample_shape + batch_shape + event_shape + event_shape
   214|         0|            0|            0|  0.00%|
   215|         1|  3.60012e-05|  3.60012e-05|  0.00%|        with torch.no_grad():
(call)|         1|  4.52995e-05|  4.52995e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:65 __enter__
   216|         1|  7.53403e-05|  7.53403e-05|  0.00%|            K = self.K.expand(shape_kernel).clone()
   217|         1|  7.89165e-05|  7.89165e-05|  0.00%|            value = torch.zeros(shape_value, dtype=torch.bool, device=K.device)
   218|         1|  0.000157595|  0.000157595|  0.00%|            rand = torch.rand(shape_value, dtype=K.dtype, device=K.device)
   219|         0|            0|            0|  0.00%|
   220|       401|   0.00422454|   1.0535e-05|  0.00%|            for j in range(rand.shape[-1]):
   221|       400|    0.0133486|  3.33714e-05|  0.00%|                c = rand[..., j] < K[..., j, j]
(call)|       400|    0.0178058|  4.45145e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py:25 wrapped
   222|       400|      0.01423|   3.5575e-05|  0.00%|                value[..., j] = c
   223|       400|    0.0488696|  0.000122174|  0.01%|                K[..., j, j] -= (~c).to(K.dtype)
   224|       400|    0.0327718|  8.19296e-05|  0.01%|                K[..., j + 1:, j] /= K[..., j, j].unsqueeze(-1)
   225|       400|     0.046437|  0.000116093|  0.01%|                K[..., j + 1:, j + 1:] -= K[..., j + 1:, j].unsqueeze(-1) * K[..., j, j + 1:].unsqueeze(-2)
   226|         0|            0|            0|  0.00%|
   227|         1|  2.12193e-05|  2.12193e-05|  0.00%|            return value
(call)|         1|  6.10352e-05|  6.10352e-05|  0.00%|# /opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py:69 __exit__
   228|         0|            0|            0|  0.00%|
   229|        24|  0.000292778|  1.21991e-05|  0.00%|    def log_prob(self, value):
   230|         0|            0|            0|  0.00%|        """ log_prob = logdet(Ls) - logdet(L+I)
   231|         0|            0|            0|  0.00%|            I am using the fact that eigen(L+I) = eigen(L)+1
   232|         0|            0|            0|  0.00%|            -> logdet(L+I)=log prod[ eigen(L+I) ] = sum log(eigen(L+I)) = sum log(eigen(L)+1)
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|            # value.shape = sample_shape + batch_shape + event_shape
   235|         0|            0|            0|  0.00%|            # logdet(L+I).shape = batch_shape
   236|         0|            0|            0|  0.00%|            :rtype:
   237|         0|            0|            0|  0.00%|        """
   238|        23|   0.00100946|  4.38898e-05|  0.00%|        assert are_broadcastable(value, self.L[..., 0])
(call)|        23|   0.00142217|  6.18333e-05|  0.00%|# /home/jupyter/REPOS/spacetx-research/src/MODULES/utilities_ml.py:17 are_broadcastable
   239|        23|  0.000194311|  8.44831e-06|  0.00%|        assert self.L.device == value.device
   240|        23|  0.000249863|  1.08636e-05|  0.00%|        assert value.dtype == torch.bool
   241|         0|            0|            0|  0.00%|
   242|        23|  0.000161648|  7.02817e-06|  0.00%|        if self._validate_args:
   243|         0|            0|            0|  0.00%|            self._validate_sample(value)
   244|         0|            0|            0|  0.00%|
   245|        23|    0.0194669|  0.000846386|  0.00%|        logdet_L_plus_I = (self.s_l + 1).log().sum(dim=-1)  # batch_shape
   246|         0|            0|            0|  0.00%|
   247|         0|            0|            0|  0.00%|        # Reshapes
   248|        23|  0.000385284|  1.67515e-05|  0.00%|        independet_dims = list(value.shape[:-1])
   249|        23|  0.000396252|  1.72283e-05|  0.00%|        value = value.flatten(start_dim=0, end_dim=-2)  # *, event_shape
   250|        23|  0.000761032|  3.30884e-05|  0.00%|        L = self.L.expand(independet_dims + [-1, -1]).flatten(start_dim=0, end_dim=-3)  # *, event_shape, event_shape
   251|        23|    0.0097456|  0.000423722|  0.00%|        logdet_Ls = torch.zeros(independet_dims, dtype=self.L.dtype, device=value.device).view(-1)  # *
   252|         0|            0|            0|  0.00%|
   253|         0|            0|            0|  0.00%|        # Select rows and columns of the matrix which correspond to selected particles
   254|      2663|    0.0512934|  1.92615e-05|  0.01%|        for i in range(logdet_Ls.shape[0]):
   255|      2640|      1.21055|   0.00045854|  0.25%|            tmp = L[i, value[i], :][:, value[i]]
   256|      2640|      7.20001|   0.00272728|  1.51%|            logdet_Ls[i] = torch.logdet(tmp)
   257|        23|  0.000538111|  2.33961e-05|  0.00%|        logdet_Ls = logdet_Ls.view(independet_dims)  # sample_shape, batch_shape
   258|        23|   0.00132537|  5.76247e-05|  0.00%|        return logdet_Ls - logdet_L_plus_I
