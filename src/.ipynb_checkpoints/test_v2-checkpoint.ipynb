{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "from MODULES.utilities_neptune import log_object_as_artifact, log_model_summary, log_img_only, log_dict_metrics\n",
    "from MODULES.vae_model import *\n",
    "from MODULES.utilities_visualization import show_batch, plot_tiling, plot_all_from_dictionary, plot_label_contours\n",
    "from MODULES.utilities_visualization import plot_reconstruction_and_inference, plot_generation, plot_segmentation\n",
    "from MODULES.utilities_ml import ConditionalRandomCrop, SpecialDataSet, process_one_epoch\n",
    "from MODULES.graph_clustering import GraphSegmentation\n",
    "from MODULES.utilities import QC_on_integer_mask, concordance_integer_masks\n",
    "import skimage.io\n",
    "\n",
    "# Check versions\n",
    "import torch\n",
    "import numpy\n",
    "from platform import python_version\n",
    "print(\"python_version() ---> \", python_version())\n",
    "print(\"torch.__version__ --> \", torch.__version__)\n",
    "\n",
    "# make sure to fix the randomness at the very beginning\n",
    "torch.manual_seed(0)\n",
    "numpy.random.seed(0)\n",
    "\n",
    "params = load_json_as_dict(\"./ML_parameters.json\")\n",
    "\n",
    "neptune.set_project(params[\"neptune_project\"])\n",
    "exp: neptune.experiments.Experiment = \\\n",
    "    neptune.create_experiment(params=flatten_dict(params),\n",
    "                              upload_source_files=[\"./main.py\", \"./ML_parameters.json\", \"./MODULES/vae_parts.py\",\n",
    "                                                   \"./MODULES/vae_model.py\", \"./MODULES/encoders_decoders.py\"],\n",
    "                              upload_stdout=True,\n",
    "                              upload_stderr=True)\n",
    "\n",
    "# Get the training and test data\n",
    "preprocessed = load_obj(\"./data_train.pt\")\n",
    "img_torch = preprocessed.img.float()\n",
    "roi_mask_torch = preprocessed.roi_mask.bool()\n",
    "assert len(img_torch.shape) == len(roi_mask_torch.shape) == 4\n",
    "# print(\"GPU GB after opening data ->\",torch.cuda.memory_allocated()/1E9)\n",
    "\n",
    "BATCH_SIZE = params[\"simulation\"][\"batch_size\"]\n",
    "SIZE_CROPS = params[\"input_image\"][\"size_raw_image\"]\n",
    "N_TEST = params[\"simulation\"][\"N_test\"]\n",
    "N_TRAIN = params[\"simulation\"][\"N_train\"]\n",
    "conditional_crop_test = ConditionalRandomCrop(desired_w=SIZE_CROPS, desired_h=SIZE_CROPS, \n",
    "                                              min_roi_fraction=0.9, n_crops_per_image=N_TEST)\n",
    "\n",
    "conditional_crop_train = ConditionalRandomCrop(desired_w=SIZE_CROPS, desired_h=SIZE_CROPS, \n",
    "                                               min_roi_fraction=0.9, n_crops_per_image=N_TRAIN)\n",
    "\n",
    "test_data = conditional_crop_test.crop(img=img_torch,\n",
    "                                       roi_mask=roi_mask_torch)\n",
    "# print(\"GPU GB after defining test data ->\",torch.cuda.memory_allocated()/1E9)\n",
    "\n",
    "\n",
    "test_loader = SpecialDataSet(img=test_data,\n",
    "                             store_in_cuda=False,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False,\n",
    "                             batch_size=BATCH_SIZE)\n",
    "test_batch_example_fig = test_loader.check_batch()\n",
    "log_img_only(name=\"test_batch_example\", fig=test_batch_example_fig, experiment=exp)\n",
    "\n",
    "train_loader = SpecialDataSet(img=img_torch,\n",
    "                              roi_mask=roi_mask_torch,\n",
    "                              data_augmentation=conditional_crop_train,\n",
    "                              store_in_cuda=False,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              batch_size=BATCH_SIZE)\n",
    "train_batch_example_fig = train_loader.check_batch()\n",
    "log_img_only(name=\"train_batch_example\", fig=train_batch_example_fig, experiment=exp)\n",
    "# print(\"GPU GB after train_loader ->\",torch.cuda.memory_allocated()/1E9)\n",
    "\n",
    "# Make a batch of reference images by cropping the train_data at consecutive locations\n",
    "reference_imgs_list = []\n",
    "crop_size = params[\"input_image\"][\"size_raw_image\"]\n",
    "for ni in range(2):\n",
    "    i = 1080 + ni * crop_size\n",
    "    for nj in range(4):\n",
    "        j = 2140 + nj * crop_size\n",
    "        reference_imgs_list.append(img_torch[..., i:i+crop_size, j:j+crop_size])\n",
    "reference_imgs = torch.cat(reference_imgs_list, dim=-4)\n",
    "if torch.cuda.is_available():\n",
    "    reference_imgs = reference_imgs.cuda()\n",
    "_ = show_batch(reference_imgs,\n",
    "               n_padding=4,\n",
    "               figsize=(12, 12),\n",
    "               title=\"reference imgs\",\n",
    "               neptune_name=\"reference_imgs\")\n",
    "\n",
    "# Instantiate model, optimizer and checks\n",
    "vae = CompositionalVae(params)\n",
    "log_model_summary(vae)\n",
    "optimizer = instantiate_optimizer(model=vae, dict_params_optimizer=params[\"optimizer\"])\n",
    "\n",
    "imgs_out = vae.inference_and_generator.unet.show_grid(reference_imgs)\n",
    "unet_grid_fig = show_batch(imgs_out[:, 0], normalize_range=(0.0, 1.0), neptune_name=\"unet_grid\")\n",
    "\n",
    "# Check the constraint dictionary\n",
    "print(\"simulation type = \"+str(params[\"simulation\"][\"type\"]))\n",
    "    \n",
    "if params[\"simulation\"][\"type\"] == \"scratch\":\n",
    "    \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 999999\n",
    "\n",
    "elif params[\"simulation\"][\"type\"] == \"resume\":\n",
    "    \n",
    "    # ckpt = file2ckpt(path=\"ckpt.pt\", device=None)\n",
    "    ckpt = file2ckpt(path=\"ckpt.pt\", device='cpu')\n",
    "\n",
    "    load_from_ckpt(ckpt=ckpt,\n",
    "                   model=vae,\n",
    "                   optimizer=optimizer,\n",
    "                   overwrite_member_var=True)\n",
    "\n",
    "    epoch_restart = ckpt.get('epoch', -1)\n",
    "    history_dict = ckpt.get('history_dict', {})\n",
    "    try:\n",
    "        min_test_loss = min(history_dict.get(\"test_loss\", 999999))\n",
    "    except:\n",
    "        min_test_loss = 999999\n",
    "\n",
    "elif params[\"simulation\"][\"type\"] == \"pretrained\":\n",
    "\n",
    "    # ckpt = file2ckpt(path=\"ckpt.pt\", device=None)\n",
    "    ckpt = file2ckpt(path=\"ckpt.pt\", device='cpu')\n",
    "\n",
    "    load_from_ckpt(ckpt=ckpt,\n",
    "                   model=vae,\n",
    "                   optimizer=None,\n",
    "                   overwrite_member_var=False)\n",
    "       \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 999999\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"simulation type is NOT recognized\")\n",
    "    \n",
    "# instantiate the scheduler if necessary    \n",
    "if params[\"optimizer\"][\"scheduler_is_active\"]:\n",
    "    scheduler = instantiate_scheduler(optimizer=optimizer, dict_params_scheduler=params[\"optimizer\"])\n",
    "\n",
    "\n",
    "TEST_FREQUENCY = params[\"simulation\"][\"TEST_FREQUENCY\"]\n",
    "CHECKPOINT_FREQUENCY = params[\"simulation\"][\"CHECKPOINT_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"simulation\"][\"MAX_EPOCHS\"]\n",
    "torch.cuda.empty_cache()\n",
    "for delta_epoch in range(1, NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart    \n",
    "    \n",
    "    vae.prob_corr_factor = linear_interpolation(epoch,\n",
    "                                                values=params[\"shortcut_prob_corr_factor\"][\"values\"],\n",
    "                                                times=params[\"shortcut_prob_corr_factor\"][\"times\"])\n",
    "    exp.log_metric(\"prob_corr_factor\", vae.prob_corr_factor)\n",
    "        \n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        with torch.enable_grad():\n",
    "            vae.train()\n",
    "            train_metrics = process_one_epoch(model=vae, \n",
    "                                              dataloader=train_loader, \n",
    "                                              optimizer=optimizer, \n",
    "                                              verbose=(epoch == 0),\n",
    "                                              weight_clipper=None,\n",
    "                                              neptune_experiment=exp,\n",
    "                                              neptune_prefix=\"train_\")\n",
    "            print(\"Train \" + train_metrics.pretty_print(epoch))\n",
    "\n",
    "            if params[\"optimizer\"][\"scheduler_is_active\"]:\n",
    "                scheduler.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "\n",
    "                history_dict = append_to_dict(source=train_metrics,\n",
    "                                              destination=history_dict,\n",
    "                                              prefix_exclude=\"wrong_examples\",\n",
    "                                              prefix_to_add=\"train_\")\n",
    "\n",
    "                if (epoch % TEST_FREQUENCY) == 0:\n",
    "\n",
    "                    vae.eval()\n",
    "                    test_metrics = process_one_epoch(model=vae, \n",
    "                                                     dataloader=test_loader, \n",
    "                                                     optimizer=optimizer, \n",
    "                                                     verbose=(epoch == 0),\n",
    "                                                     weight_clipper=None,\n",
    "                                                     neptune_experiment=exp,\n",
    "                                                     neptune_prefix=\"test_\")\n",
    "                    print(\"Test  \"+test_metrics.pretty_print(epoch))\n",
    "                    history_dict = append_to_dict(source=test_metrics,\n",
    "                                                  destination=history_dict,\n",
    "                                                  prefix_exclude=\"wrong_examples\",\n",
    "                                                  prefix_to_add=\"test_\")\n",
    "                    \n",
    "                    output: Output = vae.forward(reference_imgs, draw_image=True, draw_boxes=True, verbose=False)\n",
    "                    plot_reconstruction_and_inference(output, epoch=epoch, prefix=\"rec_\")\n",
    "                    reference_n_cells = output.inference.sample_c_map.sum().item()\n",
    "                    tmp_dict = {\"reference_n_cells\": reference_n_cells}\n",
    "                    log_dict_metrics(tmp_dict)\n",
    "                    history_dict = append_to_dict(source=tmp_dict,\n",
    "                                                  destination=history_dict)\n",
    "\n",
    "                    segmentation: Segmentation = vae.segment(batch_imgs=reference_imgs)\n",
    "                    plot_segmentation(segmentation, epoch=epoch, prefix=\"seg_\")\n",
    "\n",
    "                    generated: Output = vae.generate(imgs_in=reference_imgs, draw_boxes=True)\n",
    "                    plot_generation(generated, epoch=epoch, prefix=\"gen_\")\n",
    "\n",
    "                    test_loss = test_metrics.loss\n",
    "                    min_test_loss = min(min_test_loss, test_loss)\n",
    "\n",
    "                    if (test_loss == min_test_loss) or (epoch % CHECKPOINT_FREQUENCY == 0):\n",
    "                        ckpt = create_ckpt(model=vae,\n",
    "                                           optimizer=optimizer,\n",
    "                                           epoch=epoch,\n",
    "                                           hyperparams_dict=params,\n",
    "                                           history_dict=history_dict)\n",
    "                        log_object_as_artifact(name=\"last_ckpt\", obj=ckpt)  # log file into neptune\n",
    "                        plot_all_from_dictionary(history_dict,\n",
    "                                                 params,\n",
    "                                                 test_frequency=TEST_FREQUENCY,\n",
    "                                                 train_or_test=\"test\",\n",
    "                                                 verbose=True)\n",
    "                        plot_all_from_dictionary(history_dict,\n",
    "                                                 params,\n",
    "                                                 test_frequency=TEST_FREQUENCY,\n",
    "                                                 train_or_test=\"train\",\n",
    "                                                 verbose=True)\n",
    "\n",
    "# # Check segmentation WITH and WITHOUT tiling to the GROUND_TRUTH\n",
    "img_to_segment = train_loader.img[0, :, 940:1240, 2140:2440]\n",
    "roi_mask_to_segment = train_loader.roi_mask[0, :, 940:1240, 2140:2440]\n",
    "gt_numpy = skimage.io.imread(\"./ground_truth\").astype(numpy.int32)[940:1240, 2140:2440]\n",
    "\n",
    "# tiling segmentation\n",
    "tiling: Segmentation = vae.segment_with_tiling(single_img=img_to_segment,\n",
    "                                               roi_mask=roi_mask_to_segment,\n",
    "                                               crop_size=None,\n",
    "                                               stride=(40, 40),\n",
    "                                               n_objects_max_per_patch=None,\n",
    "                                               prob_corr_factor=None,\n",
    "                                               overlap_threshold=None,\n",
    "                                               radius_nn=10,\n",
    "                                               batch_size=64)\n",
    "# log_object_as_artifact(name=\"tiling\", obj=tiling, verbose=True)\n",
    "tiling_fig = plot_tiling(tiling, neptune_name=\"tiling_before_graph\")\n",
    "\n",
    "# perform graph analysis\n",
    "g = GraphSegmentation(tiling, min_fg_prob=0.1, min_edge_weight=0.01, normalize_graph_edges=True)\n",
    "partition_graph = g.find_partition_leiden(resolution=1.0,\n",
    "                                          window=None,\n",
    "                                          min_size=30,\n",
    "                                          cpm_or_modularity=\"modularity\",\n",
    "                                          each_cc_separately=False,\n",
    "                                          n_iterations=10,\n",
    "                                          initial_membership=None)\n",
    "g.plot_partition(partition_graph, neptune_name=\"tiling_after_graph\")\n",
    "graph_integer_mask = g.partition_2_integer_mask(partition_graph)\n",
    "\n",
    "# qualitative comparison segmentation\n",
    "simple_integer_mask = QC_on_integer_mask(tiling.integer_mask[0, 0], min_area=30).to(dtype=graph_integer_mask.dtype,\n",
    "                                                                                    device=graph_integer_mask.device)\n",
    "\n",
    "gt_integer_mask = torch.from_numpy(QC_on_integer_mask(gt_numpy, min_area=30)).to(dtype=graph_integer_mask.dtype,\n",
    "                                                                                 device=graph_integer_mask.device)\n",
    "\n",
    "# compare with ground truth\n",
    "print(\"graph_integer_mask\", graph_integer_mask.device, graph_integer_mask.dtype, graph_integer_mask.shape)\n",
    "print(\"gt_integer_mask\", gt_integer_mask.device, gt_integer_mask.dtype, gt_integer_mask.shape)\n",
    "print(\"simple_integer_mask\", simple_integer_mask.device, simple_integer_mask.dtype, simple_integer_mask.shape)\n",
    "\n",
    "plot_label_contours(label=gt_integer_mask,\n",
    "                    image=tiling.raw_image[0, 0],\n",
    "                    contour_thickness=2,\n",
    "                    neptune_name=\"tiling_contours_ground_truth\")\n",
    "\n",
    "plot_label_contours(label=simple_integer_mask,\n",
    "                    image=tiling.raw_image[0, 0],\n",
    "                    contour_thickness=2,\n",
    "                    neptune_name=\"tiling_contours_simple\")\n",
    "\n",
    "plot_label_contours(label=graph_integer_mask,\n",
    "                    image=tiling.raw_image[0, 0],\n",
    "                    contour_thickness=2,\n",
    "                    neptune_name=\"tiling_contours_graph\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantitative comparison\n",
    "#simple_vs_gt = concordance_integer_masks(simple_integer_mask, gt_integer_mask)\n",
    "#graph_vs_gt = concordance_integer_masks(graph_integer_mask, gt_integer_mask)\n",
    "\n",
    "graph_vs_simple = concordance_integer_masks(simple_integer_mask, graph_integer_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM HERE. MAKE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
