{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,w,h = 2,20,20\n",
    "prob_corr_factor = 0.23\n",
    "n_objects_max = 20\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ee247d56315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpass_bernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mnms_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# only if c=1, there is NMS.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpass_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mlog_prob_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_mask\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_q\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mc_mask\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_one_minus_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4ee247d56315>\u001b[0m in \u001b[0;36mcompute_nms\u001b[0;34m(prob, c)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mnms_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnms_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class PassBernoulli(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, p):\n",
    "        c = torch.rand_like(p)<p\n",
    "        return c\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output\n",
    "\n",
    "def pass_bernoulli(prob):\n",
    "    return PassBernoulli.apply(prob)\n",
    "    \n",
    "class PassMask(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, c, mask):\n",
    "        return c*nms_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output\n",
    "    \n",
    "def pass_mask(c, mask):\n",
    "    return PassMask.apply(c, mask)\n",
    "\n",
    "def compute_nms(prob, c):\n",
    "    raise NotImplementedError\n",
    "    nms_mask = (c == 1)\n",
    "    return nms_mask\n",
    "\n",
    "\n",
    "raw =torch.randn((b,1,w,h))\n",
    "q = torch.sigmoid(raw)\n",
    "\n",
    "# Correction factor\n",
    "if prob_corr_factor == 0:\n",
    "    log_q = F.logsigmoid(raw)\n",
    "    log_one_minus_q = F.logsigmoid(-raw)\n",
    "else:\n",
    "    correction = torch.rand_like(q)\n",
    "    q = ((1-prob_corr_factor)*q + prob_corr_factor*correction).clamp(min=1E-4, max=1-1E-4)\n",
    "    log_q = torch.log(q)\n",
    "    log_one_minus_q = torch.log1p(-q)\n",
    "\n",
    "# sample, NMS, log_prob\n",
    "c = pass_bernoulli(prob=q)\n",
    "with torch.no_grad():\n",
    "    nms_mask = compute_nms(prob=q, c=c)  # only if c=1, there is NMS.\n",
    "c_mask = pass_mask(c, nms_mask) \n",
    "log_prob_posterior = (c_mask*log_q + ~c_mask*log_one_minus_q).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(ncols=3, figsize=(12,12))\n",
    "ax[0].imshow(q[0,0])\n",
    "ax[1].imshow(c[0,0])\n",
    "ax[2].imshow(c_mask[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.distribution import Distribution\n",
    "from torch.distributions import constraints\n",
    "from utilities_ml import are_broadcastable\n",
    "\n",
    "class Similarity(torch.nn.Module):\n",
    "    \"\"\" Similarity based on sum of gaussian kernels of different strength and length_scales \"\"\"\n",
    "\n",
    "    def __init__(self, n_kernels: int = 4, eps: float = 1E-4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_kernels = n_kernels\n",
    "        self.eps = eps\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        \n",
    "        self.w = torch.nn.Parameter(data=torch.randn(self.n_kernels, \n",
    "                                                     device=self.device, \n",
    "                                                     dtype=torch.float), requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(data=torch.randn(self.n_kernels, \n",
    "                                                     device=self.device, \n",
    "                                                     dtype=torch.float), requires_grad=True)\n",
    "        \n",
    "        # Initialization\n",
    "        self.n_width = -1\n",
    "        self.n_height = -1\n",
    "        self.locations = None\n",
    "        self.d2 = None\n",
    "        self.diag = None \n",
    "        \n",
    "    def _compute_d2_diag(self, n_width: int, n_height: int):\n",
    "        with torch.no_grad():\n",
    "            ix_array = torch.arange(start=0, end=n_width, dtype=torch.int, device=self.device)\n",
    "            iy_array = torch.arange(start=0, end=n_height, dtype=torch.int, device=self.device)\n",
    "            ix_grid, iy_grid = torch.meshgrid([ix_array, iy_array])\n",
    "            map_points = torch.stack((ix_grid, iy_grid), dim=-1)  # n_width, n_height, 2\n",
    "            locations = map_points.flatten(start_dim=0, end_dim=-2)  # (n_width*n_height, 2)\n",
    "            d2 = (locations.unsqueeze(-2) - locations.unsqueeze(-3)).pow(2).sum(dim=-1).float()\n",
    "            diag = torch.eye(d2.shape[-2], \n",
    "                             dtype=torch.float, \n",
    "                             device=self.device, \n",
    "                             requires_grad=False) * self.eps\n",
    "            return d2, diag\n",
    "        \n",
    "    def sample_2_mask(self, sample):\n",
    "        independent_dims = list(sample.shape[:-1])\n",
    "        mask = sample.view(independent_dims+[self.n_width, self.n_height])\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, n_width: int, n_height: int):\n",
    "        \"\"\" Implement L = sum_i a_i exp[-b_i d2] \"\"\"\n",
    "        b = F.softplus(self.b).view(-1,1,1)  # add singleton for w,h\n",
    "        w = F.softplus(self.w).view(-1,1,1)  # add singleton for w,h\n",
    "        \n",
    "        if (n_width != self.n_width) or (n_height != self.n_height):\n",
    "            self.n_width=n_width\n",
    "            self.n_height=n_height\n",
    "            self.d2, self.diag = self._compute_d2_diag(n_width=n_width, n_height=n_height)\n",
    "                    \n",
    "        likelihood_kernel = (w*torch.exp(-b*self.d2)).sum(dim=-3) + self.diag\n",
    "        return likelihood_kernel  # shape (n_width*n_height, n_width*n_height)\n",
    "    \n",
    "class FiniteDPP(Distribution):\n",
    "    \"\"\" Finite DPP distribution defined via:\n",
    "        1. L = likelihood kernel of shape *,n,n \n",
    "        2. K = correlation kernel of shape *,n,n \n",
    "        \n",
    "        The constraints are:\n",
    "        K = positive semidefinite, symmetric, eigenvalues in [0,1]\n",
    "        L = positive semidefinite, symmetric, eigenvalues >= 0\n",
    "    \"\"\"\n",
    "    \n",
    "    arg_constraints = {'K': constraints.positive_definite, \n",
    "                       'L': constraints.positive_definite}\n",
    "    support = constraints.boolean\n",
    "    has_rsample = False\n",
    "    \n",
    "    def __init__(self, K=None, L=None, validate_args=None):\n",
    "        \n",
    "        if (K is None and L is None) or (K is not None and L is not None):\n",
    "            raise Exception(\"only one among K and L need to be defined\")\n",
    "                    \n",
    "        elif K is not None:\n",
    "            self.K = 0.5*(K+K.transpose(-1,-2))  # make sure it is symmetrized\n",
    "            u,s_k,v = torch.svd(self.K)\n",
    "            s_l = s_k / (1.0-s_k)\n",
    "            self.L = torch.matmul(u * s_l.unsqueeze(-2), v.transpose(-1,-2))\n",
    "            \n",
    "            tmp = torch.matmul(u * s_k.unsqueeze(-2), v.transpose(-1,-2))\n",
    "            check = (tmp-self.K).abs().max()\n",
    "            # print(\"check ->\",check)\n",
    "            assert check < 1E-4\n",
    "            \n",
    "        else:\n",
    "            self.L = 0.5*(L+L.transpose(-1,-2))  # make sure it is symmetrized \n",
    "            u,s_l,v = torch.svd(self.L) \n",
    "            s_k = s_l / (1.0+s_l) \n",
    "            self.K = torch.matmul(u * s_k.unsqueeze(-2), v.transpose(-1,-2))\n",
    "            \n",
    "            tmp = torch.matmul(u * s_l.unsqueeze(-2), v.transpose(-1,-2))\n",
    "            check = (tmp-self.L).abs().max()\n",
    "            # print(\"check ->\",check)\n",
    "            assert check < 1E-4\n",
    "        \n",
    "        self.s_l = s_l            \n",
    "        batch_shape, event_shape = self.K.shape[:-2], self.K.shape[-1:]\n",
    "        super(FiniteDPP, self).__init__(batch_shape, event_shape, validate_args=validate_args)\n",
    "        \n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        new = self._get_checked_instance(FiniteDPP, _instance)\n",
    "        batch_shape = torch.Size(batch_shape)\n",
    "        kernel_shape = batch_shape + self.event_shape + self.event_shape\n",
    "        value_shape = batch_shape + self.event_shape \n",
    "        new.s_l = self.s_l.expand(value_shape) \n",
    "        new.L = self.L.expand(kernel_shape)\n",
    "        new.K = self.K.expand(kernel_shape)\n",
    "        super(FiniteDPP, new).__init__(batch_shape,\n",
    "                                       self.event_shape,\n",
    "                                       validate_args=False)\n",
    "        new._validate_args = self._validate_args\n",
    "        return new\n",
    "\n",
    "    \n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        shape_value = self._extended_shape(sample_shape)  # shape = sample_shape + batch_shape + event_shape\n",
    "        shape_kernel = shape_value + self._event_shape  # shape = sample_shape + batch_shape + event_shape + event_shape\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            K = self.K.expand(shape_kernel).clone()\n",
    "            value = torch.zeros(shape_value, dtype=torch.bool, device=K.device)\n",
    "            rand = torch.rand(shape_value, dtype=K.dtype, device=K.device)\n",
    "\n",
    "            for j in range(rand.shape[-1]):\n",
    "                c = rand[...,j]<K[...,j,j] \n",
    "                value[...,j] = c\n",
    "                K[..., j, j] -= (~c).to(K.dtype)\n",
    "                K[..., j + 1:, j] /= K[..., j, j].unsqueeze(-1)\n",
    "                K[..., j + 1:, j + 1:] -= K[..., j + 1:, j].unsqueeze(-1) * K[..., j, j + 1:].unsqueeze(-2)\n",
    "        \n",
    "            return value\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        \"\"\" log_prob = logdet(Ls) - logdet(L+I)\n",
    "            I am using the fact that eigen(L+I) = eigen(L)+1 \n",
    "            -> logdet(L+I)=log prod[ eigen(L+I) ] = sum log(eigen(L+I)) = sum log(eigen(L)+1) \n",
    "            \n",
    "            # value.shape = sample_shape + batch_shape + event_shape\n",
    "            # logdet(L+I).shape = batch_shape\n",
    "        \"\"\"\n",
    "        assert are_broadcastable(value, self.L[...,0])\n",
    "        assert self.L.device == value.device\n",
    "        assert value.dtype == torch.bool\n",
    "        \n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        \n",
    "        logdet_L_plus_I = (self.s_l+1).log().sum(dim=-1)  # batch_shape\n",
    "        \n",
    "        # Reshapes\n",
    "        independet_dims = list(value.shape[:-1])\n",
    "        value = value.flatten(start_dim=0, end_dim=-2)  # *, event_shape\n",
    "        L = self.L.expand(independet_dims+[-1,-1]).flatten(start_dim=0, end_dim=-3)  # *, event_shape, event_shape\n",
    "        logdet_Ls = torch.zeros(independet_dims, dtype=self.L.dtype, device=value.device).view(-1)  # *\n",
    "        \n",
    "        # Select rows and columns of the matrix which correspond to selected particles\n",
    "        for i in range(logdet_Ls.shape[0]):\n",
    "            tmp = L[i,value[i],:][:,value[i]]\n",
    "            logdet_Ls[i] = torch.logdet(tmp)\n",
    "        logdet_Ls = logdet_Ls.view(independet_dims)  # sample_shape, batch_shape\n",
    "        return logdet_Ls - logdet_L_plus_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-269.5494, -266.9750, -269.7152], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd31e6c2fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity = Similarity()\n",
    "L = similarity(n_width=20, n_height=20)\n",
    "DPP = FiniteDPP(L=L)\n",
    "value = DPP.sample(sample_shape=torch.Size([3]))\n",
    "log_p = DPP.log_prob(value)\n",
    "mask = similarity.sample_2_mask(value)\n",
    "\n",
    "print(log_p)\n",
    "fig, ax =  plt.subplots(ncols=4, figsize=(12,12))\n",
    "ax[0].imshow(mask[0])\n",
    "ax[1].imshow(mask[1])\n",
    "ax[2].imshow(mask[2])\n",
    "ax[3].imshow(mask.sum(dim=(-3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
