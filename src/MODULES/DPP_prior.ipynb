{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,w,h = 2,20,20\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity(torch.nn.Module):\n",
    "    \"\"\" Similarity based on sum of gaussian kernels of different strength and length_scales \"\"\"\n",
    "\n",
    "    def __init__(self, n_kernels: int = 4, eps: float = 1E-6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_kernels = n_kernels\n",
    "        self.eps = eps\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        \n",
    "        self.w = torch.nn.Parameter(data=torch.randn(self.n_kernels, \n",
    "                                                     device=self.device, \n",
    "                                                     dtype=torch.float), requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(data=torch.randn(self.n_kernels, \n",
    "                                                     device=self.device, \n",
    "                                                     dtype=torch.float), requires_grad=True)\n",
    "        \n",
    "        \n",
    "        # Initialization\n",
    "        self.n_width = -1\n",
    "        self.n_height = -1\n",
    "        self.ix_grid = None\n",
    "        self.iy_grid = None\n",
    "        self.d2 = None\n",
    "        self.diag = None \n",
    "        \n",
    "        \n",
    "    def compute_ixgrid_iygrid_d2_diag(self, n_width: int, n_height: int):\n",
    "        with torch.no_grad():\n",
    "            ix_array = torch.arange(start=0, end=n_width, dtype=torch.int, device=self.device)\n",
    "            iy_array = torch.arange(start=0, end=n_height, dtype=torch.int, device=self.device)\n",
    "            ix_grid, iy_grid = torch.meshgrid([ix_array, iy_array])\n",
    "            pmap_points = torch.stack((ix_grid, iy_grid), dim=-1)  # n_width, n_height, 2\n",
    "            tmp = pmap_points.flatten(start_dim=0, end_dim=-2)  # (n_width*n_height, 2)\n",
    "            d2 = (tmp.unsqueeze(-2) - tmp.unsqueeze(-3)).pow(2).sum(dim=-1).float()\n",
    "            diag = torch.eye(d2.shape[-2], \n",
    "                             dtype=torch.float, \n",
    "                             device=self.device, \n",
    "                             requires_grad=False) * self.eps\n",
    "            return ix_grid, iy_grid, d2, diag\n",
    "        \n",
    "    \n",
    "    def forward(self, n_width: int, n_height: int):\n",
    "        \"\"\" Implement L = sum_i a_i exp[-b_i d2] \"\"\"\n",
    "        b = F.softplus(self.b).view(-1,1,1)\n",
    "        w = F.softplus(self.w).view(-1,1,1)\n",
    "        \n",
    "        if (n_width != self.n_width) or (n_height != self.n_height):\n",
    "            self.n_width=n_width\n",
    "            self.n_height=n_height\n",
    "            tmp = self.compute_ixgrid_iygrid_d2_diag(n_width=n_width, n_height=n_height)\n",
    "            self.ix_grid, self.iy_grid, self.d2, self.diag = tmp\n",
    "                    \n",
    "        #likelihood_kernel = (w*torch.exp(-b*self.d2)).sum(dim=-3) + self.diag\n",
    "        \n",
    "        likelihood_kernel = torch.exp(-0.1*self.d2) + self.diag\n",
    "        return likelihood_kernel  # shape (n_width*n_height, n_width*n_height)\n",
    "    \n",
    "    #def plot(self, sample):\n",
    "    #    loc = torch.zeros(self.K.shape[-1])\n",
    "    #    loc[sample] = 1\n",
    "    #    loc.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dpp(object):\n",
    "    \n",
    "    def __init__(self, L=None):\n",
    "        self.L = L\n",
    "        print(self.L)\n",
    "        lower = torch.cholesky(L)\n",
    "        #debug1 = (torch.matmul(tmp,tmp.T)-L).abs().max()\n",
    "        #print(debug1)\n",
    "        \n",
    "        d = torch.diagonal(lower, offset=0, dim1=-2, dim2=-1)\n",
    "        self.L_eig_vals = d.pow(2)\n",
    "        print(self.L_eig_vals)\n",
    "        self.eig_vecs = lower/d\n",
    "        #debug2 = (torch.matmul(self.eig_vecs*self.L_eig_vals, self.eig_vecs.T)-L).abs().max()\n",
    "        #print(debug2)\n",
    "        \n",
    "        self.K_eig_vals = self.L_eig_vals / (1.0 + self.L_eig_vals)\n",
    "        self.K = torch.matmul(self.eig_vecs * self.K_eig_vals, self.eig_vecs.T)\n",
    "        print(self.K_eig_vals)\n",
    "        print(self.K)\n",
    "        \n",
    "    def sample(self):\n",
    "        A = self.L.clone()\n",
    "        sample = []\n",
    "\n",
    "        for j in range(len(A)):\n",
    "\n",
    "            if torch.rand(1) < A[j, j]:\n",
    "                sample.append(j)\n",
    "            else:\n",
    "                A[j, j] -= 1\n",
    "\n",
    "            A[j + 1:, j] /= A[j, j]\n",
    "            A[j + 1:, j + 1:] -= A[j + 1:, j].unsqueeze(-1)*A[j, j + 1:].unsqueeze(-2)\n",
    "\n",
    "        return sample #, A\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM. \n",
    "0. USE THE MODEL STRAIGHT FROM THE CODE AND SEE IF IT WORKS\n",
    "1. MATRIX K is not translationally invariant...\n",
    "2. SAMPLE ALWAYS PREFER THE FIRST LOCATION\n",
    "3. Implement a nice plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "similarity = Similarity()\n",
    "L = similarity.forward(n_width=4, n_height=2)\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9048, 0.9048, 0.8187, 0.6703, 0.6065, 0.4066, 0.3679],\n",
      "        [0.9048, 1.0000, 0.8187, 0.9048, 0.6065, 0.6703, 0.3679, 0.4066],\n",
      "        [0.9048, 0.8187, 1.0000, 0.9048, 0.9048, 0.8187, 0.6703, 0.6065],\n",
      "        [0.8187, 0.9048, 0.9048, 1.0000, 0.8187, 0.9048, 0.6065, 0.6703],\n",
      "        [0.6703, 0.6065, 0.9048, 0.8187, 1.0000, 0.9048, 0.9048, 0.8187],\n",
      "        [0.6065, 0.6703, 0.8187, 0.9048, 0.9048, 1.0000, 0.8187, 0.9048],\n",
      "        [0.4066, 0.3679, 0.6703, 0.6065, 0.9048, 0.8187, 1.0000, 0.9048],\n",
      "        [0.3679, 0.4066, 0.6065, 0.6703, 0.8187, 0.9048, 0.9048, 1.0000]])\n",
      "tensor([1.0000, 0.1813, 0.1813, 0.0329, 0.0598, 0.0108, 0.0270, 0.0049])\n",
      "tensor([0.5000, 0.1535, 0.1535, 0.0318, 0.0564, 0.0107, 0.0263, 0.0049])\n",
      "tensor([[0.5000, 0.4524, 0.4524, 0.4094, 0.3352, 0.3033, 0.2033, 0.1839],\n",
      "        [0.4524, 0.5628, 0.4094, 0.5093, 0.3033, 0.3773, 0.1839, 0.2288],\n",
      "        [0.4524, 0.4094, 0.5628, 0.5093, 0.5558, 0.5029, 0.4400, 0.3981],\n",
      "        [0.4094, 0.5093, 0.5093, 0.6182, 0.5029, 0.6005, 0.3981, 0.4697],\n",
      "        [0.3352, 0.3033, 0.5558, 0.5029, 0.6966, 0.6303, 0.6846, 0.6195],\n",
      "        [0.3033, 0.3773, 0.5029, 0.6005, 0.6303, 0.7362, 0.6195, 0.7138],\n",
      "        [0.2033, 0.1839, 0.4400, 0.3981, 0.6846, 0.6195, 0.8221, 0.7439],\n",
      "        [0.1839, 0.2288, 0.3981, 0.4697, 0.6195, 0.7138, 0.7439, 0.8462]])\n"
     ]
    }
   ],
   "source": [
    "dpp = Dpp(L=L)\n",
    "#dpp.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc5c50b2dc0>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax =  plt.subplots(ncols=4, figsize=(12,12))\n",
    "ax[0].imshow(L.detach().numpy())\n",
    "ax[1].imshow(s.d2)\n",
    "ax[2].imshow(s.ix_grid)\n",
    "ax[3].imshow(s.iy_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5, 6]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpp_sampler_generic_kernel(K, random_state=None):\n",
    "    \"\"\" Sample from generic :math:`\\\\operatorname{DPP}(\\\\mathbf{K})` with potentially non hermitian correlation kernel :math:`\\\\operatorname{DPP}(\\\\mathbf{K})` based on :math:`LU` factorization procedure.\n",
    "    :param K:\n",
    "        Correlation kernel (potentially non hermitian).\n",
    "    :type K:\n",
    "        array_like\n",
    "    :return:\n",
    "        A sample :math:`\\\\mathcal{X}` from :math:`\\\\operatorname{DPP}(K)` and\n",
    "        the in-place :math:`LU factorization of :math:`K − I_{\\\\mathcal{X}^{c}}` where :math:`I_{\\\\mathcal{X}^{c}}` is the diagonal indicator matrix for the entries not in the sample :math:`\\\\mathcal{X}`.\n",
    "    :rtype:\n",
    "        list and array_like\n",
    "    .. seealso::\n",
    "        - :cite:`Pou19` Algorithm 1\n",
    "    \"\"\"\n",
    "\n",
    "    A = K.clone()\n",
    "    sample = []\n",
    "\n",
    "    for j in range(len(A)):\n",
    "\n",
    "        if torch.rand(1) < A[j, j]:\n",
    "            sample.append(j)\n",
    "        else:\n",
    "            A[j, j] -= 1\n",
    "\n",
    "        A[j + 1:, j] /= A[j, j]\n",
    "        A[j + 1:, j + 1:] -= A[j + 1:, j]*A[j, j + 1:]\n",
    "\n",
    "    return sample, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 5, 6],\n",
       " tensor([[-0.1922,  0.5003,  0.5003,  0.3194,  0.1415,  0.0976,  0.0257,  0.0189],\n",
       "         [-2.6029,  2.3337,  1.6260,  1.1669,  0.2062,  0.2274,  0.0236,  0.0339],\n",
       "         [-2.6029,  0.6967,  1.2010,  0.1977,  0.6659,  0.3411,  0.1880,  0.1187],\n",
       "         [-1.6616,  0.8307,  0.6709,  0.7031, -0.0506,  0.5707,  0.0748,  0.1912],\n",
       "         [-0.7361,  0.6018,  0.7121, -0.1816, -0.2857,  0.2735,  0.7528,  0.5372],\n",
       "         [-0.5076,  0.6343,  0.5039,  0.3784, -0.8849,  1.2316,  1.1969,  0.9564],\n",
       "         [-0.1338,  0.5667,  0.3059, -0.6101, -0.9498,  0.2136,  1.7250,  0.2931],\n",
       "         [-0.0982,  0.5718,  0.2545, -0.4725,  0.0307,  0.5600,  0.7189, -0.1762]],\n",
       "        grad_fn=<CopySlices>))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpp_sampler_generic_kernel(dpp.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3842e-07, grad_fn=<MaxBackward1>)\n",
      "tensor(2.3842e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "dpp = Dpp(similarity=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6907, 1.3997, 1.3958, 1.2219, 1.3786, 1.2081, 1.3742, 1.2052],\n",
      "       grad_fn=<DiagonalBackward>)\n",
      "tensor([0.4274, 0.5954, 0.7741, 0.6738, 0.0093, 0.0381, 0.6485, 0.4944])\n",
      "tensor([False,  True,  True,  True, False, False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "dpp.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[0., 3., 6.],\n",
      "        [1., 4., 7.],\n",
      "        [2., 5., 8.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(9).view(3,3).float()\n",
    "print(a)\n",
    "print(a.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logit = torch.randn((b,1,w,h))\n",
    "pb = pass_bernoulli(logit=logit)\n",
    "\n",
    "c = pb.sample()\n",
    "log_p = pb.log_prob(c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
