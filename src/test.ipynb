{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MODULES.encoders_decoders import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_version() --->  3.8.2\n",
      "torch.__version__ -->  1.6.0\n"
     ]
    }
   ],
   "source": [
    "from MODULES.vae_model import *\n",
    "from MODULES.utilities_ml import process_one_epoch\n",
    "from MODULES.utilities_visualization import show_batch\n",
    "import torch.nn.functional as F\n",
    "from MODULES.utilities_ml import ConditionalRandomCrop, SpecialDataSet, process_one_epoch\n",
    "\n",
    "\n",
    "# Check versions\n",
    "from platform import python_version\n",
    "print(\"python_version() ---> \", python_version())\n",
    "print(\"torch.__version__ --> \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lenght: 10\n",
      "img.shape torch.Size([10, 1, 80, 80])\n",
      "img.dtype torch.float32\n",
      "img.device cpu\n",
      "MINIBATCH: img.shapes seg.shape labels.shape, index.shape -> torch.Size([8, 1, 80, 80]) torch.Size([8, 1, 80, 80]) torch.Size([8]) torch.Size([8])\n",
      "MINIBATCH: min and max of minibatch tensor(0.) tensor(1.)\n",
      "Dataset lenght: 10\n",
      "img.shape torch.Size([10, 1, 80, 80])\n",
      "img.dtype torch.float32\n",
      "img.device cpu\n",
      "MINIBATCH: img.shapes seg.shape labels.shape, index.shape -> torch.Size([8, 1, 80, 80]) torch.Size([8, 1, 80, 80]) torch.Size([8]) torch.Size([8])\n",
      "MINIBATCH: min and max of minibatch tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "multi_mnist_data_train = \"/Users/ldalessi/DAPI_unsupervised/spacetx-research/dataset_multiMNIST/multi_mnist_train.pt\"\n",
    "multi_mnist_data_test = \"/Users/ldalessi/DAPI_unsupervised/spacetx-research/dataset_multiMNIST/multi_mnist_test.pt\"\n",
    "\n",
    "params = load_json_as_dict(\"./ML_parameters.json\")\n",
    "img_train, seg_mask_train, count_train  = load_obj(multi_mnist_data_train)\n",
    "img_test, seg_mask_test, count_test  = load_obj(multi_mnist_data_test)\n",
    "\n",
    "BATCH_SIZE = params[\"simulation\"][\"batch_size\"]\n",
    "SIZE_CROPS = params[\"input_image\"][\"size_raw_image\"]\n",
    "N_TEST = params[\"simulation\"][\"N_test\"]\n",
    "N_TRAIN = params[\"simulation\"][\"N_train\"]\n",
    "\n",
    "train_loader = SpecialDataSet(img=img_train, \n",
    "                              roi_mask=None, \n",
    "                              seg_mask=seg_mask_train, \n",
    "                              labels=count_train, \n",
    "                              batch_size=4, #BATCH_SIZE , \n",
    "                              drop_last=False,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_loader = SpecialDataSet(img=img_test, \n",
    "                             roi_mask=None, \n",
    "                             seg_mask=seg_mask_test, \n",
    "                             labels=count_test, \n",
    "                             batch_size=4, #BATCH_SIZE , \n",
    "                             drop_last=False,\n",
    "                             shuffle=False)\n",
    "\n",
    "test_batch_example_fig = test_loader.check_batch()\n",
    "train_batch_example_fig = train_loader.check_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = CompositionalVae(params)\n",
    "optimizer = instantiate_optimizer(model=vae, dict_params_optimizer=params[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "i =   0 train_loss=18.35329\n",
      "i =   1 train_loss=17.33237\n",
      "i =   2 train_loss=20.44165\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    train_metrics = process_one_epoch(model=vae, \n",
    "                                      dataloader=test_loader, \n",
    "                                      optimizer=optimizer, \n",
    "                                      verbose=(epoch == 0),\n",
    "                                      weight_clipper=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_segment = train_loader.img[0, :, 1060:1360, 2100:2400]\n",
    "plt.imshow(img_to_segment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 1240-160\n",
    "iy= 2140\n",
    "print(ix)\n",
    "img_to_segment = train_loader.img[0, :, ix:ix+2*(80), iy:iy+4*(80)]\n",
    "plt.imshow(img_to_segment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_to_segment = train_loader.img[0, :, 940:1240, 2140:2440]\n",
    "plt.imshow(img_to_segment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entropy(\\pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = params['input_image']['size_raw_image']\n",
    "b, c, w, h = 8, params['input_image']['ch_in'], image_size, image_size\n",
    "imgs_in = torch.sigmoid(torch.randn(b,c,w, h))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(imgs_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from MODULES.utilities_ml import SpecialDataSet\n",
    "#\n",
    "#train_loader = SpecialDataSet(img=imgs_in,\n",
    "#                              store_in_cuda=False,\n",
    "#                              shuffle=True,\n",
    "#                              drop_last=True,\n",
    "#                              batch_size=2)\n",
    "#optimizer = instantiate_optimizer(model=vae, dict_params_optimizer=params[\"optimizer\"])\n",
    "#epoch_restart = -1\n",
    "#history_dict = {}\n",
    "#min_test_loss = 99999999\n",
    "#    \n",
    "#for delta_epoch in range(1, 5):\n",
    "#    epoch = delta_epoch+epoch_restart\n",
    "#    with torch.autograd.set_detect_anomaly(True):\n",
    "#        train_metrics = process_one_epoch(model=vae, \n",
    "#                                          dataloader=train_loader, \n",
    "#                                          optimizer=optimizer, \n",
    "#                                          verbose=True)\n",
    "#        print(train_metrics.pretty_print(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.inference_and_generator.similarity_kernel_dpp.get_l_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated._fields)\n",
    "print(generated.inference._fields)\n",
    "print(generated.inference.sample_c_map.shape)\n",
    "show_batch(generated.inference.sample_c_map.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated.inference.prob_map[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(generated.inference.prob_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MODULES.utilities_visualization import plot_reconstruction_and_inference, plot_segmentation\n",
    "\n",
    "plot_reconstruction_and_inference(generated, epoch=0, prefix=\"gen_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.prob_corr_factor = 0.0\n",
    "output = vae.forward(imgs_in, draw_image=True, draw_boxes=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.max(output.inference.prob_map))\n",
    "show_batch(output.inference.prob_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_map_2 = (torch.rand_like(output.inference.prob_map) < output.inference.prob_map).float()\n",
    "show_batch(c_map_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(output.inference.sample_c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(output.inference.sample_c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.inference.bb_few.bh[..., 0])\n",
    "print(vae.inference_and_generator.size_min)\n",
    "print(vae.inference_and_generator.size_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_and_inference(output, epoch=0, prefix=\"rec_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
